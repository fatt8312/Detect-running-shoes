{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dict of class --> {\"file name - number\" : [gender, color, brand, (possibly their tag no.)]}\n",
    "\n",
    "- I need to crop the largest 2 person in every picture and keep it in some folder \n",
    "- Check and eliminate people that doesn't have shoes from the folder \n",
    "--> store the gender of each person\n",
    "\n",
    "- Crop only the shoes part and keep it in another folder \n",
    "--> store the color of each shoes\n",
    "\n",
    "- Do the classification stuff and store the brand into this dict as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in d:\\anaconda\\lib\\site-packages (8.1.10)\n",
      "Collecting ultralytics\n",
      "  Obtaining dependency information for ultralytics from https://files.pythonhosted.org/packages/aa/cc/a5755f24432e5ffe2b6733ddef64913f650348ba7d20a62fe8795f7c6d39/ultralytics-8.2.2-py3-none-any.whl.metadata\n",
      "  Downloading ultralytics-8.2.2-py3-none-any.whl.metadata (40 kB)\n",
      "     -------------------------------------- 40.4/40.4 kB 944.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (3.4.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (4.7.0.72)\n",
      "Requirement already satisfied: pillow>=7.1.2 in d:\\anaconda\\lib\\site-packages (from ultralytics) (8.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in d:\\anaconda\\lib\\site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (2.26.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in d:\\anaconda\\lib\\site-packages (from ultralytics) (1.11.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (2.0.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (0.15.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: psutil in d:\\anaconda\\lib\\site-packages (from ultralytics) (5.8.0)\n",
      "Requirement already satisfied: py-cpuinfo in d:\\anaconda\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in d:\\anaconda\\lib\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in d:\\anaconda\\lib\\site-packages (from ultralytics) (1.3.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (0.11.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.16 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\anaconda\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2021.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.2)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.10.0)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.9)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2.11.3)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.4)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.2.1)\n",
      "Downloading ultralytics-8.2.2-py3-none-any.whl (750 kB)\n",
      "   ---------------------------------------- 750.8/750.8 kB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: ultralytics\n",
      "  Attempting uninstall: ultralytics\n",
      "    Found existing installation: ultralytics 8.1.10\n",
      "    Uninstalling ultralytics-8.1.10:\n",
      "      Successfully uninstalled ultralytics-8.1.10\n",
      "Successfully installed ultralytics-8.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import math\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# source_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\my-own\\clm10-2023_cut'\n",
    "# destination_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\my-own\\my_own_test'\n",
    "\n",
    "# # ตรวจสอบว่า path ที่ระบุมีอยู่จริงหรือไม่\n",
    "# if not os.path.exists(destination_path):\n",
    "#     os.makedirs(destination_path)\n",
    "\n",
    "# # นับจำนวนไฟล์ใน path source\n",
    "# file_count = len([f for f in os.listdir(source_path) if os.path.isfile(os.path.join(source_path, f))])\n",
    "\n",
    "# # เปลี่ยนชื่อไฟล์\n",
    "# for i, filename in enumerate(os.listdir(source_path)):\n",
    "#     if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # แก้ไขตามนามสกุลของไฟล์ที่คุณมี\n",
    "#         new_filename = f\"{i+1}.jpg\"  # ให้เปลี่ยนเป็นนามสกุลที่ต้องการ\n",
    "#         source_file_path = os.path.join(source_path, filename)\n",
    "#         destination_file_path = os.path.join(destination_path, new_filename)\n",
    "#         os.rename(source_file_path, destination_file_path)\n",
    "\n",
    "# print(f\"เปลี่ยนชื่อไฟล์เรียบร้อยแล้ว จำนวนทั้งหมด {file_count} ไฟล์\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import requests\n",
    "\n",
    "# input_folder = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\my-own\\my_own_test'\n",
    "# output_folder = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\my-own\\pre_my_own_test3'\n",
    "\n",
    "# api_url = 'https://clipdrop-api.co/remove-background/v1'\n",
    "# api_key = '6aef7ec76249c5c2e6f7c38aad06e1a338b58bc3a5528fbe80dbdbbb82d11ec899c97520ecf23aa1ee34bd08b470f858'  # ใส่ API key ของคุณที่นี่\n",
    "\n",
    "# # หากโฟลเดอร์ปลายทางไม่ได้ถูกสร้างไว้ ให้สร้างโฟลเดอร์นี้\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "# for filename in os.listdir(input_folder):\n",
    "#     if filename.endswith('.jpg'):\n",
    "#         input_filepath = os.path.join(input_folder, filename)\n",
    "#         output_filepath = os.path.join(output_folder, filename)\n",
    "\n",
    "#         # อ่านไฟล์รูปภาพ\n",
    "#         with open(input_filepath, 'rb') as image_file_object:\n",
    "#             # ทำการลบพื้นหลังของรูป\n",
    "#             response = requests.post(\n",
    "#                 api_url,\n",
    "#                 files={'image_file': (filename, image_file_object, 'image/jpeg')},\n",
    "#                 headers={'x-api-key': api_key}\n",
    "#             )\n",
    "\n",
    "#             # บันทึกรูปที่ผ่านการลบพื้นหลัง\n",
    "#             if response.ok:\n",
    "#                 with open(output_filepath, 'wb') as out:\n",
    "#                     out.write(response.content)\n",
    "#                 print(f\"Removed background for {filename} and saved to {output_filepath}\")\n",
    "#             else:\n",
    "#                 print(f\"Error removing background for {filename}: {response.status_code}, {response.text}\")\n",
    "\n",
    "# print(\"Processing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rembg in c:\\users\\acer\\appdata\\roaming\\python\\python39\\site-packages (2.0.53)\n",
      "Requirement already satisfied: jsonschema in d:\\anaconda\\lib\\site-packages (from rembg) (3.2.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from rembg) (1.26.1)\n",
      "Requirement already satisfied: onnxruntime in c:\\users\\acer\\appdata\\roaming\\python\\python39\\site-packages (from rembg) (1.16.3)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\acer\\appdata\\roaming\\python\\python39\\site-packages (from rembg) (4.9.0.80)\n",
      "Requirement already satisfied: pillow in d:\\anaconda\\lib\\site-packages (from rembg) (8.4.0)\n",
      "Requirement already satisfied: pooch in c:\\users\\acer\\appdata\\roaming\\python\\python39\\site-packages (from rembg) (1.8.0)\n",
      "Requirement already satisfied: pymatting in c:\\users\\acer\\appdata\\roaming\\python\\python39\\site-packages (from rembg) (1.1.12)\n",
      "Requirement already satisfied: scikit-image in d:\\anaconda\\lib\\site-packages (from rembg) (0.18.3)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from rembg) (1.11.3)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from rembg) (4.66.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in d:\\anaconda\\lib\\site-packages (from jsonschema->rembg) (23.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in d:\\anaconda\\lib\\site-packages (from jsonschema->rembg) (0.18.0)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from jsonschema->rembg) (68.2.2)\n",
      "Requirement already satisfied: six>=1.11.0 in d:\\anaconda\\lib\\site-packages (from jsonschema->rembg) (1.16.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\acer\\appdata\\roaming\\python\\python39\\site-packages (from onnxruntime->rembg) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in d:\\anaconda\\lib\\site-packages (from onnxruntime->rembg) (23.5.26)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from onnxruntime->rembg) (21.0)\n",
      "Requirement already satisfied: protobuf in d:\\anaconda\\lib\\site-packages (from onnxruntime->rembg) (4.24.4)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from onnxruntime->rembg) (1.9)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in d:\\anaconda\\lib\\site-packages (from pooch->rembg) (4.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\anaconda\\lib\\site-packages (from pooch->rembg) (2.26.0)\n",
      "Requirement already satisfied: numba!=0.49.0 in c:\\users\\acer\\appdata\\roaming\\python\\python39\\site-packages (from pymatting->rembg) (0.58.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-image->rembg) (3.4.3)\n",
      "Requirement already satisfied: networkx>=2.0 in d:\\anaconda\\lib\\site-packages (from scikit-image->rembg) (2.6.3)\n",
      "Requirement already satisfied: imageio>=2.3.0 in d:\\anaconda\\lib\\site-packages (from scikit-image->rembg) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in d:\\anaconda\\lib\\site-packages (from scikit-image->rembg) (2021.7.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in d:\\anaconda\\lib\\site-packages (from scikit-image->rembg) (1.1.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm->rembg) (0.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->rembg) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->rembg) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\anaconda\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->rembg) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->rembg) (2.8.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in c:\\users\\acer\\appdata\\roaming\\python\\python39\\site-packages (from numba!=0.49.0->pymatting->rembg) (0.41.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->pooch->rembg) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->pooch->rembg) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->pooch->rembg) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->pooch->rembg) (3.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\acer\\appdata\\roaming\\python\\python39\\site-packages (from coloredlogs->onnxruntime->rembg) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->onnxruntime->rembg) (1.2.1)\n",
      "Requirement already satisfied: pyreadline3 in d:\\anaconda\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime->rembg) (3.4.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install rembg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip show rembg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version\n",
      "---------------------------------- --------------------\n",
      "absl-py                            2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.alabaster                          0.7.12\n",
      "anaconda-client                    1.9.0\n",
      "anaconda-navigator                 2.1.1\n",
      "anaconda-project                   0.10.1\n",
      "anyio                              2.2.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appdirs                            1.4.4\n",
      "argh                               0.26.2\n",
      "argon2-cffi                        20.1.0\n",
      "arrow                              0.13.1\n",
      "asgiref                            3.6.0\n",
      "asn1crypto                         1.4.0\n",
      "astroid                            2.6.6\n",
      "astropy                            4.3.1\n",
      "astunparse                         1.6.3\n",
      "async-generator                    1.10\n",
      "atomicwrites                       1.4.0\n",
      "attrs                              23.2.0\n",
      "Automat                            22.10.0\n",
      "autopep8                           1.5.7\n",
      "Babel                              2.9.1\n",
      "backcall                           0.2.0\n",
      "backports.functools-lru-cache      1.6.4\n",
      "backports.shutil-get-terminal-size 1.0.0\n",
      "backports.tempfile                 1.0\n",
      "backports.weakref                  1.0.post1\n",
      "bcrypt                             3.2.0\n",
      "beautifulsoup4                     4.10.0\n",
      "binaryornot                        0.4.4\n",
      "bitarray                           2.3.0\n",
      "bkcharts                           0.2\n",
      "black                              19.10b0\n",
      "bleach                             4.0.0\n",
      "bokeh                              2.4.1\n",
      "boto                               2.49.0\n",
      "boto3                              1.28.5\n",
      "botocore                           1.31.5\n",
      "Bottleneck                         1.3.2\n",
      "brotlipy                           0.7.0\n",
      "cached-property                    1.5.2\n",
      "cachetools                         5.3.2\n",
      "certifi                            2023.7.22\n",
      "cffi                               1.14.6\n",
      "chardet                            4.0.0\n",
      "charset-normalizer                 2.0.4\n",
      "click                              8.0.3\n",
      "cloudpickle                        2.0.0\n",
      "clyent                             1.2.2\n",
      "cmake                              3.26.0\n",
      "colorama                           0.4.4\n",
      "colorcet                           3.0.1\n",
      "coloredlogs                        15.0.1\n",
      "comtypes                           1.1.10\n",
      "conda                              22.9.0\n",
      "conda-build                        3.26.1\n",
      "conda-content-trust                0+unknown\n",
      "conda_index                        0.2.3\n",
      "conda-pack                         0.6.0\n",
      "conda-package-handling             2.1.0\n",
      "conda_package_streaming            0.8.0\n",
      "conda-repo-cli                     1.0.4\n",
      "conda-token                        0.3.0\n",
      "conda-verify                       3.4.2\n",
      "constantly                         15.1.0\n",
      "contextlib2                        0.6.0.post1\n",
      "cookiecutter                       1.7.2\n",
      "cryptography                       3.4.8\n",
      "cssselect                          1.2.0\n",
      "cycler                             0.10.0\n",
      "Cython                             0.29.24\n",
      "cytoolz                            0.11.0\n",
      "daal4py                            2021.3.0\n",
      "dask                               2021.10.0\n",
      "datashader                         0.15.1\n",
      "datashape                          0.5.4\n",
      "debugpy                            1.4.1\n",
      "decorator                          5.1.0\n",
      "defusedxml                         0.7.1\n",
      "diff-match-patch                   20200713\n",
      "distributed                        2021.10.0\n",
      "dj-database-url                    1.2.0\n",
      "Django                             4.1.7\n",
      "django-heroku                      0.3.1\n",
      "dlib                               19.22.0\n",
      "dnspython                          2.4.2\n",
      "docutils                           0.17.1\n",
      "entrypoints                        0.3\n",
      "et-xmlfile                         1.1.0\n",
      "exceptiongroup                     1.2.0\n",
      "face-recognition                   1.3.0\n",
      "face-recognition-models            0.3.0\n",
      "fastcache                          1.1.0\n",
      "filelock                           3.3.1\n",
      "flake8                             3.9.2\n",
      "Flask                              1.1.2\n",
      "flatbuffers                        23.5.26\n",
      "fonttools                          4.25.0\n",
      "fsspec                             2021.10.1\n",
      "future                             0.18.3\n",
      "gast                               0.5.4\n",
      "gdown                              4.6.4\n",
      "gensim                             4.2.0\n",
      "gevent                             21.8.0\n",
      "gitdb                              4.0.11\n",
      "GitPython                          3.1.40\n",
      "glob2                              0.7\n",
      "google-auth                        2.23.3\n",
      "google-auth-oauthlib               1.0.0\n",
      "google-pasta                       0.2.0\n",
      "greenlet                           1.1.1\n",
      "grpcio                             1.59.0\n",
      "h11                                0.14.0\n",
      "h5py                               3.2.1\n",
      "HeapDict                           1.0.1\n",
      "holoviews                          1.15.4\n",
      "html5lib                           1.1\n",
      "hub-sdk                            0.0.2\n",
      "humanfriendly                      10.0\n",
      "hvplot                             0.8.4\n",
      "hyperlink                          21.0.0\n",
      "idna                               3.2\n",
      "imagecodecs                        2021.8.26\n",
      "imageio                            2.9.0\n",
      "imagesize                          1.2.0\n",
      "importlib-metadata                 4.8.1\n",
      "incremental                        22.10.0\n",
      "inflection                         0.5.1\n",
      "iniconfig                          1.1.1\n",
      "intake                             0.7.0\n",
      "intervaltree                       3.1.0\n",
      "ipykernel                          6.4.1\n",
      "ipython                            7.29.0\n",
      "ipython-genutils                   0.2.0\n",
      "ipywidgets                         7.6.5\n",
      "isort                              5.9.3\n",
      "itemadapter                        0.8.0\n",
      "itemloaders                        1.1.0\n",
      "itsdangerous                       2.0.1\n",
      "jdcal                              1.4.1\n",
      "jedi                               0.18.0\n",
      "Jinja2                             2.11.3\n",
      "jinja2-time                        0.2.0\n",
      "jmespath                           1.0.1\n",
      "joblib                             1.1.0\n",
      "jovian                             0.2.47\n",
      "json5                              0.9.6\n",
      "jsonschema                         3.2.0\n",
      "jupyter                            1.0.0\n",
      "jupyter-client                     6.1.12\n",
      "jupyter-console                    6.4.0\n",
      "jupyter-core                       4.8.1\n",
      "jupyter-server                     1.4.1\n",
      "jupyterlab                         3.2.1\n",
      "jupyterlab-pygments                0.1.2\n",
      "jupyterlab-server                  2.8.2\n",
      "jupyterlab-widgets                 1.0.0\n",
      "keras                              2.14.0\n",
      "keyring                            23.1.0\n",
      "kiwisolver                         1.3.1\n",
      "lazy-object-proxy                  1.6.0\n",
      "libarchive-c                       2.9\n",
      "libclang                           16.0.6\n",
      "llvmlite                           0.41.1\n",
      "locket                             0.2.1\n",
      "lxml                               4.6.3\n",
      "Markdown                           3.4.3\n",
      "MarkupSafe                         1.1.1\n",
      "matplotlib                         3.4.3\n",
      "matplotlib-inline                  0.1.2\n",
      "mccabe                             0.6.1\n",
      "menuinst                           1.4.18\n",
      "mistune                            0.8.4\n",
      "mkl-fft                            1.3.1\n",
      "mkl-random                         1.2.2\n",
      "mkl-service                        2.4.0\n",
      "ml-dtypes                          0.2.0\n",
      "mock                               4.0.3\n",
      "more-itertools                     8.10.0\n",
      "mpmath                             1.2.1\n",
      "msgpack                            1.0.2\n",
      "multipledispatch                   0.6.0\n",
      "munkres                            1.1.4\n",
      "mypy-extensions                    0.4.3\n",
      "navigator-updater                  0.2.1\n",
      "nbclassic                          0.2.6\n",
      "nbclient                           0.5.3\n",
      "nbconvert                          6.1.0\n",
      "nbformat                           5.1.3\n",
      "nest-asyncio                       1.5.1\n",
      "networkx                           2.6.3\n",
      "nltk                               3.6.5\n",
      "nose                               1.3.7\n",
      "notebook                           6.4.5\n",
      "numba                              0.58.1\n",
      "numexpr                            2.7.3\n",
      "numpy                              1.26.1\n",
      "numpydoc                           1.1.0\n",
      "oauthlib                           3.2.2\n",
      "olefile                            0.46\n",
      "onnxruntime                        1.16.3\n",
      "opencv-python                      4.7.0.72\n",
      "opencv-python-headless             4.9.0.80\n",
      "openpyxl                           3.0.9\n",
      "opt-einsum                         3.3.0\n",
      "outcome                            1.3.0.post0\n",
      "packaging                          21.0\n",
      "pandas                             1.3.4\n",
      "pandocfilters                      1.4.3\n",
      "panel                              0.14.4\n",
      "param                              1.13.0\n",
      "paramiko                           2.7.2\n",
      "parsel                             1.8.1\n",
      "parso                              0.8.2\n",
      "partd                              1.2.0\n",
      "path                               16.0.0\n",
      "pathlib2                           2.3.6\n",
      "pathspec                           0.7.0\n",
      "patsy                              0.5.2\n",
      "pep8                               1.7.1\n",
      "pexpect                            4.8.0\n",
      "pickleshare                        0.7.5\n",
      "Pillow                             8.4.0\n",
      "pip                                23.2\n",
      "pkginfo                            1.7.1\n",
      "platformdirs                       4.1.0\n",
      "plotly                             5.15.0\n",
      "pluggy                             0.13.1\n",
      "ply                                3.11\n",
      "pooch                              1.8.0\n",
      "poyo                               0.5.0\n",
      "prometheus-client                  0.11.0\n",
      "prompt-toolkit                     3.0.20\n",
      "Protego                            0.2.1\n",
      "protobuf                           4.24.4\n",
      "psutil                             5.8.0\n",
      "psycopg2                           2.9.5\n",
      "ptyprocess                         0.7.0\n",
      "py                                 1.10.0\n",
      "py-cpuinfo                         9.0.0\n",
      "pyasn1                             0.4.8\n",
      "pyasn1-modules                     0.2.7\n",
      "pycodestyle                        2.7.0\n",
      "pycosat                            0.6.3\n",
      "pycparser                          2.20\n",
      "pyct                               0.4.6\n",
      "pycurl                             7.44.1\n",
      "PyDispatcher                       2.0.5\n",
      "pydocstyle                         6.1.1\n",
      "pyerfa                             2.0.0\n",
      "pyflakes                           2.3.1\n",
      "Pygments                           2.16.1\n",
      "PyJWT                              2.4.0\n",
      "pylint                             2.9.6\n",
      "pyls-spyder                        0.4.0\n",
      "PyMatting                          1.1.12\n",
      "pymongo                            4.6.1\n",
      "PyNaCl                             1.4.0\n",
      "pyodbc                             4.0.0-unsupported\n",
      "pyOpenSSL                          21.0.0\n",
      "pyparsing                          3.0.4\n",
      "pyreadline                         2.1\n",
      "pyreadline3                        3.4.1\n",
      "pyrsistent                         0.18.0\n",
      "PySocks                            1.7.1\n",
      "pytest                             6.2.4\n",
      "python-dateutil                    2.8.2\n",
      "python-dotenv                      1.0.1\n",
      "python-lsp-black                   1.0.0\n",
      "python-lsp-jsonrpc                 1.0.0\n",
      "python-lsp-server                  1.2.4\n",
      "python-slugify                     5.0.2\n",
      "pytz                               2021.3\n",
      "pyviz-comms                        2.3.2\n",
      "PyWavelets                         1.1.1\n",
      "pywin32                            228\n",
      "pywin32-ctypes                     0.2.0\n",
      "pywinpty                           0.5.7\n",
      "PyYAML                             6.0\n",
      "pyzmq                              22.2.1\n",
      "QDarkStyle                         3.0.2\n",
      "qstylizer                          0.1.10\n",
      "QtAwesome                          1.0.2\n",
      "qtconsole                          5.1.1\n",
      "QtPy                               1.10.0\n",
      "queuelib                           1.6.2\n",
      "regex                              2021.8.3\n",
      "rembg                              2.0.53\n",
      "requests                           2.26.0\n",
      "requests-file                      1.5.1\n",
      "requests-oauthlib                  1.3.1\n",
      "rope                               0.19.0\n",
      "rsa                                4.9\n",
      "Rtree                              0.9.7\n",
      "ruamel-yaml-conda                  0.15.100\n",
      "s3transfer                         0.6.1\n",
      "scikit-image                       0.18.3\n",
      "scikit-learn                       0.24.2\n",
      "scikit-learn-intelex               2021.20210714.120553\n",
      "scipy                              1.11.3\n",
      "Scrapy                             2.9.0\n",
      "seaborn                            0.11.2\n",
      "selenium                           4.18.1\n",
      "Send2Trash                         1.8.0\n",
      "service-identity                   18.1.0\n",
      "setuptools                         68.2.2\n",
      "simplegeneric                      0.8.1\n",
      "singledispatch                     3.7.0\n",
      "sip                                4.19.13\n",
      "six                                1.16.0\n",
      "smart-open                         6.3.0\n",
      "smmap                              5.0.1\n",
      "sniffio                            1.3.1\n",
      "snowballstemmer                    2.1.0\n",
      "sortedcollections                  2.1.0\n",
      "sortedcontainers                   2.4.0\n",
      "soupsieve                          2.2.1\n",
      "Sphinx                             4.2.0\n",
      "sphinxcontrib-applehelp            1.0.2\n",
      "sphinxcontrib-devhelp              1.0.2\n",
      "sphinxcontrib-htmlhelp             2.0.0\n",
      "sphinxcontrib-jsmath               1.0.1\n",
      "sphinxcontrib-qthelp               1.0.3\n",
      "sphinxcontrib-serializinghtml      1.1.5\n",
      "sphinxcontrib-websupport           1.2.4\n",
      "spyder                             5.1.5\n",
      "spyder-kernels                     2.1.3\n",
      "SQLAlchemy                         1.4.22\n",
      "sqlparse                           0.4.3\n",
      "statsmodels                        0.12.2\n",
      "sympy                              1.9\n",
      "tables                             3.6.1\n",
      "tabulate                           0.9.0\n",
      "TBB                                0.2\n",
      "tblib                              1.7.0\n",
      "tenacity                           8.2.2\n",
      "tensorboard                        2.14.1\n",
      "tensorboard-data-server            0.7.2\n",
      "tensorboard-plugin-wit             1.8.1\n",
      "tensorflow                         2.14.0\n",
      "tensorflow-estimator               2.14.0\n",
      "tensorflow-intel                   2.14.0\n",
      "tensorflow-io-gcs-filesystem       0.31.0\n",
      "termcolor                          2.3.0\n",
      "terminado                          0.9.4\n",
      "testpath                           0.5.0\n",
      "text-unidecode                     1.3\n",
      "textdistance                       4.2.1\n",
      "thop                               0.1.1.post2209072238\n",
      "threadpoolctl                      2.2.0\n",
      "three-merge                        0.1.1\n",
      "tifffile                           2021.7.2\n",
      "tinycss                            0.4\n",
      "tldextract                         3.4.4\n",
      "toml                               0.10.2\n",
      "tomli                              2.0.1\n",
      "toolz                              0.11.1\n",
      "torch                              2.0.0\n",
      "torchaudio                         2.0.2\n",
      "torchvision                        0.15.1\n",
      "tornado                            6.1\n",
      "tqdm                               4.66.1\n",
      "traitlets                          5.1.0\n",
      "trio                               0.25.0\n",
      "trio-websocket                     0.11.1\n",
      "Twisted                            22.4.0\n",
      "twisted-iocpsupport                1.0.2\n",
      "typed-ast                          1.4.3\n",
      "typing_extensions                  4.10.0\n",
      "tzdata                             2022.7\n",
      "ujson                              4.0.2\n",
      "ultralytics                        8.2.2\n",
      "unicodecsv                         0.14.1\n",
      "Unidecode                          1.2.0\n",
      "urllib3                            1.26.7\n",
      "uuid                               1.30\n",
      "w3lib                              2.1.1\n",
      "watchdog                           2.1.3\n",
      "wcwidth                            0.2.5\n",
      "webdriver-manager                  4.0.1\n",
      "webencodings                       0.5.1\n",
      "Werkzeug                           2.0.2\n",
      "wheel                              0.37.0\n",
      "whichcraft                         0.6.1\n",
      "whitenoise                         6.4.0\n",
      "widgetsnbextension                 3.5.1\n",
      "win-inet-pton                      1.1.0\n",
      "win-unicode-console                0.5\n",
      "wincertstore                       0.2\n",
      "wrapt                              1.12.1\n",
      "wsproto                            1.2.0\n",
      "xarray                             2022.11.0\n",
      "xlrd                               2.0.1\n",
      "XlsxWriter                         3.0.1\n",
      "xlwings                            0.24.9\n",
      "xlwt                               1.3.0\n",
      "xmltodict                          0.12.0\n",
      "yapf                               0.31.0\n",
      "zict                               2.0.0\n",
      "zipp                               3.6.0\n",
      "zope.event                         4.5.0\n",
      "zope.interface                     5.4.0\n",
      "zstandard                          0.19.0\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from rembg import remove\n",
    "\n",
    "\n",
    "input_folder = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\my-own\\my_own_test'\n",
    "output_folder = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\my-own\\pre_my_own_test3'\n",
    "\n",
    "# ดึงรายชื่อไฟล์ทั้งหมดในโฟลเดอร์ input\n",
    "input_files = os.listdir(input_folder)\n",
    "\n",
    "# วนลูปทุกรูปภาพในโฟลเดอร์ input\n",
    "for input_file in input_files:\n",
    "    input_path = os.path.join(input_folder, input_file)\n",
    "    output_path = os.path.join(output_folder, f\"{input_file}\")\n",
    "\n",
    "    with open(input_path, 'rb') as i:\n",
    "        with open(output_path, 'wb') as o:\n",
    "            input_data = i.read()\n",
    "            output_data = remove(input_data)\n",
    "            o.write(output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # withoutbg\n",
    "# # https://withoutbg.com/account/\n",
    "\n",
    "# import os\n",
    "# import requests\n",
    "\n",
    "# url = 'https://api.withoutbg.com/v1.0/image-without-background'\n",
    "# api_key = 'd9d4a5b6-88ab-410b-b9ea-d2bdeea4e838' #เปลี่ยน api key\n",
    "\n",
    "# input_folder_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\my-own\\my_own_test'\n",
    "\n",
    "# output_folder_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\my-own\\my_own_test4'\n",
    "\n",
    "# for filename in os.listdir(input_folder_path):\n",
    "#     if filename.endswith('.jpg'):\n",
    "#         input_file_path = os.path.join(input_folder_path, filename)\n",
    "#         output_file_path = os.path.join(output_folder_path, filename)\n",
    "        \n",
    "#         headers = {\n",
    "#             'accept': 'application/json',\n",
    "#             'X-API-Key': api_key,\n",
    "#         }\n",
    "        \n",
    "#         files = {\n",
    "#             'file': (filename, open(input_file_path, 'rb')),\n",
    "#         }\n",
    "        \n",
    "#         response = requests.post(url, headers=headers, files=files)\n",
    "        \n",
    "#         with open(output_file_path, 'wb') as f:\n",
    "#             f.write(response.content)\n",
    "\n",
    "# print(\"All images processed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 1.jpg\n",
      "All images processed and saved with a black background.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "input_folder = r\"D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\my-own\\pre_my_own_test3\"\n",
    "output_folder = r\"D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\my-own\\my_own_test3\"\n",
    "\n",
    "# ตรวจสอบว่าโฟลเดอร์ output มีหรือไม่\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# อ่านไฟล์รูป\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Check if the image has an alpha channel (transparency)\n",
    "        if img.mode == 'RGBA':\n",
    "            # If it has an alpha channel, use it as the mask\n",
    "            black_background = Image.new(\"RGB\", img.size, \"black\")\n",
    "            black_background.paste(img, mask=img.split()[3])\n",
    "        else:\n",
    "            # If there's no alpha channel, simply paste the image on a black background\n",
    "            black_background = Image.new(\"RGB\", img.size, \"black\")\n",
    "            black_background.paste(img)\n",
    "\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        black_background.save(output_path)\n",
    "\n",
    "        print(f\"Processed: {filename}\")\n",
    "\n",
    "print(\"All images processed and saved with a black background.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect DA PERSON w yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yolov5 = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\yolov5\\yolov5'\n",
    "os.chdir(yolov5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\yolov5\\yolov5\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['D:\\\\SWE62-363 Seminar for software Engineering\\\\Detect running shoes\\\\yolov5m_Objects365.pt'], source=D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\my-own\\my_own_test3, data=data\\coco128.yaml, imgsz=[416, 416], conf_thres=0.7, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_csv=False, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "'git' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "YOLOv5  2023-9-25 Python-3.9.7 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 22323858 parameters, 0 gradients\n",
      "image 1/1 D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\my-own\\my_own_test3\\1.jpg: 416x288 1 Person, 2 Sneakerss, 282.1ms\n",
      "Speed: 1.0ms pre-process, 282.1ms inference, 14.5ms NMS per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\exp\u001b[0m\n",
      "1 labels saved to runs\\detect\\exp\\labels\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights \"D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\yolov5m_Objects365.pt\" --source \"D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\my-own\\my_own_test3\" --imgsz 416 --conf 0.7 --save-txt --save-conf\n",
    "# the source is the same path as the shoes folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't forget to change and check the source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop DA person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = 'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1'\n",
    "os.chdir(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = 'D:\\\\SWE62-363 Seminar for software Engineering\\\\Detect running shoes\\\\yolov5\\\\yolov5\\\\runs\\\\detect\\\\exp\\\\labels' #change the txt file from the person detected\n",
    "original_folder = 'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\my-own\\my_own_test3'  #change the source above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file Person already exists.\n"
     ]
    }
   ],
   "source": [
    "#Can use here \n",
    "os.chdir(real)\n",
    "!mkdir Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xe_ye(xe, ye, img_file):\n",
    "    os.chdir(original_folder)\n",
    "    img = cv2.imread(img_file)\n",
    "\n",
    "    ye = float(img.shape[0])\n",
    "    xe = float(img.shape[1])\n",
    "\n",
    "    return(xe,ye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w_h(i, xe, ye, width, height, conf):\n",
    "    content = i.split()\n",
    "    c, ctr_x, ctr_y, w, h, conf = content[0:6]\n",
    "    ctr_x = float(ctr_x)\n",
    "    ctr_y = float(ctr_y)\n",
    "    w = float(w)\n",
    "    h = float(h)\n",
    "    \n",
    "    # store the actual size information\n",
    "    x = xe * ctr_x\n",
    "    y = ye * ctr_y\n",
    "\n",
    "    width = w * xe\n",
    "    height = h * ye\n",
    "\n",
    "    return(width, height, conf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for fun\n",
    "#Create a dictionary that store each person information\n",
    "cooord_dict = {} #dict of a list of 2 dictionary\n",
    "# {'(203)' : [{person1: [34.3, 43.33, 43.3, 34.3]}, {person2: 33, 33, 32, 22}, {shoes1-1:22,33,4,55},], '(34)' : [{}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_folder = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Person'\n",
    "os.makedirs(person_folder, exist_ok=True)\n",
    "\n",
    "shoes_folder = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes'\n",
    "os.makedirs(shoes_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_shoes(img_file, lines, file_name, c_d):\n",
    "  num = 1\n",
    "\n",
    "  os.chdir(original_folder)\n",
    "  img = cv2.imread(img_file)\n",
    "\n",
    "  ye,xe = img.shape[0], img.shape[1] #coordinate of the image\n",
    "\n",
    "  xe = float(xe)\n",
    "  ye = float(ye)\n",
    "\n",
    "  dn = file_name.rpartition('-')\n",
    "  #cooord_dict[dn[0]] = []\n",
    "  hey = c_d[dn[0]]\n",
    "\n",
    "  for i in lines:\n",
    "\n",
    "    # read in the raw data from the label txt file\n",
    "    content = i.split()\n",
    "    c, ctr_x, ctr_y, w, h = content[0:5]\n",
    "    ctr_x = float(ctr_x)\n",
    "    ctr_y = float(ctr_y)\n",
    "    w = float(w)\n",
    "    h = float(h)\n",
    "    \n",
    "\n",
    "    # store the actual size information\n",
    "    x = xe * ctr_x\n",
    "    y = ye * ctr_y\n",
    "\n",
    "    width = w * xe\n",
    "    height = h * ye\n",
    "\n",
    "    # find the actual predicted box\n",
    "    start_x = x - (width/2)\n",
    "    start_y = y - (height/2)\n",
    "\n",
    "    sx = int(start_x)\n",
    "    ww = int(width)\n",
    "\n",
    "    sy = int(start_y)\n",
    "    hh = int(height)\n",
    "\n",
    "    #os.chdir(img_folder)\n",
    "    img_r = cv2.imread(img_file)\n",
    "    shoes_obj = img_r[sy:sy+hh+10, sx:sx+ww]\n",
    "\n",
    "    num = str(num)\n",
    "\n",
    "    # change accoarding to where you wanna put the file and what name\n",
    "    path_name = os.path.join(person_folder, f'{file_name}{num}.jpg')    \n",
    "    cv2.imwrite(path_name, shoes_obj)\n",
    "    sub_pers_name = f'person-{num}'\n",
    "    sub_dict = {sub_pers_name: [[sx,sy], [sx+ww,sy], [sx+ww,sy+hh+10], [sx,sy+hh+10]]}\n",
    "    hey.append(sub_dict)    \n",
    "\n",
    "    num = int(num)\n",
    "    num = num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_shoes2(img_file, file_name, xe, ye, i, num, c_d):\n",
    "  os.chdir(original_folder)\n",
    "  img = cv2.imread(img_file)\n",
    "\n",
    "  # read in the raw data from the label txt file\n",
    "  content = i.split()\n",
    "  c, ctr_x, ctr_y, w, h = content[0:5]\n",
    "  ctr_x = float(ctr_x); ctr_y = float(ctr_y); w = float(w); h = float(h)\n",
    "  \n",
    "  # store the actual size information\n",
    "  x = xe * ctr_x\n",
    "  y = ye * ctr_y\n",
    "  \n",
    "  width = w * xe\n",
    "  height = h * ye\n",
    "  \n",
    "  # find the actual predicted box\n",
    "  start_x = x - (width/2)\n",
    "  start_y = y - (height/2)\n",
    "  \n",
    "  sx = int(start_x)\n",
    "  ww = int(width)\n",
    "  \n",
    "  sy = int(start_y)\n",
    "  hh = int(height)\n",
    "  \n",
    "  img_r = cv2.imread(img_file)\n",
    "  shoes_obj = img_r[sy:sy+hh+10, sx:sx+ww]\n",
    "  num = str(num)\n",
    "  \n",
    "  dn = file_name.rpartition('-')\n",
    "  hey = c_d[dn[0]]\n",
    "\n",
    "  sub_pers_name = f'person-{num}'\n",
    "  sub_dict = {sub_pers_name: [[sx,sy], [sx+ww,sy], [sx+ww,sy+hh+10], [sx,sy+hh+10]]}\n",
    "  hey.append(sub_dict)\n",
    "  \n",
    "  # change accoarding to where you wanna put the file and what namE\n",
    "  path_name = os.path.join(person_folder, f'{file_name}{num}.jpg')\n",
    "  cv2.imwrite(path_name, shoes_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir(txt_file):\n",
    "    if (i.endswith('txt')):\n",
    "        f = i.rpartition(\".\")\n",
    "        cooord_dict[f[0]] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this one might be better\n",
    "\n",
    "folder = txt_file\n",
    "\n",
    "for i in os.listdir(folder):\n",
    "  compare_dict = {}\n",
    "  if (i.endswith('txt')):\n",
    "    f = i.rpartition(\".\")\n",
    "    f_jpg = f[0] + '.jpg'\n",
    "    f_name = f[0] + '-'\n",
    "\n",
    "    xe = int(1); ye = int(1)\n",
    "    xe,ye = get_xe_ye(xe, ye, f_jpg)\n",
    "\n",
    "    os.chdir(txt_file)\n",
    "    txt = open(i, 'r')\n",
    "    lines = txt.readlines()\n",
    "\n",
    "    \n",
    "    num = 0\n",
    "    for lll in lines:\n",
    "      content = lll.split()\n",
    "      u = content[1]\n",
    "      w = int(1); h = int(1); conf = int(1)\n",
    "      w, h, conf = get_w_h(lll, xe, ye, w, h, conf)\n",
    "      num = str(num)\n",
    "      dms = float(w*h)\n",
    "      compare_dict[u] = dms\n",
    "\n",
    "    if len(compare_dict) <= 2:\n",
    "      crop_to_shoes(f_jpg, lines, f_name, cooord_dict)\n",
    "    \n",
    "    else:\n",
    "      num = int(1)\n",
    "      while len(compare_dict) != 2:\n",
    "        min_used = min(compare_dict, key=compare_dict.get)\n",
    "        compare_dict.pop(min_used)\n",
    "\n",
    "      for i in compare_dict:\n",
    "        for j in lines:\n",
    "          cont = j.split()\n",
    "          cfl = cont[1]\n",
    "          if cfl == i:\n",
    "            crop_to_shoes2(f_jpg, f_name, xe, ye, j, num, cooord_dict)\n",
    "            num+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_if_not_exists(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Person\n"
     ]
    }
   ],
   "source": [
    "pers_fld = 'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Person' # Still accoarding to the above path\n",
    "# pers_fld = 'F:\\\\intern\\\\model_shoes_detection\\\\Detect running shoes\\\\shoe detection\\\\ImageBackgroundRemover\\\\static\\\\results'\n",
    "create_folder_if_not_exists(pers_fld)\n",
    "print(pers_fld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find DA shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file Shoes already exists.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(real)\n",
    "!mkdir Shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes\n"
     ]
    }
   ],
   "source": [
    "shoes_fld = 'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes' #New folder to store the shoes\n",
    "create_folder_if_not_exists(shoes_fld)\n",
    "print(shoes_fld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir(pers_fld):\n",
    "    if i.endswith('jpg'):\n",
    "        os.chdir(pers_fld)\n",
    "        img = cv2.imread(i)\n",
    "\n",
    "        ye = int(img.shape[0])\n",
    "        xe = int(img.shape[1])\n",
    "\n",
    "        start_y = int(ye * 2 / 3)\n",
    "    \n",
    "        shoes_obj = img[start_y:ye, :,:]\n",
    "    \n",
    "        os.chdir(shoes_fld)\n",
    "        cv2.imwrite(i, shoes_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov5 = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\yolov5\\yolov5'\n",
    "os.chdir(yolov5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['D:\\\\SWE62-363 Seminar for software Engineering\\\\Detect running shoes\\\\yolov5m_Objects365.pt'], source=D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes, data=data\\coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_csv=False, save_conf=True, save_crop=False, nosave=False, classes=[1], agnostic_nms=False, augment=True, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "'git' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "YOLOv5  2023-9-25 Python-3.9.7 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 22323858 parameters, 0 gradients\n",
      "image 1/2 D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes\\1-1.jpg: 160x416 (no detections), 332.5ms\n",
      "image 2/2 D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes\\1-2.jpg: 384x416 2 Sneakerss, 683.3ms\n",
      "Speed: 0.5ms pre-process, 507.9ms inference, 2.5ms NMS per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\exp2\u001b[0m\n",
      "1 labels saved to runs\\detect\\exp2\\labels\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights \"D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\yolov5m_Objects365.pt\" --source \"D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes\" --imgsz 416 --conf 0.5 --classes 1 --save-txt --save-conf --augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python detect.py --weights \"F:\\\\intern\\\\model_shoes_detection\\\\Detect running shoes\\\\yolov5m_Objects365.pt\" --source \"F:\\\\intern\\\\model_shoes_detection\\\\Detect running shoes\\\\shoe detection\\\\Real_1\\\\Shoes\" --imgsz 416 --conf 0.5 --classes 1 --save-txt --save-conf\n",
    "# the source is the same path as the shoes folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "shoes_txt = 'D:\\\\SWE62-363 Seminar for software Engineering\\\\Detect running shoes\\\\yolov5\\\\yolov5\\\\runs\\\\detect\\\\exp2\\\\labels'\n",
    "pers_fld = 'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Person'  # Replace this with the path to your folder containing person images\n",
    "shoes_fld = 'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes'  # Replace this with the path to your folder containing shoes images\n",
    "\n",
    "# Assuming cooord_dict is defined somewhere in your code\n",
    "# cooord_dict = ...\n",
    "\n",
    "for i in os.listdir(pers_fld):\n",
    "    if i.endswith('.jpg'):\n",
    "        os.chdir(shoes_txt)\n",
    "        f = os.path.splitext(i)[0] + '.txt'  # Get the corresponding label file name\n",
    "        path = Path(f)\n",
    "        if not path.is_file():\n",
    "            os.chdir(pers_fld)\n",
    "            os.remove(i)  # Remove person image\n",
    "            os.chdir(shoes_fld)\n",
    "            os.remove(i)  # Remove shoes image\n",
    "\n",
    "            # Extract the numeric part of the filename without extension\n",
    "            index_part = os.path.splitext(i)[0].split('-')[1]\n",
    "            pop_this = int(index_part) - 1  # Convert index to integer and subtract 1\n",
    "\n",
    "            key = os.path.splitext(i)[0].split('-')[0]  # Extract the key part of the filename without extension\n",
    "            sub_dict = cooord_dict.get(key, [])  # Get the corresponding sublist from the dictionary\n",
    "            \n",
    "            if len(sub_dict) > pop_this:  # Check if the index is within the range of the list\n",
    "                sub_dict.pop(pop_this)  # Remove the element from the list\n",
    "            else:\n",
    "                print(\"Index out of range for key:\", key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #reomove person with no shoes and remove picture of shoes with no shoes\n",
    "# shoes_txt = 'F:\\\\intern\\\\model_shoes_detection\\\\Detect running shoes\\\\yolov5\\\\yolov5\\\\runs\\\\detect\\\\exp2\\\\labels'\n",
    "\n",
    "# for i in os.listdir(pers_fld):\n",
    "#     if (i.endswith('jpg' or 'jpg')):\n",
    "#         os.chdir(shoes_txt)\n",
    "#         f = i.rpartition(\".\")\n",
    "#         f_txt = f[0] + '.txt'\n",
    "#         path = Path(f_txt)\n",
    "#         if not (path.is_file()):\n",
    "#             os.chdir(pers_fld) \n",
    "#             os.remove(i)\n",
    "#             os.chdir(shoes_fld)\n",
    "#             os.remove(i)\n",
    "\n",
    "#             y = i.rpartition('.') #(501)-1 . JPG\n",
    "#             key = y[0].rpartition('-') # (501) - 1\n",
    "#             pop_this = int(key[2]) - 1\n",
    "\n",
    "#             sub_dict = cooord_dict[key[0]]\n",
    "            \n",
    "#             if len(sub_dict) > 1:\n",
    "#                 sub_dict.pop(pop_this)\n",
    "#             else:\n",
    "#                 print(\"List has fewer than 2 elements, cannot pop.\")\n",
    "\n",
    "# os.chdir(real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find DA face and keep them in DA dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary that store each person information\n",
    "bio_dict = {}\n",
    "\n",
    "for i in os.listdir(pers_fld):\n",
    "    if i.endswith('jpg'):\n",
    "        name = i.rpartition('.')\n",
    "        key = name[0]\n",
    "        bio_dict[key] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # โหลดภาพ\n",
    "# image_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Person\\1-2.jpg'\n",
    "# image = cv2.imread(image_path)\n",
    "\n",
    "# # ปรับขนาดภาพเป็น 374x1046\n",
    "# resized_image = cv2.resize(image, (374, 1046))\n",
    "\n",
    "# # คำนวณค่าเฉลี่ยของแต่ละช่องสีในภาพ\n",
    "# mean_values = np.mean(resized_image, axis=(0, 1))\n",
    "# print(\"Mean Values (B, G, R):\", mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def create_folder_if_not_exists(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Person-crop\n"
     ]
    }
   ],
   "source": [
    "pers_crop_fld = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Person-crop' # Still accoarding to the above path\n",
    "# pers_fld = 'F:\\\\intern\\\\model_shoes_detection\\\\Detect running shoes\\\\shoe detection\\\\ImageBackgroundRemover\\\\static\\\\results'\n",
    "create_folder_if_not_exists(pers_crop_fld)\n",
    "print(pers_crop_fld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "gender_ranges = ['Male', 'Female']\n",
    "image_folder = r\"D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Person\"\n",
    "output_folder = r\"D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Person-crop\"\n",
    "\n",
    "# Get a list of all image files in the 'Person' folder\n",
    "image_files = glob.glob(os.path.join(image_folder, '*.jpg'))\n",
    "\n",
    "# Create an empty dictionary to store the results\n",
    "i_bio_dict = {}\n",
    "\n",
    "# Load the gender detection model\n",
    "gender_net = cv2.dnn.readNet(\n",
    "    'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\gender-detection\\gender_net.caffemodel',\n",
    "    'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\gender-detection\\gender_deploy.prototxt')\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each image file and process it\n",
    "for img_path in image_files:\n",
    "    test_image = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier('D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\gender-detection\\haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        # Find the largest face\n",
    "        largest_face = max(faces, key=lambda rect: rect[2] * rect[3])\n",
    "        x, y, w, h = largest_face\n",
    "\n",
    "        # Crop the image to the region of the largest face\n",
    "        cropped_image = test_image[y:y + h, x:x + w]\n",
    "\n",
    "        # Save the cropped image to the output folder\n",
    "        file_name = os.path.basename(img_path)\n",
    "        output_path = os.path.join(output_folder, file_name)\n",
    "        cv2.imwrite(output_path, cropped_image)\n",
    "\n",
    "        # Process the cropped image to detect gender\n",
    "        gender_img = cv2.resize(cropped_image, (100, 100), interpolation=cv2.INTER_AREA)\n",
    "        blob = cv2.dnn.blobFromImage(gender_img, 1.0, (227, 227), (78.4263377603, 87.7689143744, 114.895847746), swapRB=False)\n",
    "        gender_net.setInput(blob)\n",
    "        genderPreds = gender_net.forward()\n",
    "        gender = gender_ranges[genderPreds[0].argmax()]\n",
    "\n",
    "        # Get the base file name without the path and extension\n",
    "        file_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "        # Check if the name is already in the dictionary, if not, create an empty list\n",
    "        if file_name not in i_bio_dict:\n",
    "            i_bio_dict[file_name] = []\n",
    "\n",
    "        # Append the gender prediction to the list\n",
    "        i_bio_dict[file_name].append(gender)\n",
    "\n",
    "# Print the sorted bio_dict\n",
    "bio_dict = dict(sorted(i_bio_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1-2': ['Male']}\n"
     ]
    }
   ],
   "source": [
    "print(bio_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing Models and set mean values\n",
    "# face1 = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\gender-detection\\opencv_face_detector.pbtxt'\n",
    "# face2 = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\gender-detection\\opencv_face_detector_uint8.pb'\n",
    "# gen1 = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\gender-detection\\gender_deploy.prototxt'\n",
    "# gen2 = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\gender-detection\\gender_net.caffemodel'\n",
    "\n",
    "\n",
    "# # MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "# MODEL_MEAN_VALUES = (116.51791393, 126.78930941, 154.04674543) \n",
    "\n",
    "# face = cv2.dnn.readNet(face2, face1)\n",
    "# face_net = cv2.dnn.readNet(face2, face1)\n",
    "\n",
    "# gen = cv2.dnn.readNet(gen2, gen1)\n",
    "# lg = ['Male', 'Female']\n",
    "\n",
    "# for img in os.listdir(pers_fld):\n",
    "#   if img.endswith('jpg'):\n",
    "#     os.chdir(pers_fld)\n",
    "#     image = cv2.imread(img)\n",
    "#     name = img.rpartition('.')\n",
    "#     name = name[0]\n",
    "    \n",
    "#     if image is None:\n",
    "#       #bio_dict[name].append('no detection') \n",
    "#       continue\n",
    "    \n",
    "#     # image = cv2.resize(image, (229, 640))\n",
    "#     image = cv2.resize(image, (374, 1046))\n",
    "    \n",
    "#     # Copy image    \n",
    "#     fr_cv = image.copy()\n",
    "    \n",
    "#     # Face detection\n",
    "#     fr_h = fr_cv.shape[0]\n",
    "#     fr_w = fr_cv.shape[1]\n",
    "#     blob = cv2.dnn.blobFromImage(fr_cv, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "#     face_net.setInput(blob)\n",
    "#     detections = face_net.forward()\n",
    "    \n",
    "#     faceBoxes = []\n",
    "#     for i in range(detections.shape[2]):\n",
    "#       #Bounding box creation if confidence > 0.5\n",
    "#       confidence = detections[0, 0, i, 2]\n",
    "#       if confidence > 0.5:\n",
    "#         x1 = int(detections[0, 0, i, 3]*fr_w)\n",
    "#         y1 = int(detections[0, 0, i, 4]*fr_h)\n",
    "#         x2 = int(detections[0, 0, i, 5]*fr_w)\n",
    "#         y2 = int(detections[0, 0, i, 6]*fr_h)\n",
    "        \n",
    "#         faceBoxes.append([x1, y1, x2, y2])\n",
    "        \n",
    "#         cv2.rectangle(fr_cv, (x1, y1), (x2, y2),(0, 255, 0), int(round(fr_h/150)), 8)\n",
    "        \n",
    "#         # Checking if face detected or not\n",
    "#     if not faceBoxes:\n",
    "#       bio_dict[name].append('no detection') \n",
    "#       continue\n",
    "\n",
    "#         # Final results (otherwise)\n",
    "#     else:\n",
    "#       faceBox = faceBoxes[0]\n",
    "#       #Extracting face as per the faceBox\n",
    "#       face = fr_cv[max(0, faceBox[1]-15):min(faceBox[3]+15, fr_cv.shape[0]-1),\n",
    "#                   max(0, faceBox[0]-15):min(faceBox[2]+15,fr_cv.shape[1]-1)]\n",
    "\n",
    "#       #Extracting the main blob part\n",
    "#       blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "        \n",
    "#      #Prediction of gender\n",
    "#       gen.setInput(blob)\n",
    "#       genderPreds = gen.forward()\n",
    "#       gender = lg[genderPreds[0].argmax()]\n",
    "#       bio_dict[name].append(gender) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(bio_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect DA COlor (but first we need to crop DA shoes first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD VERSION --------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file Shoes-crop already exists.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(real)\n",
    "!mkdir Shoes-crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_crop = 'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_txt_file = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\yolov5\\yolov5\\runs\\detect\\exp2\\labels'\n",
    "original_file = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_only_shoes(img_file, txt_file, f_name, c_d, l):\n",
    "    # Get the dimensions of the image\n",
    "    img = cv2.imread(img_file)\n",
    "    xe, ye = img.shape[1], img.shape[0]\n",
    "\n",
    "    f_name = f_name + '_'\n",
    "    num = 1\n",
    "\n",
    "    for i, line in enumerate(l):\n",
    "        # read in the raw data from the label txt file\n",
    "        content = line.split()\n",
    "        c, ctr_x, ctr_y, w, h = content[0:5]\n",
    "\n",
    "        ctr_x = float(ctr_x)\n",
    "        ctr_y = float(ctr_y)\n",
    "        w = float(w)\n",
    "        h = float(h)\n",
    "\n",
    "        # store the actual size information\n",
    "        x = xe * ctr_x\n",
    "        y = ye * ctr_y\n",
    "\n",
    "        width = w * xe\n",
    "        height = h * ye\n",
    "\n",
    "        # find the actual predicted box\n",
    "        start_x = x - (width / 2)\n",
    "        start_y = y - (height / 2)\n",
    "\n",
    "        sx = int(start_x)\n",
    "        ww = int(width)\n",
    "\n",
    "        sy = int(start_y)\n",
    "        hh = int(height)\n",
    "\n",
    "        shoes_obj = img[sy:sy + hh + 10, sx - 15:sx + ww + 15]\n",
    "\n",
    "        if shoes_obj.size == 0:\n",
    "            print(f\"Empty shoes object in line {i}\")\n",
    "            continue\n",
    "\n",
    "        num_str = str(num)\n",
    "        os.chdir(shoes_crop)\n",
    "\n",
    "        path_name = f_name + num_str + '.jpg'\n",
    "        cv2.imwrite(path_name, shoes_obj)\n",
    "\n",
    "        # file that are saved in this part are name (1)-1_1.JPG picture 1 person 1 side 1\n",
    "        # sub_pers_name are the one in the () so we will see\n",
    "        # f_name are (1)-1 #key = (1)-1\n",
    "\n",
    "        # get the sub_pers_name\n",
    "        dn = f_name.rpartition('-')\n",
    "\n",
    "        # num is the side\n",
    "        sub_pers_name = 'person' + dn[2] + '-' + 'side' + num_str  # person1-side1\n",
    "        sub_dict = {sub_pers_name: [[sx - 15, sy], [sx + ww + 15, sy], [sx + ww + 15, sy + hh + 10], [sx - 15, sy + hh + 10]]}\n",
    "\n",
    "        hey = c_d[dn[0]]\n",
    "        hey.append(sub_dict)\n",
    "\n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_fld = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in os.listdir(exp2_txt_file):\n",
    "  if (i.endswith('txt')):\n",
    "    f = i.rpartition(\".\")\n",
    "    f_jpg = os.path.join(original_file, f[0] + '.jpg') \n",
    "    f_name = f[0]\n",
    "\n",
    "    os.chdir(exp2_txt_file)\n",
    "    txt = open(i, 'r')\n",
    "    lines = txt.readlines() #lines is a list so you can pop it \n",
    "\n",
    "    if len(lines) != 2:\n",
    "      print(lines)\n",
    "      conf_list = []\n",
    "      popped_list = []\n",
    "      for l in lines:\n",
    "        y = l.rpartition(' ')\n",
    "        conf = y[2]\n",
    "        conf = conf.rpartition('\\n')\n",
    "        conf_list.append(float(conf[0]))\n",
    "\n",
    "      while len(conf_list) != 2 and conf_list:  # ตรวจสอบว่า list ไม่ว่าง\n",
    "        popped_list.append(min(conf_list))\n",
    "        conf_list.remove(min(conf_list))\n",
    "\n",
    "      while len(lines) != len(conf_list):\n",
    "        for l in lines:\n",
    "          y = l.rpartition(' ')\n",
    "          conf = y[2]\n",
    "          conf = conf.rpartition('\\n')\n",
    "    \n",
    "          if float(conf[0]) in popped_list:\n",
    "            lines.remove(l)\n",
    "    \n",
    "    crop_only_shoes(f_jpg, i, f_name, cooord_dict, lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "lll = [23, 233, 1, 3, 4 , 444444  ]\n",
    "print(min(lll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in cooord_dict.keys():\n",
    "#     if not bool(cooord_dict[i]):\n",
    "#         cooord_dict.pop(i)\n",
    "\n",
    "\n",
    "keys_to_remove = []\n",
    "for i in cooord_dict.keys():\n",
    "    if not bool(cooord_dict[i]):\n",
    "        keys_to_remove.append(i)\n",
    "\n",
    "for key in keys_to_remove:\n",
    "    cooord_dict.pop(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': [{'person-2': [[144, 133], [360, 133], [360, 701], [144, 701]]}, {'person2_-side1': [[9, 93], [78, 93], [78, 177], [9, 177]]}, {'person2_-side2': [[54, 133], [147, 133], [147, 191], [54, 191]]}]}\n"
     ]
    }
   ],
   "source": [
    "print(cooord_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop'\n",
    "\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     if filename.endswith('_2.jpg'):\n",
    "#         file_path = os.path.join(folder_path, filename)\n",
    "#         os.remove(file_path)\n",
    "#         print(f'ลบไฟล์: {filename}')\n",
    "\n",
    "# print('เสร็จสิ้นการลบไฟล์')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION 2.0 -----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(real)\n",
    "# !mkdir Shoes-crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shoes_crop = 'F:\\\\intern\\\\model_shoes_detection\\\\Detect running shoes\\\\shoe detection\\\\Real_1\\\\Shoes-crop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp2_txt_file = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\yolov5\\yolov5\\runs\\detect\\exp2\\labels'\n",
    "# original_file = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes'\n",
    "\n",
    "# def crop_only_shoes(img_file, txt_file, f_name, c_d, l, shoes_crop):\n",
    "#     # Get the dimensions of the image\n",
    "#     img = cv2.imread(img_file)\n",
    "#     xe, ye = img.shape[1], img.shape[0]\n",
    "\n",
    "#     f_name = f_name + '_'\n",
    "#     num = 1\n",
    "\n",
    "#     for i, line in enumerate(l):\n",
    "#         # read in the raw data from the label txt file\n",
    "#         content = line.split()\n",
    "#         c, ctr_x, ctr_y, w, h = content[0:5]\n",
    "\n",
    "#         ctr_x = float(ctr_x)\n",
    "#         ctr_y = float(ctr_y)\n",
    "#         w = float(w)\n",
    "#         h = float(h)\n",
    "\n",
    "#         # store the actual size information\n",
    "#         x = xe * ctr_x\n",
    "#         y = ye * ctr_y\n",
    "\n",
    "#         width = w * xe\n",
    "#         height = h * ye\n",
    "\n",
    "#         # find the actual predicted box\n",
    "#         start_x = x - (width / 2)\n",
    "#         start_y = y - (height / 2)\n",
    "\n",
    "#         sx = int(start_x)\n",
    "#         ww = int(width)\n",
    "\n",
    "#         sy = int(start_y)\n",
    "#         hh = int(height)\n",
    "\n",
    "#         # Check if the shoe bounding box is on the left side of the image\n",
    "#         if ctr_x < 0.5:\n",
    "#             side = 'left'\n",
    "#             sx = max(0, sx)  # Ensure the x-coordinate does not go below 0\n",
    "#         else:\n",
    "#             # Skip the right side bounding box\n",
    "#             continue\n",
    "\n",
    "#         # Crop only the shoe on the specified side\n",
    "\n",
    "#         shoes_obj = img[sy:sy + hh, sx:sx + ww]\n",
    "\n",
    "#         if shoes_obj.size == 0:\n",
    "#             print(f\"Empty shoes object in line {i}\")\n",
    "#             continue\n",
    "    \n",
    "#         num_str = str(num)\n",
    "        \n",
    "#         # Remove \"left\" from the filename if it's on the left side\n",
    "#         if side == 'left':\n",
    "#             num_str = num_str.replace('_left', '')\n",
    "    \n",
    "#         path_name = os.path.join(shoes_crop, f_name + num_str + '.jpg')\n",
    "#         cv2.imwrite(path_name, shoes_obj)\n",
    "    \n",
    "#         sub_pers_name = 'person' + f_name + '_' + 'side' + num_str\n",
    "#         sub_dict = {sub_pers_name: [[sx, sy], [sx + ww, sy], [sx + ww, sy + hh], [sx, sy + hh]]}\n",
    "    \n",
    "#         if f_name not in c_d:\n",
    "#             c_d[f_name] = []\n",
    "    \n",
    "#         c_d[f_name].append(sub_dict)\n",
    "    \n",
    "#         num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shoes_fld = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in os.listdir(exp2_txt_file):\n",
    "#     if i.endswith('txt'):\n",
    "#         f = i.rpartition(\".\")\n",
    "#         f_jpg = os.path.join(original_file, f[0] + '.jpg') \n",
    "#         f_name = f[0]\n",
    "\n",
    "#         os.chdir(exp2_txt_file)\n",
    "#         txt = open(i, 'r')\n",
    "#         lines = txt.readlines()\n",
    "\n",
    "#         if len(lines) != 2:\n",
    "#             conf_list = []\n",
    "#             popped_list = []\n",
    "#             for l in lines:\n",
    "#                 y = l.rpartition(' ')\n",
    "#                 conf = y[2]\n",
    "#                 conf = conf.rpartition('\\n')\n",
    "#                 conf_list.append(float(conf[0]))\n",
    "\n",
    "#             while len(conf_list) != 2 and conf_list:\n",
    "#                 popped_list.append(min(conf_list))\n",
    "#                 conf_list.remove(min(conf_list))\n",
    "\n",
    "#             while len(lines) != len(conf_list):\n",
    "#                 for l in lines:\n",
    "#                     y = l.rpartition(' ')\n",
    "#                     conf = y[2]\n",
    "#                     conf = conf.rpartition('\\n')\n",
    "\n",
    "#                     if float(conf[0]) in popped_list:\n",
    "#                         lines.remove(l)\n",
    "\n",
    "#         crop_only_shoes(f_jpg, i, f_name, cooord_dict, lines, shoes_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lll = [23, 233, 1, 3, 4 , 444444  ]\n",
    "# print(min(lll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in cooord_dict.keys():\n",
    "#     if not bool(cooord_dict[i]):\n",
    "#         cooord_dict.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cooord_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET DAA BIPPPPPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(yolov5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Person\\1-2.jpg: 640x256 1 Bip, 611.7ms\n",
      "Speed: 1.0ms preprocess, 611.7ms inference, 245.1ms postprocess per image at shape (1, 3, 640, 256)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "1 label saved to runs\\detect\\predict\\labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'Bip'}\n",
       " obb: None\n",
       " orig_img: array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8)\n",
       " orig_shape: (568, 216)\n",
       " path: 'D:\\\\SWE62-363 Seminar for software Engineering\\\\Detect running shoes\\\\shoe detection\\\\Real_1\\\\Person\\\\1-2.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict'\n",
       " speed: {'preprocess': 0.9975433349609375, 'inference': 611.6764545440674, 'postprocess': 245.07522583007812}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO('D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\BIP.pt')\n",
    "model.predict(pers_fld, save = True, save_conf = True, save_txt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file bip1 already exists.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(real)\n",
    "!mkdir bip1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "bip1 = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\bip1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bip_txt_file = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\yolov5\\yolov5\\runs\\detect\\predict\\labels'\n",
    "original_file = pers_fld\n",
    "\n",
    "def crop_to_bip(img_file, txt_file, f_name):\n",
    "  key = f_name\n",
    "  f_name = f_name + '_'\n",
    "\n",
    "  os.chdir(bip_txt_file)\n",
    "  f = open(txt_file, 'r')\n",
    "  lines = f.readlines()\n",
    "  num = 1\n",
    "\n",
    "  os.chdir(original_file)\n",
    "  img = cv2.imread(img_file)\n",
    "\n",
    "  ye,xe = img.shape[0], img.shape[1] #coordinate of the image\n",
    "\n",
    "  xe = float(xe)\n",
    "  ye = float(ye)\n",
    "\n",
    "  for i in lines:\n",
    "    # read in the raw data from the label txt file\n",
    "    content = i.split()\n",
    "    c, ctr_x, ctr_y, w, h = content[0:5]\n",
    "    ctr_x = float(ctr_x)\n",
    "    ctr_y = float(ctr_y)\n",
    "    w = float(w)\n",
    "    h = float(h)\n",
    "    #f.close() # ??\n",
    "\n",
    "    # store the actual size information\n",
    "    x = xe * ctr_x\n",
    "    y = ye * ctr_y\n",
    "\n",
    "    width = w * xe\n",
    "    height = h * ye\n",
    "\n",
    "    # find the actual predicted box\n",
    "    start_x = x - (width/2)\n",
    "    start_y = y - (height/2)\n",
    "\n",
    "    sx = int(start_x)\n",
    "    ww = int(width)\n",
    "\n",
    "    sy = int(start_y)\n",
    "    hh = int(height)\n",
    "\n",
    "    shoes_obj = img[sy:sy+hh+10, sx-15:sx+ww+15]\n",
    "\n",
    "    if shoes_obj.size == 0:\n",
    "      #bio_dict.pop(key)\n",
    "      print(img_file)\n",
    "      continue\n",
    "\n",
    "    num = str(num)\n",
    "\n",
    "    os.chdir(bip1)\n",
    "    path_name = f_name + num + '.jpg'\n",
    "    cv2.imwrite(path_name, shoes_obj)\n",
    "\n",
    "    num = int(num)\n",
    "    num = num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir(bip_txt_file):\n",
    "  if (i.endswith('txt')):\n",
    "    f = i.rpartition(\".\")\n",
    "    f_jpg = f[0] + '.jpg'\n",
    "    f_name = f[0]\n",
    "\n",
    "    crop_to_bip(f_jpg, i, f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET DAA NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(yolov5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\bip1\\1-2_1.jpg: 640x480 1 2, 963.8ms\n",
      "Speed: 2.0ms preprocess, 963.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "1 label saved to runs\\detect\\predict2\\labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9'}\n",
       " obb: None\n",
       " orig_img: array([[[178,  18,   0],\n",
       "         [175,  17,   0],\n",
       "         [176,  19,   3],\n",
       "         ...,\n",
       "         [ 28,  20,  31],\n",
       "         [ 35,  27,  38],\n",
       "         [ 40,  30,  43]],\n",
       " \n",
       "        [[179,  19,   1],\n",
       "         [175,  17,   0],\n",
       "         [175,  18,   2],\n",
       "         ...,\n",
       "         [  9,   4,  13],\n",
       "         [ 14,   6,  16],\n",
       "         [ 15,   7,  18]],\n",
       " \n",
       "        [[179,  19,   1],\n",
       "         [175,  17,   0],\n",
       "         [173,  16,   0],\n",
       "         ...,\n",
       "         [  0,   0,   4],\n",
       "         [  3,   0,   5],\n",
       "         [  4,   0,   6]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255,  42,  12],\n",
       "         [255,  42,   9],\n",
       "         [250,  39,   5],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        [[255,  44,  13],\n",
       "         [255,  44,  10],\n",
       "         [251,  42,   8],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        [[254,  45,  13],\n",
       "         [255,  46,  12],\n",
       "         [252,  46,  11],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]]], dtype=uint8)\n",
       " orig_shape: (85, 61)\n",
       " path: 'D:\\\\SWE62-363 Seminar for software Engineering\\\\Detect running shoes\\\\shoe detection\\\\Real_1\\\\bip1\\\\1-2_1.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict2'\n",
       " speed: {'preprocess': 1.9962787628173828, 'inference': 963.7789726257324, 'postprocess': 1.421213150024414}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO('D:\\\\SWE62-363 Seminar for software Engineering\\\\Detect running shoes\\\\number.pt')\n",
    "model.predict(bip1, save = True, save_conf = True, save_txt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "nio_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir(pers_fld):\n",
    "    if i.endswith('jpg'):\n",
    "        r = i.partition('.jpg')\n",
    "        nio_dict[r[0]] = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_txt_fld = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\yolov5\\yolov5\\runs\\detect\\predict2\\labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir(num_txt_fld):\n",
    "    if i.endswith('txt'):\n",
    "        file_name = i.partition('_')\n",
    "        os.chdir(num_txt_fld)\n",
    "        f = open(i, 'r')\n",
    "        lines = f.readlines()\n",
    "\n",
    "        class_dict = {}\n",
    "        coord_dict = {}\n",
    "        conf_dict = {}\n",
    "        just_to_pop = {}\n",
    "        num = int(0)\n",
    "\n",
    "        for j in lines:\n",
    "            content = j.split()\n",
    "            num = str(num)\n",
    "\n",
    "            class_dict[num] = str(content[0])\n",
    "            coord_dict[num] = float(content[1])\n",
    "            conf_dict[num] = float(content[5])\n",
    "            just_to_pop[num] = ('HI')\n",
    "\n",
    "            num = int(num)\n",
    "            num+=1\n",
    "        \n",
    "        min_conf = float(1)\n",
    "\n",
    "        while len(conf_dict) > 5: #check the amount to not excedd 5\n",
    "            for c in conf_dict:\n",
    "                new_min = conf_dict[c]\n",
    "                if new_min < min_conf:\n",
    "                    min_conf = new_min\n",
    "                    counter = c\n",
    "\n",
    "            class_dict.pop(c)\n",
    "            coord_dict.pop(c)\n",
    "            conf_dict.pop(c)\n",
    "            just_to_pop.pop(c)\n",
    "\n",
    "        dict(sorted(coord_dict.items(), key=lambda item: item[1]))\n",
    "\n",
    "        same_coord = float(2)\n",
    "        for cd in coord_dict: # check if it's the same coord or not \n",
    "            coord_value = float(round(coord_dict[cd], 2))\n",
    "        \n",
    "            if coord_value == same_coord:\n",
    "                cd = int(cd)\n",
    "                cd_ong = cd-1\n",
    "                cd_ong = str(cd)\n",
    "                cd = str(cd)\n",
    "            \n",
    "                cd_2 = float(conf_dict[cd])\n",
    "                cd_1 = float(conf_dict[cd_ong])\n",
    "                \n",
    "                if cd_2 > cd_1:\n",
    "                    just_to_pop.pop(cd_ong)\n",
    "                else:\n",
    "                    just_to_pop.pop(cd)\n",
    "            \n",
    "            same_coord = coord_value\n",
    "\n",
    "            # 1: 8.7, 2:8.7, 3:8.7\n",
    "            # 1: 98, 93, 99\n",
    "\n",
    "        if len(just_to_pop) != len(coord_dict):\n",
    "            for n in conf_dict:\n",
    "                if n not in just_to_pop:\n",
    "                    class_dict.pop(n)\n",
    "                    coord_dict.pop(n)\n",
    "\n",
    "        done = ''\n",
    "\n",
    "        for i in class_dict:\n",
    "            done += str(class_dict[min(coord_dict, key=coord_dict.get)])\n",
    "            coord_dict.pop(min(coord_dict, key=coord_dict.get))\n",
    "\n",
    "        if len(done) <= 2:\n",
    "            nio_dict[file_name[0]] = '-'\n",
    "        else:\n",
    "            nio_dict[file_name[0]] = done \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1-2': '-'}\n"
     ]
    }
   ],
   "source": [
    "print(nio_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nope #####\n",
    "####for i in nio_dict:\n",
    "####    bio_dict[i].append(nio_dict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLassification TIME + DA brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: py-cpuinfo in d:\\anaconda\\lib\\site-packages (9.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip3 install py-cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_fld = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(yolov5)\n",
    "folder = crop_fld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('D:\\\\SWE62-363 Seminar for software Engineering\\\\Detect running shoes\\\\best_epochxi_200.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/2 D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop\\1-2_1.jpg: 224x224 Saucony 0.99, Adidas 0.01, Nike 0.00, New Balance 0.00, Asics 0.00, 180.2ms\n",
      "image 2/2 D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop\\1-2_2.jpg: 224x224 Saucony 1.00, Adidas 0.00, Asics 0.00, Nike 0.00, New Balance 0.00, 153.9ms\n",
      "Speed: 1.5ms preprocess, 167.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict\u001b[0m\n",
      "2 labels saved to runs\\classify\\predict\\labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: None\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'Adidas', 1: 'Asics', 2: 'Hoka', 3: 'New Balance', 4: 'Nike', 5: 'Saucony'}\n",
       " obb: None\n",
       " orig_img: array([[[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 1,  1,  1]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [13,  3,  3],\n",
       "         [14,  7,  4],\n",
       "         [19, 10,  7]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 9,  1,  2],\n",
       "         [ 6,  1,  0],\n",
       "         [ 8,  1,  0]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 8,  2,  3],\n",
       "         [ 8,  3,  2],\n",
       "         [ 8,  3,  2]]], dtype=uint8)\n",
       " orig_shape: (84, 69)\n",
       " path: 'D:\\\\SWE62-363 Seminar for software Engineering\\\\Detect running shoes\\\\shoe detection\\\\Real_1\\\\Shoes-crop\\\\1-2_1.jpg'\n",
       " probs: ultralytics.engine.results.Probs object\n",
       " save_dir: 'runs\\\\classify\\\\predict'\n",
       " speed: {'preprocess': 1.9936561584472656, 'inference': 180.206298828125, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: None\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'Adidas', 1: 'Asics', 2: 'Hoka', 3: 'New Balance', 4: 'Nike', 5: 'Saucony'}\n",
       " obb: None\n",
       " orig_img: array([[[122, 119, 245],\n",
       "         [117, 111, 242],\n",
       "         [ 99,  83, 225],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        [[132, 128, 254],\n",
       "         [117, 109, 240],\n",
       "         [ 79,  63, 204],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        [[109, 101, 231],\n",
       "         [ 86,  75, 207],\n",
       "         [100,  83, 224],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]]], dtype=uint8)\n",
       " orig_shape: (57, 93)\n",
       " path: 'D:\\\\SWE62-363 Seminar for software Engineering\\\\Detect running shoes\\\\shoe detection\\\\Real_1\\\\Shoes-crop\\\\1-2_2.jpg'\n",
       " probs: ultralytics.engine.results.Probs object\n",
       " save_dir: 'runs\\\\classify\\\\predict'\n",
       " speed: {'preprocess': 0.9613037109375, 'inference': 153.94926071166992, 'postprocess': 0.0}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(folder, save = True, save_conf = True, save_txt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/2 D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop\\1-2_1.jpg: 224x224 Adidas 0.78, Saucony 0.14, Nike 0.07, Asics 0.01, New Balance 0.00, 138.2ms\n",
      "image 2/2 D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop\\1-2_2.jpg: 224x224 Saucony 0.85, Nike 0.08, Asics 0.03, Adidas 0.03, Hoka 0.00, 145.1ms\n",
      "Speed: 0.5ms preprocess, 141.6ms inference, 0.5ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n",
      "2 labels saved to runs\\classify\\predict2\\labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: None\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'Adidas', 1: 'Asics', 2: 'Hoka', 3: 'New Balance', 4: 'Nike', 5: 'Saucony'}\n",
       " obb: None\n",
       " orig_img: array([[[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 1,  1,  1]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [13,  3,  3],\n",
       "         [14,  7,  4],\n",
       "         [19, 10,  7]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 9,  1,  2],\n",
       "         [ 6,  1,  0],\n",
       "         [ 8,  1,  0]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [ 8,  2,  3],\n",
       "         [ 8,  3,  2],\n",
       "         [ 8,  3,  2]]], dtype=uint8)\n",
       " orig_shape: (84, 69)\n",
       " path: 'D:\\\\SWE62-363 Seminar for software Engineering\\\\Detect running shoes\\\\shoe detection\\\\Real_1\\\\Shoes-crop\\\\1-2_1.jpg'\n",
       " probs: ultralytics.engine.results.Probs object\n",
       " save_dir: 'runs\\\\classify\\\\predict2'\n",
       " speed: {'preprocess': 0.9963512420654297, 'inference': 138.1542682647705, 'postprocess': 0.9963512420654297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: None\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'Adidas', 1: 'Asics', 2: 'Hoka', 3: 'New Balance', 4: 'Nike', 5: 'Saucony'}\n",
       " obb: None\n",
       " orig_img: array([[[122, 119, 245],\n",
       "         [117, 111, 242],\n",
       "         [ 99,  83, 225],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        [[132, 128, 254],\n",
       "         [117, 109, 240],\n",
       "         [ 79,  63, 204],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        [[109, 101, 231],\n",
       "         [ 86,  75, 207],\n",
       "         [100,  83, 224],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]]], dtype=uint8)\n",
       " orig_shape: (57, 93)\n",
       " path: 'D:\\\\SWE62-363 Seminar for software Engineering\\\\Detect running shoes\\\\shoe detection\\\\Real_1\\\\Shoes-crop\\\\1-2_2.jpg'\n",
       " probs: ultralytics.engine.results.Probs object\n",
       " save_dir: 'runs\\\\classify\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 145.07269859313965, 'postprocess': 0.0}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO('D:\\\\SWE62-363 Seminar for software Engineering\\\\Detect running shoes\\\\best.pt')\n",
    "model.predict(folder, save = True, save_conf = True, save_txt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_dict = {}\n",
    "dict_class = model.names\n",
    "\n",
    "for i in os.listdir(crop_fld):\n",
    "  if i.lower().endswith('jpg'):\n",
    "    os.chdir(crop_fld)\n",
    "    file_name = i.rpartition(\"_\")\n",
    "\n",
    "    file_name_dict[file_name[0]] = {}\n",
    "    pls = file_name_dict[file_name[0]]\n",
    "\n",
    "    for t in dict_class:\n",
    "      pls[dict_class[t]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for fun\n",
    "# create a dict that the key is the number and the value is the list of all the file name that is that number\n",
    "\n",
    "dict_file_num = {}\n",
    "\n",
    "for i in nio_dict:\n",
    "    if nio_dict[i] != '-':\n",
    "        dict_file_num[nio_dict[i]] = []\n",
    "\n",
    "for i in nio_dict:\n",
    "    if nio_dict[i] != '-':\n",
    "        dict_file_num[nio_dict[i]].append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1-2': '-'}\n"
     ]
    }
   ],
   "source": [
    "print(nio_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(dict_file_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for fun\n",
    "#NAH\n",
    "#file_name_dict has the raw value so we can try adding everything together in this dict so.... \n",
    "nio_dict_ver2 = {}\n",
    "for i in dict_file_num:\n",
    "    nio_dict_ver2[i] = {}\n",
    "    pls = nio_dict_ver2[i]\n",
    "\n",
    "    for n in dict_class:\n",
    "        pls[dict_class[n]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key '-' does not exist in nio_dict_ver2\n"
     ]
    }
   ],
   "source": [
    "result = nio_dict_ver2.get('-', \"Key '-' does not exist in nio_dict_ver2\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch222_lbd = 'D:\\\\SWE62-363 Seminar for software Engineering\\\\Detect running shoes\\\\yolov5\\\\yolov5\\\\runs\\\\classify\\\\predict\\\\labels'\n",
    "best_lbd = 'D:\\\\SWE62-363 Seminar for software Engineering\\\\Detect running shoes\\\\yolov5\\\\yolov5\\\\runs\\\\classify\\\\predict2\\\\labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dict(lbd, file_name_dict):\n",
    "  for i in os.listdir(lbd):\n",
    "    os.chdir(lbd)\n",
    "  \n",
    "    if (i.endswith('txt')):\n",
    "      \n",
    "      file_name = i.rpartition('_')\n",
    "      f = open(i, 'r')\n",
    "      lines = f.readlines()\n",
    "\n",
    "      for t in lines:\n",
    "        content = t.split()\n",
    "        if len(content) == 3: \n",
    "            conf_level, n, b = content[0:3]\n",
    "            class_name = n + \" \" + b\n",
    "        else:\n",
    "            conf_level, class_name = content[0:2]\n",
    "    \n",
    "        cl = float(conf_level)\n",
    "        cl = cl*100\n",
    "\n",
    "        this_dict = file_name_dict[file_name[0]]\n",
    "        this_dict[class_name] += cl\n",
    "\n",
    "        for dfn in dict_file_num:\n",
    "           for sub in dict_file_num[dfn]:\n",
    "              if file_name[0] == sub:\n",
    "                td = nio_dict_ver2[dfn]\n",
    "                td[class_name] += cl\n",
    "\n",
    "  return(file_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_dict = add_dict(epoch222_lbd, file_name_dict)\n",
    "file_name_dict = add_dict(best_lbd, file_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key '-' does not exist in nio_dict_ver2\n"
     ]
    }
   ],
   "source": [
    "result = nio_dict_ver2.get('-', \"Key '-' does not exist in nio_dict_ver2\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key not found\n"
     ]
    }
   ],
   "source": [
    "result = file_name_dict.get('(524)-1', 'Key not found')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_dict = {}\n",
    "for i in file_name_dict:\n",
    "  if max(file_name_dict[i].values()) <= 150:\n",
    "    win_dict[i] = \"-\"\n",
    "\n",
    "  else:\n",
    "    win_dict[i] = max(file_name_dict[i], key = file_name_dict[i].get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1-2': 'Saucony'}\n"
     ]
    }
   ],
   "source": [
    "print(win_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nio_dict: {'(678)-2': '30189', '(687)-1': '5634', '(605)-2': '20364'}\n",
    "# file_name_dict: {'(647)-1': {'Adidas': 0.0, 'Asics': 0.0, 'Hoka': 392.0, 'New Balance': 2.0, 'Nike': 4.0, 'Saucony': 2.0}}\n",
    "# nio_dict_ver2: {'30189': {'Adidas': 157.0, 'Asics': 2.0, 'Hoka': 184.0, 'New Balance': 4.0, 'Nike': 1425.0, 'Saucony': 25.0}}\n",
    "# dict_file_num: {'30189': ['(678)-2', '(594)-2', '(524)-1', '(509)-2'}\n",
    "# win_dict: {'(647)-1': 'Hoka', '(696)-1': 'Nike', '(663)-2': 'Asics'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in win_dict:\n",
    "    for dfn in dict_file_num:\n",
    "        if len(dict_file_num[dfn]) >= 2:\n",
    "            for sub in dict_file_num[dfn]:\n",
    "                if sub == i:\n",
    "                    if win_dict[sub] != '-':\n",
    "                        win_dict[sub] = max(nio_dict_ver2[dfn], key = nio_dict_ver2[dfn].get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in win_dict:\n",
    "#     bio_dict[i].append(win_dict[i])\n",
    "\n",
    "for i in win_dict:\n",
    "    if i in bio_dict:\n",
    "        # Append the values from win_dict[i] to the existing list in bio_dict[i]\n",
    "        bio_dict[i].append(win_dict[i])\n",
    "    else:\n",
    "        # If the key is not present, add it to the dictionary with a list containing win_dict[i]\n",
    "        bio_dict[i] = [win_dict[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1-2': ['Male', 'Saucony']}\n"
     ]
    }
   ],
   "source": [
    "print(bio_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in list(bio_dict):\n",
    "  value_list = bio_dict[g]\n",
    "  if '-' in value_list or len(value_list) == 1: # change to whatever it should be but im not putting color in rn\n",
    "    bio_dict.pop(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bio_dict\n",
    "df = pd.DataFrame.from_dict(data, orient='index', columns=['Gender', 'Brand'])\n",
    "df.to_excel('after.xlsx', index_label='Crop_File')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = cooord_dict\n",
    "df = pd.DataFrame.from_dict(data, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('after.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numeric(crop_file):\n",
    "    parts = crop_file.split('-')\n",
    "    if len(parts) > 1:\n",
    "        return int(parts[0].zfill(3) + parts[-1])\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Numeric'] = df['Crop_File'].apply(extract_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by='Numeric', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.drop(columns=['Numeric'], inplace=True)\n",
    "df_sorted.to_excel('after.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# อ่านข้อมูลจากไฟล์ after2.xlsx\n",
    "after2_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\after.xlsx'\n",
    "df_after2 = pd.read_excel(after2_path)\n",
    "\n",
    "\n",
    "directory_path_txt = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\yolov5\\yolov5\\runs\\detect\\exp\\labels'\n",
    "\n",
    "data = []\n",
    "\n",
    "files = sorted([file for file in os.listdir(directory_path_txt) if file.endswith(\".txt\")], key=lambda x: int(x.split('.')[0].split('-')[0]))\n",
    "\n",
    "for filename_txt in files:\n",
    "    file_path_txt = os.path.join(directory_path_txt, filename_txt)\n",
    "    with open(file_path_txt, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        selected_lines = [line.split() for line in lines if line.startswith('0')]\n",
    "        if selected_lines:\n",
    "            parts = selected_lines[0]  # เลือกบรรทัดแรกที่มี ID เป็น 0\n",
    "            x_coord = float(parts[1])\n",
    "            y_coord = float(parts[2])\n",
    "            corresponding_xlsx = f\"{filename_txt.split('.')[0]}-2\"\n",
    "            data.append({\n",
    "                'Crop_File': corresponding_xlsx,\n",
    "                'person coordinate x': x_coord,\n",
    "                'person coordinate y': y_coord\n",
    "            })\n",
    "\n",
    "df_txt = pd.DataFrame(data)\n",
    "\n",
    "# แบ่งค่าพิกัด x และ y เป็นคอลัมน์แยก\n",
    "df_txt['index'] = df_txt.groupby('Crop_File').cumcount() + 1\n",
    "df_txt = df_txt.set_index(['Crop_File', 'index']).unstack().sort_index(axis=1, level=1)\n",
    "df_txt.columns = [f'{col[0]}_{col[1]}' for col in df_txt.columns]\n",
    "\n",
    "# ผสมข้อมูลจาก after2.xlsx และข้อมูลจาก .txt โดยใช้ชื่อไฟล์เป็น key\n",
    "merged_df = pd.merge(df_after2, df_txt, left_on='Crop_File', right_on='Crop_File', how='left')\n",
    "\n",
    "\n",
    "result_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\after.xlsx'\n",
    "merged_df.to_excel(result_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ทำเป็นไฟล์ .json\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # อ่านไฟล์ Excel\n",
    "# file_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\after.xlsx'\n",
    "# df = pd.read_excel(file_path)\n",
    "\n",
    "# # แปลงข้อมูล DataFrame เป็น JSON\n",
    "# json_data = df.to_json(orient='records')\n",
    "\n",
    "# # กำหนดที่อยู่ของไฟล์ JSON ที่ต้องการเขียน\n",
    "# output_file_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\output.json'\n",
    "\n",
    "# # เขียนข้อมูล JSON ลงในไฟล์\n",
    "# with open(output_file_path, 'w') as file:\n",
    "#     file.write(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import requests\n",
    "\n",
    "# input_folder = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Person-crop'\n",
    "# output_folder = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop-dlgb'\n",
    "\n",
    "\n",
    "# api_url = 'https://api.pixian.ai/api/v2/remove-background'\n",
    "# headers = {\n",
    "#     'Authorization': 'Basic cHg0cjV6aXpwdHJ2cHBtOnZtcTBxcnZkb3Y4cWtsYjJwcWo4anA2ZjZzZThjM3AxMDZlanVnN2g2OHY0azB0azJkaW4='\n",
    "# }\n",
    "\n",
    "# # หากโฟลเดอร์ปลายทางไม่ได้ถูกสร้างไว้ ให้สร้างโฟลเดอร์นี้\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "\n",
    "# for filename in os.listdir(input_folder):\n",
    "\n",
    "#     if filename.endswith('.jpg'):\n",
    "#         input_filepath = os.path.join(input_folder, filename)\n",
    "#         output_filepath = os.path.join(output_folder, filename)\n",
    "\n",
    "#         # ทำการลบพื้นหลังของรูป\n",
    "#         response = requests.post(\n",
    "#             api_url,\n",
    "#             files={'image': open(input_filepath, 'rb')},\n",
    "#             data={},\n",
    "#             headers=headers\n",
    "#         )\n",
    "\n",
    "#         # บันทึกรูปที่ผ่านการลบพื้นหลัง\n",
    "#         if response.status_code == requests.codes.ok:\n",
    "#             # เปลี่ยนจาก .jpg เป็น .png ในชื่อไฟล์\n",
    "#             output_filepath = os.path.join(output_folder, os.path.splitext(filename)[0] + '.png')\n",
    "            \n",
    "#             with open(output_filepath, 'wb') as out:\n",
    "#                 out.write(response.content)\n",
    "#             print(f\"Removed background for {filename} and saved to {output_filepath}\")\n",
    "#         else:\n",
    "#             print(f\"Error removing background for {filename}: {response.status_code}, {response.text}\")\n",
    "\n",
    "# print(\"Processing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# folder_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop-dlgb'\n",
    "\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     if filename.endswith('_2.png'):\n",
    "#         file_path = os.path.join(folder_path, filename)\n",
    "#         os.remove(file_path)\n",
    "#         print(f'ลบไฟล์: {filename}')\n",
    "\n",
    "# print('เสร็จสิ้นการลบไฟล์')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import colorsys\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def calculate_distance_hsv_weighted(color1, color2):\n",
    "    h1, s1, v1 = color1\n",
    "    h2, s2, v2 = color2\n",
    "\n",
    "    # Calculate circular distance for Hue, Saturation, and Value\n",
    "    hue_distance = min(abs(h1 - h2), 360 - abs(h1 - h2))\n",
    "    saturation_distance = abs(s1 - s2)\n",
    "    value_distance = abs(v1 - v2)\n",
    "\n",
    "    # Define weights for each component\n",
    "    hue_weight = 1.0  # You can experiment with different weights\n",
    "    saturation_weight = 1.0\n",
    "    value_weight_white = 2.0  # Higher weight for white color\n",
    "\n",
    "    # Normalize distances\n",
    "    max_distance = 360 # Maximum possible distance for hue\n",
    "    normalized_hue_distance = hue_distance / max_distance\n",
    "    normalized_saturation_distance = saturation_distance\n",
    "    normalized_value_distance = value_distance / value_weight_white  # Divide by the weight for white color\n",
    "\n",
    "    # Calculate weighted distance\n",
    "    weighted_distance = (\n",
    "        hue_weight * normalized_hue_distance +\n",
    "        saturation_weight * normalized_saturation_distance +\n",
    "        value_weight_white * normalized_value_distance\n",
    "    )\n",
    "\n",
    "    return weighted_distance\n",
    "\n",
    "def find_closest_color_h(color, colors):\n",
    "    tolerance = 150\n",
    "    min_distance = tolerance\n",
    "    closest_color = None\n",
    "    for color_name, hsv in colors.items():\n",
    "        distance = calculate_distance_hsv_weighted(color, hsv)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_color = color_name\n",
    "    return closest_color\n",
    "\n",
    "# สร้าง DataFrame เพื่อเก็บข้อมูล\n",
    "data = {'Crop_File': [], 'Shoes_Color': []}\n",
    "\n",
    "# # กำหนด path ของโฟลเดอร์\n",
    "folder_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop'\n",
    "\n",
    "# # ลูปทั้งโฟลเดอร์\n",
    "file_list = sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'(\\d+)-(\\d+)_\\d+\\.jpg', x).group(1)))\n",
    "\n",
    "# Loop through the folder\n",
    "for idx, filename in enumerate(file_list):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Perform K-Means clustering\n",
    "        k = 5\n",
    "        reshaped_image = image_rgb.reshape((-1, 3))\n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "        kmeans.fit(reshaped_image)\n",
    "\n",
    "        # Get dominant colors\n",
    "        dominant_colors = kmeans.cluster_centers_.astype(int)\n",
    "\n",
    "        # Count the occurrences of each dominant color\n",
    "        counts = np.bincount(kmeans.labels_)\n",
    "\n",
    "        # Find the index of the dominant color excluding black\n",
    "        non_black_indices = [idx for idx, color in enumerate(dominant_colors) if np.mean(color) > 50]\n",
    "        max_count_index = non_black_indices[np.argmax(counts[non_black_indices])]\n",
    "\n",
    "        # Get the dominant color\n",
    "        dominant_color = dominant_colors[max_count_index]\n",
    "\n",
    "        # Convert dominant color from RGB to HSV\n",
    "        dominant_color_hsv = colorsys.rgb_to_hsv(dominant_color[0]/255.0, dominant_color[1]/255.0, dominant_color[2]/255.0)\n",
    "\n",
    "        # Convert the H value from the range [0, 1] back to [0, 360]\n",
    "        dominant_color_hsv = (dominant_color_hsv[0]*360 , dominant_color_hsv[1], dominant_color_hsv[2])\n",
    "\n",
    "        # เพิ่มค่า V เพื่อทำให้ dominant color สว่างขึ้น\n",
    "        dominant_color_hsv = (dominant_color_hsv[0], dominant_color_hsv[1]+0.1, dominant_color_hsv[2] + 0.1)\n",
    "\n",
    "        # ตรวจสอบว่าค่า V ไม่เกิน 1\n",
    "        dominant_color_hsv = (dominant_color_hsv[0], dominant_color_hsv[1], min(1, dominant_color_hsv[2]))\n",
    "\n",
    "       \n",
    "        # Define predefined colors in HSV with fixed Saturation and Value\n",
    "        colors_hsv = {\n",
    "                    \"Red\": (0, 1.0, 1.0),\n",
    "                    \"Orange\": (20, 1.0, 1.0),\n",
    "                    \"Yellow\": (45, 1.0, 1.0),\n",
    "                    \"Green\": (120, 1.0, 1.0),\n",
    "                    \"Cyan\": (186, 1.0, 1.0),\n",
    "                    \"Blue\": (210, 1.0, 1.0),\n",
    "                    \"Purple\": (295, 1.0, 1.0),\n",
    "                    \"Pink\": (330, 1.0, 1.0),\n",
    "                    \"Pink2\":(315,1.0,1.0),\n",
    "                #     \"Magenta\":(305, 1.0, 1.0),\n",
    "        }\n",
    "\n",
    "        # Check if the dominant color is black based on Saturation (S) and Value (V)\n",
    "        if dominant_color_hsv[1] < 0.45 and dominant_color_hsv[2] < 0.45:\n",
    "            closest_color_h = \"Black\"\n",
    "        # Check if the dominant color is white based on Saturation (S) and Value (V)\n",
    "        elif dominant_color_hsv[1] <= 0.22 and dominant_color_hsv[2] >= 0.97:\n",
    "            closest_color_h = \"White\"\n",
    "\n",
    "        elif dominant_color_hsv[1] <= 0.34 and dominant_color_hsv[2] <= 0.85:\n",
    "            closest_color_h = \"Grey\"\n",
    "        else:\n",
    "            # Find the closest predefined color in H, S, and V\n",
    "            closest_color_h = find_closest_color_h(dominant_color_hsv, colors_hsv)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        # Add data to DataFrame\n",
    "        data['Crop_File'].append(filename)\n",
    "        data['Shoes_Color'].append(closest_color_h)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['NumericPart'] = df['Crop_File'].apply(lambda x: int(re.search(r'(\\d+)-(\\d+)_\\d+\\.jpg', x).group(1)))\n",
    "\n",
    "# Select specific columns from the DataFrame\n",
    "df = df.sort_values(by='NumericPart').drop(columns='NumericPart')\n",
    "\n",
    "# Save to Excel\n",
    "output_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\after2.xlsx'\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "    # Write the entire DataFrame without the 'NumericPart' column\n",
    "    df[['Crop_File']].to_excel(writer, sheet_name='Sheet1', index=False, startcol=0, startrow=0)\n",
    "    \n",
    "    df[['Shoes_Color']].to_excel(writer, sheet_name='Sheet1', index=False, startcol=2, startrow=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openpyxl\n",
    "\n",
    "# workbook = openpyxl.load_workbook('after2.xlsx')\n",
    "# sheet = workbook.active\n",
    "# sheet['B1'] = 'Gender'\n",
    "# sheet['C1'] = 'Brand'\n",
    "\n",
    "# workbook.save('after2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "workbook = openpyxl.load_workbook('after2.xlsx')\n",
    "sheet = workbook.active\n",
    "# sheet['B1'] = 'Gender'\n",
    "sheet['B1'] = 'Brand'\n",
    "\n",
    "workbook.save('after2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read data from after2.xlsx\n",
    "after2_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\after2.xlsx'\n",
    "df_after2 = pd.read_excel(after2_path)\n",
    "\n",
    "# Read data from .txt files\n",
    "directory_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\yolov5\\yolov5\\runs\\detect\\exp2\\labels'\n",
    "\n",
    "data = []\n",
    "\n",
    "files = sorted([file for file in os.listdir(directory_path) if file.endswith(\".txt\")], key=lambda x: int(x.split('-')[0]))\n",
    "\n",
    "for filename in files:\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            parts = line.split()\n",
    "            x_coord = float(parts[1])\n",
    "            y_coord = float(parts[2])\n",
    "\n",
    "            # Create a key based on the common part of the filename\n",
    "            key = filename.split('.')[0]\n",
    "\n",
    "            # Create a dictionary for each line of coordinates\n",
    "            data.append({\n",
    "                'Crop_File': f'{key}_{i+1}.jpg',  # Create unique filenames\n",
    "                'coordinate x': x_coord,\n",
    "                'coordinate y': y_coord\n",
    "            })\n",
    "\n",
    "# Create a DataFrame from the coordinates data\n",
    "df_txt = pd.DataFrame(data)\n",
    "\n",
    "# Reshape the DataFrame to have separate columns for each coordinate (x, y)\n",
    "df_txt['index'] = df_txt.groupby('Crop_File').cumcount() + 1\n",
    "df_txt = df_txt.set_index(['Crop_File', 'index']).unstack().sort_index(axis=1, level=1)\n",
    "df_txt.columns = [f'{col[0]}_{col[1]}' for col in df_txt.columns]\n",
    "\n",
    "# Merge data from after2.xlsx and .txt files based on Crop_File\n",
    "merged_df = pd.merge(df_after2, df_txt, left_on='Crop_File', right_on='Crop_File', how='left')\n",
    "\n",
    "# Save the merged DataFrame to a new Excel file\n",
    "result_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\after2.xlsx'\n",
    "merged_df.to_excel(result_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # อ่านข้อมูลจากไฟล์ Excel\n",
    "# df_after = pd.read_excel('after.xlsx')\n",
    "# df_after2 = pd.read_excel('after2.xlsx')\n",
    "\n",
    "# # สร้าง dictionary จาก df_after โดยให้ Crop_File เป็น key และ Gender, Brand เป็น values\n",
    "# crop_file_dict = df_after.set_index('Crop_File')[['Gender', 'Brand']].to_dict(orient='index')\n",
    "# df_after2 = df_after2.applymap(str)\n",
    "\n",
    "# for index, row in df_after2.iterrows():\n",
    "#     image_name = row['Crop_File'].split('_')[0]\n",
    "#     if image_name in crop_file_dict:\n",
    "#         gender_value = crop_file_dict[image_name]['Gender']\n",
    "#         brand_value = crop_file_dict[image_name]['Brand']\n",
    "#         if pd.notna(gender_value) and gender_value != '':\n",
    "#             df_after2.at[index, 'Gender'] = gender_value\n",
    "#         if pd.notna(brand_value):\n",
    "#             df_after2.at[index, 'Brand'] = brand_value\n",
    "\n",
    "# df_after2.to_excel('after3.xlsx', index=False)\n",
    "# print('Save file after3.xlsx success!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save file after3_brand_and_color.xlsx success!!!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# อ่านข้อมูลจากไฟล์ Excel\n",
    "df_after = pd.read_excel('after.xlsx')\n",
    "df_after2 = pd.read_excel('after2.xlsx')\n",
    "\n",
    "# สร้าง dictionary จาก df_after โดยให้ Crop_File เป็น key และ Gender, Brand เป็น values\n",
    "# crop_file_dict = df_after.set_index('Crop_File')[['Gender', 'Brand']].to_dict(orient='index')\n",
    "crop_file_dict = df_after.set_index('Crop_File')[['Brand']].to_dict(orient='index')\n",
    "\n",
    "df_after2 = df_after2.applymap(str)\n",
    "\n",
    "for index, row in df_after2.iterrows():\n",
    "    image_name = row['Crop_File'].split('_')[0]\n",
    "    if image_name in crop_file_dict:\n",
    "        brand_value = crop_file_dict[image_name]['Brand']\n",
    "        if pd.notna(brand_value):\n",
    "            df_after2.at[index, 'Brand'] = brand_value\n",
    "\n",
    "df_after2.to_excel('after3_brand_and_color.xlsx', index=False)\n",
    "print('Save file after3_brand_and_color.xlsx success!!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save file after4_gender.xlsx success!!!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from Excel files\n",
    "df_after = pd.read_excel('after.xlsx')\n",
    "df_after2 = pd.read_excel('after2.xlsx')\n",
    "\n",
    "# Merge df_after2 with df_after on 'Crop_File'\n",
    "df_merged = pd.merge(df_after2, df_after[['Crop_File', 'person coordinate x_1', 'person coordinate y_1']], on='Crop_File', how='left')\n",
    "\n",
    "# Create a dictionary from df_after using Crop_File as the key and Gender as values\n",
    "crop_file_dict = df_after.set_index('Crop_File')[['Gender', 'person coordinate x_1', 'person coordinate y_1']].to_dict(orient='index')\n",
    "\n",
    "# Apply str conversion to all columns in df_after2\n",
    "df_after2 = df_after2.applymap(str)\n",
    "\n",
    "# Add empty columns 'person coordinate x_1' and 'person coordinate y_1' to df_after2\n",
    "df_after2['person coordinate x_1'] = ''\n",
    "df_after2['person coordinate y_1'] = ''\n",
    "\n",
    "# Check if the columns exist in df_after2 before adding them to the columns list\n",
    "additional_columns = ['person coordinate x_1', 'person coordinate y_1']\n",
    "for col in additional_columns:\n",
    "    if col in df_after2.columns:\n",
    "        df_after2[col] = df_after2[col].astype(str)\n",
    "\n",
    "# Iterate through rows and update 'Gender', 'person coordinate x_1', and 'person coordinate y_1' based on the information from df_after\n",
    "for index, row in df_after2.iterrows():\n",
    "    image_name = row['Crop_File'].split('_')[0]\n",
    "    if image_name in crop_file_dict:\n",
    "        data = crop_file_dict[image_name]\n",
    "        df_after2.at[index, 'Gender'] = data['Gender']\n",
    "        df_after2.at[index, 'person coordinate x_1'] = data['person coordinate x_1']\n",
    "        df_after2.at[index, 'person coordinate y_1'] = data['person coordinate y_1']\n",
    "\n",
    "# Add the columns to the columns list only if they exist\n",
    "columns_list = ['Crop_File', 'Gender'] + [col for col in additional_columns if col in df_after2.columns]\n",
    "\n",
    "# Save the modified DataFrame to a new Excel file\n",
    "df_after2.to_excel('after4_gender.xlsx', index=False, columns=columns_list)\n",
    "print('Save file after4_gender.xlsx success!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in d:\\anaconda\\lib\\site-packages (4.6.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in d:\\anaconda\\lib\\site-packages (from pymongo) (2.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigurationError",
     "evalue": "The DNS query name does not exist: _mongodb._tcp.cluster0.xf2c6og.mongodb.net.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConfigurationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6460/3522036815.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMongoClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mongodb+srv://authachaizzz:1234@cluster0.xf2c6og.mongodb.net/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shoes_detect_database\"\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# เลือกฐานข้อมูลที่ต้องการ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, host, port, document_class, tz_aware, connect, type_registry, **kwargs)\u001b[0m\n\u001b[0;32m    769\u001b[0m                         \u001b[0mkeyword_opts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcased_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"connecttimeoutms\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m                     )\n\u001b[1;32m--> 771\u001b[1;33m                 res = uri_parser.parse_uri(\n\u001b[0m\u001b[0;32m    772\u001b[0m                     \u001b[0mentity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m                     \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pymongo\\uri_parser.py\u001b[0m in \u001b[0;36mparse_uri\u001b[1;34m(uri, default_port, validate, warn, normalize, connect_timeout, srv_service_name, srv_max_hosts)\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mconnect_timeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnect_timeout\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"connectTimeoutMS\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[0mdns_resolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_SrvResolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfqdn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnect_timeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrv_service_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrv_max_hosts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m         \u001b[0mnodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdns_resolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_hosts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m         \u001b[0mdns_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdns_resolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdns_options\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pymongo\\srv_resolver.py\u001b[0m in \u001b[0;36mget_hosts\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_hosts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_srv_response_and_hosts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pymongo\\srv_resolver.py\u001b[0m in \u001b[0;36m_get_srv_response_and_hosts\u001b[1;34m(self, encapsulate_errors)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencapsulate_errors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     ) -> tuple[resolver.Answer, list[tuple[str, Any]]]:\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_resolve_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencapsulate_errors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;31m# Construct address tuples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pymongo\\srv_resolver.py\u001b[0m in \u001b[0;36m_resolve_uri\u001b[1;34m(self, encapsulate_errors)\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[1;31m# Else, raise all errors as ConfigurationError.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConfigurationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConfigurationError\u001b[0m: The DNS query name does not exist: _mongodb._tcp.cluster0.xf2c6og.mongodb.net."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# อ่านข้อมูลจากไฟล์ .xlsx\n",
    "file_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\after3_brand_and_color.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "client = MongoClient(\"mongodb+srv://authachaizzz:1234@cluster0.xf2c6og.mongodb.net/\")\n",
    "db = client[\"shoes_detect_database\"]  # เลือกฐานข้อมูลที่ต้องการ\n",
    "\n",
    "# เลือกคอลเล็กชัน\n",
    "collection = db[\"brand_and_color\"]  \n",
    "\n",
    "# แปลงข้อมูล DataFrame เป็น JSON และเพิ่มข้อมูลไปยังคอลเล็กชันใน MongoDB\n",
    "data = df.to_dict(orient='records')\n",
    "collection.insert_many(data)\n",
    "\n",
    "print(\"Save data brand_and_color to database Success!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save data gender to database Success!!!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# อ่านข้อมูลจากไฟล์ .xlsx\n",
    "file_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\after4_gender.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "client = MongoClient(\"mongodb+srv://authachaizzz:1234@cluster0.xf2c6og.mongodb.net/\")\n",
    "db = client[\"shoes_detect_database\"]  # เลือกฐานข้อมูลที่ต้องการ\n",
    "\n",
    "# เลือกคอลเล็กชัน\n",
    "collection = db[\"gender\"]  \n",
    "\n",
    "# แปลงข้อมูล DataFrame เป็น JSON และเพิ่มข้อมูลไปยังคอลเล็กชันใน MongoDB\n",
    "data = df.to_dict(orient='records')\n",
    "collection.insert_many(data)\n",
    "\n",
    "print(\"Save data gender to database Success!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb+srv://authachaizzz:1234@cluster0.xf2c6og.mongodb.net/\")\n",
    "\n",
    "db = client[\"shoes_detect_database\"]  \n",
    "collection = db[\"brand_and_color\"]  #brand และ สี\n",
    "   \n",
    "data_from_mongo = collection.find({})\n",
    "\n",
    "# แปลงข้อมูลใน MongoDB เป็น DataFrame ด้วย pandas\n",
    "df = pd.DataFrame(list(data_from_mongo))\n",
    "\n",
    "df = df.drop(['_id'], axis=1)\n",
    "\n",
    "file_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\shoes_data_brand_and_color.csv'\n",
    "\n",
    "df.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb+srv://authachaizzz:1234@cluster0.xf2c6og.mongodb.net/\")\n",
    "\n",
    "db = client[\"shoes_detect_database\"]  \n",
    "collection = db[\"gender\"]  #เพศ\n",
    "   \n",
    "data_from_mongo = collection.find({})\n",
    "\n",
    "# แปลงข้อมูลใน MongoDB เป็น DataFrame ด้วย pandas\n",
    "df = pd.DataFrame(list(data_from_mongo))\n",
    "\n",
    "df = df.drop(['_id'], axis=1)\n",
    "\n",
    "file_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\shoes_data_gender.csv'\n",
    "\n",
    "df.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 374 documents\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb+srv://authachaizzz:1234@cluster0.xf2c6og.mongodb.net/\")\n",
    "db = client[\"shoes_detect_database\"]  \n",
    "collection = db[\"brand_and_color\"]  #brand และ สี\n",
    "collection = db[\"gender\"]  #เพศ\n",
    "\n",
    "# ลบข้อมูลทั้งหมดใน collection\n",
    "result = collection.delete_many({})\n",
    "\n",
    "# แสดงจำนวนเอกสารที่ถูกลบ\n",
    "print(f\"Deleted {result.deleted_count} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***********************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***********************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***********************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***********************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***********************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***********************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***********************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import requests\n",
    "\n",
    "# input_folder = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop'\n",
    "# output_folder = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\dlgb'\n",
    "\n",
    "# api_url = 'https://api.pixian.ai/api/v2/remove-background'\n",
    "# headers = {\n",
    "#     'Authorization': 'Basic cHg0cjV6aXpwdHJ2cHBtOnZtcTBxcnZkb3Y4cWtsYjJwcWo4anA2ZjZzZThjM3AxMDZlanVnN2g2OHY0azB0azJkaW4='\n",
    "# }\n",
    "\n",
    "# # หากโฟลเดอร์ปลายทางไม่ได้ถูกสร้างไว้ ให้สร้างโฟลเดอร์นี้\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "\n",
    "# for filename in os.listdir(input_folder):\n",
    "\n",
    "#     if filename.endswith('.jpg'):\n",
    "#         input_filepath = os.path.join(input_folder, filename)\n",
    "#         output_filepath = os.path.join(output_folder, os.path.splitext(filename)[0] + '.png')\n",
    "\n",
    "#         # ทำการลบพื้นหลังของรูป\n",
    "#         response = requests.post(\n",
    "#             api_url,\n",
    "#             files={'image': open(input_filepath, 'rb')},\n",
    "#             data={},\n",
    "#             headers=headers\n",
    "#         )\n",
    "\n",
    "#         # บันทึกรูปที่ผ่านการลบพื้นหลังเป็น .png\n",
    "#         if response.status_code == requests.codes.ok:\n",
    "#             with open(output_filepath, 'wb') as out:\n",
    "#                 out.write(response.content)\n",
    "#             print(f\"Removed background for {filename} and saved to {output_filepath}\")\n",
    "#         else:\n",
    "#             print(f\"Error removing background for {filename}: {response.status_code}, {response.text}\")\n",
    "\n",
    "# print(\"Processing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# def detect_most_common_colors(image_path, num_colors=5):\n",
    "#     # Load image\n",
    "#     img = cv2.imread(image_path)\n",
    "\n",
    "#     # Convert BGR to RGB\n",
    "#     img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     # Flatten the image to 2D array of pixels\n",
    "#     pixels = img_rgb.reshape((-1, 3))\n",
    "\n",
    "#     # Filter out colors between (0, 0, 0) and (20, 20, 20)\n",
    "#     pixels_filtered = pixels[\n",
    "#         np.any((pixels < np.array([0, 0, 0])) | (pixels > np.array([17, 17, 17])), axis=1)\n",
    "#     ]\n",
    "\n",
    "#     # Convert to float32\n",
    "#     pixels_filtered = np.float32(pixels_filtered)\n",
    "\n",
    "#     # Define criteria and apply kmeans()\n",
    "#     criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, 0.2)\n",
    "#     _, labels, centers = cv2.kmeans(pixels_filtered, num_colors, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "#     # Convert centers to integer\n",
    "#     centers = np.uint8(centers)\n",
    "\n",
    "#     # Find counts of labels to determine the most common colors\n",
    "#     unique, counts = np.unique(labels, return_counts=True)\n",
    "#     counts = counts.tolist()\n",
    "\n",
    "#     # Sort the counts in descending order and get the indices\n",
    "#     sorted_indices = sorted(range(len(counts)), key=lambda k: counts[k], reverse=True)\n",
    "\n",
    "#     # Extract the most common colors\n",
    "#     most_common_colors = centers[sorted_indices[:num_colors]]\n",
    "\n",
    "#     return most_common_colors\n",
    "\n",
    "# # Path to your PNG image of the shoe without background\n",
    "# # image_path = r\"F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop\\5-2_1.jpg\"\n",
    "\n",
    "# # Detect the most common colors in the image\n",
    "# # most_common_colors = detect_most_common_colors(folder_path)\n",
    "\n",
    "# # # Display the most common colors found\n",
    "# # plt.figure(figsize=(8, 3))\n",
    "# # plt.title('Most Common Colors')\n",
    "# # plt.imshow([most_common_colors], aspect='auto')\n",
    "# # plt.axis('off')\n",
    "# # plt.show()\n",
    "\n",
    "# # # plt.figure(figsize=(8, 3))\n",
    "# # # plt.title('RGB Values')\n",
    "# # # for i, color in enumerate(most_common_colors):\n",
    "# # #     plt.text(0, i * 0.2, f\"{i+1}. RGB = {color}\", ha='left', fontsize=10, color='black')\n",
    "# # # plt.axis('off')\n",
    "# # # plt.show()\n",
    "\n",
    "# # print(f\"RGB: {most_common_colors[0]}\")\n",
    "\n",
    "# folder_path = r\"F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop\"\n",
    "\n",
    "# # วนลูปผ่านไฟล์ทั้งหมดในโฟลเดอร์\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     if filename.endswith(\".jpg\"):  # ตรวจสอบเฉพาะไฟล์รูปภาพเท่านั้น\n",
    "#         image_path = os.path.join(folder_path, filename)\n",
    "#         most_common_colors = detect_most_common_colors(image_path)\n",
    "#         # แสดงค่า RGB ของรูปที่ใช้ในการตรวจหาสีที่พบบ่อยที่สุด\n",
    "#         print(f\"{filename} = RGB {most_common_colors[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import math\n",
    "# import re\n",
    "\n",
    "# # โค้ดหาสี RGB ที่ใช้หาสีที่พบบ่อยที่สุดในรูป\n",
    "# def detect_most_common_colors(image_path, num_colors=5):\n",
    "#     # Load image\n",
    "#     img = cv2.imread(image_path)\n",
    "\n",
    "#     # Convert BGR to RGB\n",
    "#     img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     # Flatten the image to 2D array of pixels\n",
    "#     pixels = img_rgb.reshape((-1, 3))\n",
    "\n",
    "#     # Filter out colors between (0, 0, 0) and (20, 20, 20)\n",
    "#     pixels_filtered = pixels[\n",
    "#         np.any((pixels < np.array([0, 0, 0])) | (pixels > np.array([17, 17, 17])), axis=1)\n",
    "#     ]\n",
    "\n",
    "#     # Convert to float32\n",
    "#     pixels_filtered = np.float32(pixels_filtered)\n",
    "\n",
    "#     # Define criteria and apply kmeans()\n",
    "#     criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, 0.2)\n",
    "#     _, labels, centers = cv2.kmeans(pixels_filtered, num_colors, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "#     # Convert centers to integer\n",
    "#     centers = np.uint8(centers)\n",
    "\n",
    "#     # Find counts of labels to determine the most common colors\n",
    "#     unique, counts = np.unique(labels, return_counts=True)\n",
    "#     counts = counts.tolist()\n",
    "\n",
    "#     # Sort the counts in descending order and get the indices\n",
    "#     sorted_indices = sorted(range(len(counts)), key=lambda k: counts[k], reverse=True)\n",
    "\n",
    "#     # Extract the most common colors\n",
    "#     most_common_colors = centers[sorted_indices[:num_colors]]\n",
    "\n",
    "#     return most_common_colors\n",
    "\n",
    "# # คิดสี RGB\n",
    "# def calculate_distance(color1, color2):\n",
    "#     r1, g1, b1 = color1\n",
    "#     r2, g2, b2 = color2\n",
    "#     distance = math.sqrt((r1 - r2) ** 2 + (g1 - g2) ** 2 + (b1 - b2) ** 2)\n",
    "#     return distance\n",
    "\n",
    "# def find_closest_color(input_color, colors):\n",
    "#     tolerance = 250  # กำหนดค่า tolerance เป็น 140\n",
    "#     min_distance = tolerance\n",
    "#     closest_color = None\n",
    "#     for color, rgb in colors.items():\n",
    "#         distance = calculate_distance(input_color, rgb)\n",
    "#         if distance < min_distance:\n",
    "#             min_distance = distance\n",
    "#             closest_color = color\n",
    "#     return closest_color\n",
    "\n",
    "# # รายการสีที่กำหนดไว้\n",
    "# colors = {\n",
    "#     \"Red\": (255, 0, 0),\n",
    "#     \"Orange\": (255, 165, 0),\n",
    "#     \"Yellow\": (255, 255, 0),\n",
    "#     \"Green\": (0, 255, 0), #green1\n",
    "#     \"Green\": (0, 128, 0), #green2\n",
    "#     \"Cyan\": (0, 255, 255),\n",
    "#     \"Blue\": (0, 0, 255), #Blue1\n",
    "#     \"Blue\": (0, 0, 139), #Blue2\n",
    "#     \"Purple\": (128, 0, 128), #Purple1\n",
    "#     \"Purple\": (255, 0, 255), #Purple2\n",
    "#     \"Pink\": (255, 192, 203),\n",
    "#     # \"White\": (255, 255, 255),\n",
    "#     # \"Black\": (18, 18, 18),\n",
    "#     # \"Gray\": (128, 128, 128)\n",
    "# }\n",
    "\n",
    "# folder_path = r\"F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop\"\n",
    "\n",
    "# image_files = [f for f in os.listdir(folder_path) if f.endswith('.jpg')]\n",
    "\n",
    "# image_files.sort(key=lambda x: int(re.search(r'(\\d+)-(\\d+)_\\d+\\.jpg', x).group(1)))\n",
    "\n",
    "\n",
    "# # วนลูปผ่านไฟล์ทั้งหมดในโฟลเดอร์ที่เรียงลำดับแล้ว\n",
    "# for filename in image_files:\n",
    "#     image_path = os.path.join(folder_path, filename)\n",
    "#     most_common_colors = detect_most_common_colors(image_path)\n",
    "    \n",
    "#     # คำนวณสีที่ใกล้เคียงที่สุดจากค่า RGB\n",
    "#     closest_color = find_closest_color(most_common_colors[0], colors)\n",
    "    \n",
    "#     # แสดงผลลัพธ์ตามที่ต้องการ\n",
    "#     print(f\"{filename} = RGB {most_common_colors[0]} = {closest_color}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pillow scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# from sklearn.cluster import KMeans\n",
    "# from collections import Counter\n",
    "\n",
    "# def extract_colors(image_path, num_colors=3):\n",
    "#     # Open the image and convert it to RGB mode\n",
    "#     image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "#     # Resize the image for faster processing (optional)\n",
    "#     image = image.resize((100, 100))\n",
    "\n",
    "#     # Convert the image to a NumPy array\n",
    "#     image_array = np.array(image)\n",
    "    \n",
    "#     # Reshape the array to a flat list of RGB pixels\n",
    "#     pixels = image_array.reshape((-1, 3))\n",
    "    \n",
    "#     # Perform K-Means clustering to find dominant colors\n",
    "#     kmeans = KMeans(n_clusters=num_colors)\n",
    "#     kmeans.fit(pixels)\n",
    "    \n",
    "#     # Get the RGB values of cluster centers (dominant colors)\n",
    "#     dominant_colors = kmeans.cluster_centers_.astype(int)\n",
    "    \n",
    "#     # Count the occurrences of each dominant color\n",
    "#     color_counts = Counter(tuple(color) for color in dominant_colors)\n",
    "    \n",
    "#     # Get the most common colors\n",
    "#     most_common_colors = color_counts.most_common(num_colors)\n",
    "    \n",
    "#     # Extract RGB values of the most common colors\n",
    "#     extracted_colors = [color[0] for color in most_common_colors]\n",
    "    \n",
    "#     return extracted_colors\n",
    "\n",
    "# # Example usage\n",
    "# image_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop\\63-2_2.jpg'  # Replace this with the path to your image file\n",
    "# extracted_colors = extract_colors(image_path)\n",
    "\n",
    "# # Output the extracted colors\n",
    "# print(\"Extracted Colors (RGB):\", extracted_colors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.applications import MobileNetV2\n",
    "# from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "\n",
    "# # Image Preprocessing\n",
    "# def preprocess_image(img_path):\n",
    "#     img = cv2.imread(img_path)\n",
    "#     img = cv2.resize(img, (224, 224))  # Resize to a standard size\n",
    "#     img = img.astype('float32') / 255  # Normalize pixel values\n",
    "#     return img\n",
    "\n",
    "# # Load Pre-Trained Model (example using MobileNetV2)\n",
    "# model = MobileNetV2(weights='imagenet')  # You can change the model architecture as needed\n",
    "\n",
    "# # Classify Shoe Brands\n",
    "# shoe_folder = 'path/to/shoe_images'  # Replace with the path to your shoe images folder\n",
    "\n",
    "# shoe_brands = []\n",
    "\n",
    "# for img_file in os.listdir(shoe_folder):\n",
    "#     if img_file.lower().endswith('.jpg'):\n",
    "#         img_path = os.path.join(shoe_folder, img_file)\n",
    "#         img = preprocess_image(img_path)\n",
    "#         img = np.expand_dims(img, axis=0)\n",
    "#         img = preprocess_input(img)\n",
    "\n",
    "#         predictions = model.predict(img)\n",
    "#         decoded_predictions = decode_predictions(predictions)\n",
    "\n",
    "#         # Get the top predicted class (shoe brand)\n",
    "#         predicted_brand = decoded_predictions[0][0][1]\n",
    "#         confidence = decoded_predictions[0][0][2]\n",
    "\n",
    "#         if confidence > 0.7:  # Set a confidence threshold\n",
    "#             shoe_brands.append((img_file, predicted_brand, confidence))\n",
    "\n",
    "# # Print Shoe Brands with High Confidence\n",
    "# for img_file, brand, confidence in shoe_brands:\n",
    "#     print(f'Image: {img_file}, Predicted Brand: {brand}, Confidence: {confidence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find DA COLORRRRRR (doesn't work yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('F:/intern/model_shoes_detection/Detect running shoes/shoe detection/ImageBackgroundRemover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import uuid\n",
    "# import os\n",
    "\n",
    "# from model import U2NET\n",
    "# from torch.autograd import Variable\n",
    "# from skimage import io, transform\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currentDir = \"F:/intern/model_shoes_detection/Detect running shoes/shoe detection/ImageBackgroundRemover\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_output(image_name, output_name, pred, d_dir, type):\n",
    "#     predict = pred\n",
    "#     predict = predict.squeeze()\n",
    "#     predict_np = predict.cpu().data.numpy()\n",
    "#     im = Image.fromarray(predict_np*255).convert('RGB')\n",
    "#     image = io.imread(image_name)\n",
    "#     imo = im.resize((image.shape[1], image.shape[0]))\n",
    "#     pb_np = np.array(imo)\n",
    "#     if type == 'image':\n",
    "#         # Make and apply mask\n",
    "#         mask = pb_np[:, :, 0]\n",
    "#         mask = np.expand_dims(mask, axis=2)\n",
    "#         imo = np.concatenate((image, mask), axis=2)\n",
    "#         imo = Image.fromarray(imo, 'RGBA')\n",
    "\n",
    "#     imo.save(d_dir+output_name)\n",
    "# # Remove Background From Image (Generate Mask, and Final Results)\n",
    "\n",
    "\n",
    "# def removeBg(imagePath):\n",
    "#     inputs_dir = os.path.join(currentDir, 'static/inputs/')\n",
    "#     results_dir = os.path.join(currentDir, 'static/results/')\n",
    "#     masks_dir = os.path.join(currentDir, 'static/masks/')\n",
    "\n",
    "#     # convert string of image data to uint8\n",
    "#     with open(imagePath, \"rb\") as image:\n",
    "#         f = image.read()\n",
    "#         img = bytearray(f)\n",
    "\n",
    "#     nparr = np.frombuffer(img, np.uint8)\n",
    "\n",
    "#     if len(nparr) == 0:\n",
    "#         return '---Empty image---'\n",
    "\n",
    "#     # decode image\n",
    "#     try:\n",
    "#         img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "#     except:\n",
    "#         # build a response dict to send back to client\n",
    "#         return \"---Empty image---\"\n",
    "\n",
    "#     # save image to inputs\n",
    "#     unique_filename = str(uuid.uuid4())\n",
    "#     cv2.imwrite(inputs_dir+unique_filename+'.jpg', img)\n",
    "\n",
    "#     # processing\n",
    "#     image = transform.resize(img, (320, 320), mode='constant')\n",
    "\n",
    "#     tmpImg = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "\n",
    "#     tmpImg[:, :, 0] = (image[:, :, 0]-0.485)/0.229\n",
    "#     tmpImg[:, :, 1] = (image[:, :, 1]-0.456)/0.224\n",
    "#     tmpImg[:, :, 2] = (image[:, :, 2]-0.406)/0.225\n",
    "\n",
    "#     tmpImg = tmpImg.transpose((2, 0, 1))\n",
    "#     tmpImg = np.expand_dims(tmpImg, 0)\n",
    "#     image = torch.from_numpy(tmpImg)\n",
    "\n",
    "#     image = image.type(torch.FloatTensor)\n",
    "#     image = Variable(image)\n",
    "\n",
    "#     d1, d2, d3, d4, d5, d6, d7 = net(image)\n",
    "#     pred = d1[:, 0, :, :]\n",
    "#     ma = torch.max(pred)\n",
    "#     mi = torch.min(pred)\n",
    "#     dn = (pred-mi)/(ma-mi)\n",
    "#     pred = dn\n",
    "\n",
    "#     # Save the result in the results_dir without changing the name\n",
    "#     save_output(inputs_dir+unique_filename+'.jpg', unique_filename +\n",
    "#                 '.png', pred, results_dir, 'image')\n",
    "#     save_output(inputs_dir+unique_filename+'.jpg', unique_filename +\n",
    "#                 '.png', pred, masks_dir, 'mask')\n",
    "#     return \"---Success---\"\n",
    "\n",
    "\n",
    "# # ------- Load Trained Model --------\n",
    "# print(\"---Loading Model---\")\n",
    "# model_name = 'u2net'\n",
    "# model_dir = os.path.join(currentDir, 'saved_models',\n",
    "#                          model_name, model_name + '.pth')\n",
    "# net = U2NET(3, 1)\n",
    "# if torch.cuda.is_available():\n",
    "#     net.load_state_dict(torch.load(model_dir))\n",
    "#     net.cuda()\n",
    "# else:\n",
    "#     net.load_state_dict(torch.load(model_dir, map_location='cpu'))\n",
    "# # ------- Load Trained Model --------\n",
    "\n",
    "\n",
    "# print(\"---Removing Background...\")\n",
    "# # image_folder_path = \"F:/intern/model_shoes_detection/Detect running shoes/shoe detection/Real_1/Shoes-crop/\"\n",
    "# image_folder_path = \"F:/intern/model_shoes_detection/Detect running shoes/shoe detection/Real_1/Person/\"\n",
    "\n",
    "# # Get the list of image files in the folder\n",
    "# image_files = [f for f in os.listdir(image_folder_path) if f.endswith(\".jpg\")]\n",
    "\n",
    "# for image_file in image_files:\n",
    "#     image_path = os.path.join(image_folder_path, image_file)\n",
    "#     print(f\"Removing background for image: {image_path}\")\n",
    "\n",
    "#     # Remove the background\n",
    "#     removeBg(image_path)\n",
    "\n",
    "# print(\"Removing Background Success.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import requests\n",
    "\n",
    "# api_key = 'acc_a0f4481e7bc9aec'\n",
    "# api_secret = 'e21b279bec9d428960c43da2d81eb88a'\n",
    "\n",
    "# # directory_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\ImageBackgroundRemover\\static\\results'\n",
    "# directory_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-deletebackground'\n",
    "\n",
    "\n",
    "\n",
    "# file_list = os.listdir(directory_path)\n",
    "\n",
    "# for file_name in file_list:\n",
    "\n",
    "#     image_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "#     with open(image_path, 'rb') as image_file:\n",
    "#         response = requests.post(\n",
    "#             'https://api.imagga.com/v2/colors',\n",
    "#             auth=(api_key, api_secret),\n",
    "#             files={'image': image_file})\n",
    "\n",
    "#         colors = response.json()['result']['colors']['foreground_colors']\n",
    "        \n",
    "#         print(f\"รูป: {file_name}\")\n",
    "#         for color in colors:\n",
    "#             print(f\"สี: {color['closest_palette_color']} (ความน่าจะเป็น: {color['percent']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shoesdlbg_folder = 'F:\\\\intern\\\\model_shoes_detection\\\\Detect running shoes\\\\shoe detection\\\\Real_1\\\\Shoes-deletebackground'\n",
    "# os.makedirs(shoesdlbg_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deeplabv3_resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from io import BytesIO\n",
    "# from PIL import Image\n",
    "# import torch\n",
    "# from torchvision import transforms\n",
    "# import numpy as np\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"---Loading Model---\")\n",
    "# def load_model():\n",
    "#     model = torch.hub.load('pytorch/vision:v0.6.0', 'deeplabv3_resnet101', pretrained=True)\n",
    "#     model.eval()\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_transparent_foreground(pic, mask):\n",
    "#     b, g, r = cv2.split(np.array(pic).astype('uint8'))\n",
    "#     a = np.ones(mask.shape, dtype='uint8') * 255\n",
    "#     alpha_im = cv2.merge([b, g, r, a], 4)\n",
    "#     bg = np.zeros(alpha_im.shape)\n",
    "#     new_mask = np.stack([mask, mask, mask, mask], axis=2)\n",
    "#     foreground = np.where(new_mask, alpha_im, bg).astype(np.uint8)\n",
    "#     return foreground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_background(model, img_path):\n",
    "#     img = Image.open(img_path)\n",
    "\n",
    "#     preprocess = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ])\n",
    "#     input_tensor = preprocess(img)\n",
    "#     input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "#     if torch.cuda.is_available():\n",
    "#         input_batch = input_batch.to('cuda')\n",
    "#         model.to('cuda')\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         output = model(input_batch)['out'][0]\n",
    "#     output_predictions = output.argmax(0)\n",
    "#     mask = output_predictions.byte().cpu().numpy()\n",
    "#     background = np.zeros(mask.shape)\n",
    "#     bin_mask = np.where(mask, 255, background).astype(np.uint8)\n",
    "\n",
    "#     foreground = make_transparent_foreground(img, bin_mask)\n",
    "\n",
    "#     return foreground, bin_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # โฟลเดอร์ที่เก็บรูปภาพทั้งหมด\n",
    "# input_folder = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop'\n",
    "\n",
    "# # โฟลเดอร์ที่จะบันทึกรูปที่ลบพื้นหลังแล้ว\n",
    "# output_folder = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-deletebackground'\n",
    "\n",
    "# # โมเดล DeepLab\n",
    "# deeplab_model = load_model()\n",
    "\n",
    "# # ตัวแปรนับเพื่อตั้งชื่อรูปไฟล์\n",
    "# counter = 1\n",
    "\n",
    "# # ลูปเพื่อดึงรูปทั้งหมดในโฟลเดอร์\n",
    "# for filename in os.listdir(input_folder):\n",
    "#     if filename.endswith('.jpg'):\n",
    "#         img_path = os.path.join(input_folder, filename)\n",
    "#         foreground, bin_mask = remove_background(deeplab_model, img_path)\n",
    "        \n",
    "#         # ตั้งชื่อไฟล์ output\n",
    "#         output_filename = f'{filename.split(\".\")[0]}_de_{counter}.png'\n",
    "#         output_path = os.path.join(output_folder, output_filename)\n",
    "        \n",
    "#         # บันทึกรูปที่ลบพื้นหลังแล้ว\n",
    "#         Image.fromarray(foreground).save(output_path)\n",
    "        \n",
    "#         # เพิ่มตัวแปรนับ\n",
    "#         counter += 1\n",
    "\n",
    "# print(\"delete background process complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with api imagga\n",
    "\n",
    "# import os\n",
    "# import requests\n",
    "# import openpyxl\n",
    "\n",
    "# api_key = 'acc_a0f4481e7bc9aec'\n",
    "# api_secret = 'e21b279bec9d428960c43da2d81eb88a'\n",
    "\n",
    "# directory_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-deletebackground'\n",
    "\n",
    "# file_list = os.listdir(directory_path)\n",
    "\n",
    "# # สร้างไฟล์ Excel\n",
    "# workbook = openpyxl.Workbook()\n",
    "# sheet = workbook.active\n",
    "# sheet['A1'] = 'ชื่อรูป'\n",
    "# sheet['D1'] = 'สีของรองเท้า'\n",
    "\n",
    "# for index, file_name in enumerate(file_list, start=2):\n",
    "#     image_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "#     with open(image_path, 'rb') as image_file:\n",
    "#         response = requests.post(\n",
    "#             'https://api.imagga.com/v2/colors',\n",
    "#             auth=(api_key, api_secret),\n",
    "#             files={'image': image_file})\n",
    "\n",
    "#         colors = response.json()['result']['colors']['foreground_colors']\n",
    "\n",
    "#         color_info = \"\"\n",
    "#         for color in colors:\n",
    "#             color_info += f\"{color['closest_palette_color']} (ความน่าจะเป็น: {color['percent']})\\n\"\n",
    "\n",
    "#         # เพิ่มข้อมูลลงใน Excel\n",
    "#         sheet.cell(row=index, column=1, value=file_name)\n",
    "#         sheet.cell(row=index, column=4, value=color_info)\n",
    "\n",
    "# # บันทึกไฟล์ Excel\n",
    "# workbook.save(r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\after2.xlsx')\n",
    "# print('Save file after2.xlsx success!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# # โหลดรูปภาพด้วยค่า Alpha (RGBA)\n",
    "# img = cv2.imread(r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-deletebackground\\92-2_1_de_154.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# # ตรวจสอบว่าค่า Alpha มีค่าเท่ากับ 0 หรือไม่\n",
    "# has_alpha_channel = img.shape[2] == 4\n",
    "\n",
    "# if has_alpha_channel:\n",
    "#     print(\"ภาพนี้มีพื้นหลังโปร่งใส\")\n",
    "# else:\n",
    "#     print(\"ภาพนี้ไม่มีพื้นหลังโปร่งใส\")\n",
    "\n",
    "# # บันทึกรูปภาพที่รองรับค่า Alpha (PNG)\n",
    "# cv2.imwrite('output.png', img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop\\36-2_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,8))\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,8))\n",
    "# plt.imshow(grid_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_HSV = cv2.cvtColor(grid_RGB, cv2.COLOR_RGB2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower_red = np.array([136, 87, 111])\n",
    "# upper_red = np.array([180, 255, 255])\n",
    "\n",
    "# lower_yellow = np.array([25,150,50])\n",
    "# upper_yellow = np.array([35,255,255])\n",
    "\n",
    "# lower_background = np.array([0,0,0])\n",
    "# upper_background = np.array([250,255,30])\n",
    "\n",
    "# lower_white = np.array([0,0,255])\n",
    "# upper_white = np.array([0,0,255])\n",
    "\n",
    "# lower_green = np.array([35, 120, 70])\n",
    "# upper_green = np.array([85, 255, 255])\n",
    "\n",
    "# lower_light_blue = np.array([94, 120, 70])\n",
    "# upper_light_blue = np.array([126, 255, 255])\n",
    "\n",
    "# lower_orange = np.array([10, 50, 50])\n",
    "# upper_orange = np.array([25, 255, 255])\n",
    "\n",
    "# lower_pink = np.array([145,150,0])\n",
    "# upper_pink = np.array([155,255,255])\n",
    "\n",
    "# lower_cyan = np.array([85,150,0])\n",
    "# upper_cyan = np.array([95,255,255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_1 = cv2.inRange(grid_HSV, lower_red, upper_red)\n",
    "# mask_2 = cv2.inRange(grid_HSV, lower_yellow, upper_yellow)\n",
    "# mask_3 = cv2.inRange(grid_HSV, lower_background, upper_background)\n",
    "# mask_4 = cv2.inRange(grid_HSV, lower_white, upper_white)\n",
    "# mask_5 = cv2.inRange(grid_HSV, lower_green, upper_green)\n",
    "# mask_6 = cv2.inRange(grid_HSV, lower_light_blue, upper_light_blue)\n",
    "# mask_7 = cv2.inRange(grid_HSV, lower_orange, upper_orange)\n",
    "# mask_9 = cv2.inRange(grid_HSV, lower_pink, upper_pink)\n",
    "# mask_10 = cv2.inRange(grid_HSV, lower_cyan, upper_cyan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object_mask = mask_1 + mask_2 + mask_4 + mask_5 + mask_6 + mask_7 + mask_9 + mask_10\n",
    "# object_mask = cv2.bitwise_and(object_mask, 255 - mask_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,8))\n",
    "# plt.imshow(object_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = cv2.bitwise_and(grid_RGB, grid_RGB, mask=object_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_areas = {\n",
    "#     \"Red\": np.sum(mask_1),\n",
    "#     \"Yellow\": np.sum(mask_2),\n",
    "#     \"White\": np.sum(mask_4),\n",
    "#     \"Green\": np.sum(mask_5),\n",
    "#     \"Light Blue\": np.sum(mask_6),\n",
    "#     \"Orange\": np.sum(mask_7),\n",
    "#     \"Pink\": np.sum(mask_9),\n",
    "#     \"Cyan\": np.sum(mask_10)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object_color_areas = {\n",
    "#     \"Red\": np.sum(mask_1),\n",
    "#     \"Yellow\": np.sum(mask_2),\n",
    "#     \"White\": np.sum(mask_4),\n",
    "#     \"Green\": np.sum(mask_5),\n",
    "#     \"Light Blue\": np.sum(mask_6),\n",
    "#     \"Orange\": np.sum(mask_7),\n",
    "#     \"Pink\": np.sum(mask_9),\n",
    "#     \"Cyan\": np.sum(mask_10)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Values in object_color_areas dictionary:\", object_color_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_color_value = sum(object_color_areas.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all(value == 0 for value in object_color_areas.values()):\n",
    "#     object_color = \"ไม่สามารถระบุสีได้\"\n",
    "#     print(\"The color of your shoes is:\", object_color)\n",
    "# elif total_color_value <= 50000:\n",
    "#     object_color = \"Black\"\n",
    "#     print(\"The color of your shoes is:\", object_color)\n",
    "# else:\n",
    "#     object_color = max(object_color_areas, key=object_color_areas.get)\n",
    "#     print(\"The color of your shoes is:\", object_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 8))\n",
    "# plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import openpyxl\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_workbook = openpyxl.load_workbook(r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\after.xlsx')\n",
    "input_sheet = input_workbook.active\n",
    "\n",
    "workbook = openpyxl.Workbook()\n",
    "sheet = workbook.active\n",
    "\n",
    "sheet['A1'] = 'ชื่อรูป'\n",
    "# sheet['B1'] = 'Gender'\n",
    "# sheet['C1'] = 'Brand'\n",
    "sheet['D1'] = 'สีของรองเท้า'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the color ranges\n",
    "lower_red = np.array([0, 100, 100])\n",
    "upper_red = np.array([15, 100, 100])\n",
    "\n",
    "lower_orange = np.array([16, 100, 100])\n",
    "upper_orange = np.array([39, 100,100])\n",
    "\n",
    "lower_yellow = np.array([40, 100, 100])\n",
    "upper_yellow = np.array([70, 100, 100])\n",
    "\n",
    "# lower_white = np.array([0, 0, 91])\n",
    "# upper_white = np.array([0, 0, 100])\n",
    "\n",
    "lower_green = np.array([71, 100, 100])\n",
    "upper_green = np.array([155, 100, 100])\n",
    "\n",
    "lower_cyan = np.array([156, 100, 100])\n",
    "upper_cyan = np.array([214, 100, 100])\n",
    "\n",
    "lower_blue = np.array([215, 100, 100])\n",
    "upper_blue = np.array([259, 100, 100])\n",
    "\n",
    "lower_purple = np.array([260, 100, 100])\n",
    "upper_purple = np.array([310, 100, 100])\n",
    "\n",
    "lower_pink = np.array([311, 100, 100])\n",
    "upper_pink = np.array([345, 100,100])\n",
    "\n",
    "lower_black = np.array([0, 0, 0])\n",
    "upper_black = np.array([180, 255, 30])\n",
    "\n",
    "# lower_gray = np.array([0, 0, 30])\n",
    "# upper_gray = np.array([0, 0, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# lower_red = np.array([0, 100, 100])\n",
    "# upper_red = np.array([15, 100, 100])\n",
    "    \n",
    "# lower_orange = np.array([16, 60, 60])\n",
    "# upper_orange = np.array([39, 100,100])\n",
    "\n",
    "# lower_yellow = np.array([40, 60, 60])\n",
    "# upper_yellow = np.array([70, 100, 100])\n",
    "ใ\n",
    "# lower_green = np.array([71, 60, 60])\n",
    "# upper_green = np.array([155, 100, 100])\n",
    "\n",
    "# lower_cyan = np.array([156, 60, 60])\n",
    "# upper_cyan = np.array([214, 100, 100])    \n",
    "\n",
    "# lower_blue = np.array([215, 60, 60])\n",
    "# upper_blue = np.array([259, 100, 100])\n",
    "\n",
    "# lower_purple = np.array([260, 60, 60])\n",
    "# upper_purple = np.array([310, 100, 100])\n",
    "    \n",
    "# lower_pink = np.array([311, 60, 60])\n",
    "# upper_pink = np.array([345, 100,100])\n",
    "\n",
    "\n",
    "def find_shoe_color(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    dominant_color = 'ไม่พบสี'\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Reshape the image to a 1D array\n",
    "    pixel_values = img_rgb.reshape((-1, 3))\n",
    "\n",
    "    # Calculate the histogram\n",
    "    hist = np.zeros((256, 256, 256))\n",
    "    for pixel in pixel_values:\n",
    "        hist[pixel[0], pixel[1], pixel[2]] += 1\n",
    "\n",
    "    # Find the color with maximum occurrence\n",
    "    max_occurrence = np.argmax(hist)\n",
    "    b, g, r = np.unravel_index(max_occurrence, hist.shape)\n",
    "\n",
    "    # Convert the dominant color (RGB) to HSV\n",
    "    rgb_color = np.uint8([[[r, g, b]]])\n",
    "    hsv_color = cv2.cvtColor(rgb_color, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # Check if the color falls within any specified bounds\n",
    "    # Your defined lower and upper bounds in HSV\n",
    "    colors = {\n",
    "        \"Red\": [np.array([0, 50, 50]), np.array([30, 255, 255])],\n",
    "        \"Orange\": [np.array([31, 50, 50]), np.array([60, 255, 255])],\n",
    "        \"Yellow\": [np.array([61, 50, 50]), np.array([90, 255, 255])],\n",
    "        \"Green\": [np.array([91, 50, 50]), np.array([150, 255, 255])],\n",
    "        \"Cyan\": [np.array([151, 50, 50]), np.array([210, 255, 255])],\n",
    "        \"Blue\": [np.array([211, 50, 50]), np.array([270, 255, 255])],\n",
    "        \"Purple\": [np.array([271, 50, 50]), np.array([300, 255, 255])],\n",
    "        \"Pink\": [np.array([301, 50, 50]), np.array([340, 255, 255])]\n",
    "    }\n",
    "\n",
    "    for color, (lower, upper) in colors.items():\n",
    "        if (lower[0] <= hsv_color[0][0][0] <= upper[0]) and (lower[1] <= hsv_color[0][0][1] <= upper[1]) and (lower[2] <= hsv_color[0][0][2] <= upper[2]):\n",
    "            dominant_color = color\n",
    "            break\n",
    "\n",
    "    return dominant_color\n",
    "\n",
    "\n",
    "def save_to_excel(folder_path):\n",
    "    file_list = sorted(os.listdir(folder_path), key=lambda x: (int(x.split('_')[0].split('-')[0]), int(x.split('_')[1].split('.')[0]))) \n",
    "    image_paths = [os.path.join(folder_path, file) for file in file_list]\n",
    "\n",
    "    df = pd.DataFrame(columns=['ชื่อรูป', 'สีของรองเท้า'])\n",
    "    \n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        dominant_color = find_shoe_color(image_path)\n",
    "        \n",
    "        file_name = os.path.basename(image_path)\n",
    "        \n",
    "        df.loc[idx, 'ชื่อรูป'] = file_name\n",
    "        df.loc[idx, 'สีของรองเท้า'] = dominant_color\n",
    "    \n",
    "    df.to_excel(r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\after2.xlsx', index=False)\n",
    "\n",
    "folder_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\dlgb'\n",
    "save_to_excel(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'de_(\\d+)\\.jpg', x).group(1)) if re.search(r'de_(\\d+)\\.jpg', x) else 0)\n",
    "\n",
    "image_data = []\n",
    "\n",
    "for idx, filename in enumerate(file_list):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        grid_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        grid_HSV = cv2.cvtColor(grid_RGB, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        mask_1 = cv2.inRange(grid_HSV, lower_red, upper_red)\n",
    "        mask_2 = cv2.inRange(grid_HSV, lower_orange, upper_orange)\n",
    "        mask_3 = cv2.inRange(grid_HSV, lower_yellow, upper_yellow)\n",
    "        mask_4 = cv2.inRange(grid_HSV, lower_green, upper_green)\n",
    "        mask_5 = cv2.inRange(grid_HSV, lower_cyan, upper_cyan)\n",
    "        mask_6 = cv2.inRange(grid_HSV, lower_blue, upper_blue)\n",
    "        mask_7 = cv2.inRange(grid_HSV, lower_purple, upper_purple)\n",
    "        mask_8 = cv2.inRange(grid_HSV, lower_pink, upper_pink)\n",
    "        mask_9 = cv2.inRange(grid_HSV, lower_black, upper_black)\n",
    "        \n",
    "        object_mask = mask_1 + mask_2 + mask_3 + mask_4 + mask_5 + mask_6 + mask_7 + mask_8\n",
    "        # object_mask = mask_1 + mask_2 + mask_5 + mask_6 + mask_7 + mask_8 + mask_9 + mark_11\n",
    "\n",
    "        mask_bg = cv2.bitwise_not(mask_9)\n",
    "        \n",
    "        object_mask = cv2.bitwise_and(object_mask, object_mask, mask=mask_bg)\n",
    "\n",
    "        color_areas = {\n",
    "            \"Red\": np.sum(mask_1),\n",
    "            \"Orange\": np.sum(mask_2),\n",
    "            \"Yellow\": np.sum(mask_3),\n",
    "            \"Green\": np.sum(mask_4),\n",
    "            \"Cyan\": np.sum(mask_5),\n",
    "            \"Blue\": np.sum(mask_6),\n",
    "            \"Purple\": np.sum(mask_7),\n",
    "            \"Pink\": np.sum(mask_8),\n",
    "        }\n",
    "\n",
    "        total_color_value = sum(color_areas.values())\n",
    "        \n",
    "        if all(value == 0 for value in color_areas.values()):\n",
    "            object_color = \"ไม่สามารถระบุสีได้\"\n",
    "        elif total_color_value <= 5000 or color_areas.get(\"Black\", 0) > 0:\n",
    "            object_color = \"Black\"\n",
    "        else:\n",
    "            object_color = max(color_areas, key=color_areas.get)\n",
    "\n",
    "        # gender = input_sheet.cell(row=idx + 2, column=2).value\n",
    "        # brand = input_sheet.cell(row=idx + 2, column=3).value\n",
    "\n",
    "        # ใช้ regular expression เพื่อหาตัวเลขทั้งหมดในชื่อไฟล์\n",
    "        numbers = [int(num) for num in re.findall(r'\\d+', filename)]\n",
    "\n",
    "        # เพิ่มข้อมูลลงใน dictionary\n",
    "        image_data.append({\"filename\": filename, \"numbers\": numbers, \"object_color\": object_color})\n",
    "\n",
    "# Create a new workbook and sheet\n",
    "workbook = openpyxl.Workbook()\n",
    "sheet = workbook.active\n",
    "\n",
    "sheet['A1'] = 'ชื่อรูป'\n",
    "# sheet['B1'] = 'Gender'\n",
    "# sheet['C1'] = 'Brand'\n",
    "sheet['D1'] = 'สีของรองเท้า'\n",
    "\n",
    "# เรียงลำดับ dictionary ตามตัวเลข (หลักหน่วยและหลักร้อย)\n",
    "sorted_image_data = sorted(image_data, key=lambda x: (x[\"numbers\"][0], x[\"numbers\"][1]))\n",
    "\n",
    "for data in sorted_image_data:\n",
    "    sheet.append([data[\"filename\"], '', '', data[\"object_color\"]])\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save(r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\after2.xlsx')\n",
    "print('Save file after2.xlsx success!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # โหลดรูปภาพ\n",
    "# image_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop\\3-2_2.jpg'  # ระบุ path ของรูปภาพที่ต้องการใช้\n",
    "# image = cv2.imread(image_path)\n",
    "\n",
    "# # แปลงภาพเป็นรูปแบบ HSV (Hue, Saturation, Value)\n",
    "# hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# # กำหนดช่วงสีต่าง ๆ ในรูปแบบ HSV\n",
    "# color_ranges = {\n",
    "#     'Red': ([0, 100, 100], [10, 255, 255]),\n",
    "#     'Orange': ([11, 100, 100], [20, 255, 255]),\n",
    "#     'Yellow': ([21, 100, 100], [30, 255, 255]),\n",
    "#     'Green': ([31, 100, 100], [85, 255, 255]),\n",
    "#     'Cyan': ([86, 100, 100], [125, 255, 255]),\n",
    "#     'Blue': ([126, 100, 100], [165, 255, 255]),\n",
    "#     'Purple': ([166, 100, 100], [250, 255, 255]),\n",
    "#     'Pink': ([251, 100, 100], [295, 255, 255]),\n",
    "#     # 'White': ([0, 0, 231], [180, 30, 255]),\n",
    "#     # 'Black': ([0, 0, 0], [180, 255, 30])\n",
    "# }\n",
    "\n",
    "# # นับจำนวนพิกเซลที่ตรงกับแต่ละสี\n",
    "# color_counts = {}\n",
    "# for color, (lower_bound, upper_bound) in color_ranges.items():\n",
    "#     mask = cv2.inRange(hsv_image, np.array(lower_bound), np.array(upper_bound))\n",
    "#     color_counts[color] = cv2.countNonZero(mask)\n",
    "\n",
    "# # หาสีที่มีจำนวนพิกเซลมากที่สุด\n",
    "# dominant_color = max(color_counts, key=color_counts.get)\n",
    "\n",
    "# print(f\"สีที่มีจำนวนพิกเซลมากที่สุดในรูปคือ: {dominant_color}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "\n",
    "def find_most_frequent_color(image_path):\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Convert the image to RGB color space\n",
    "    image = image.convert('RGB')\n",
    "    \n",
    "    # Get the pixel data\n",
    "    pixels = image.getdata()\n",
    "    \n",
    "    # Count the frequency of each color\n",
    "    color_counter = Counter(pixels)\n",
    "    \n",
    "    # Find the most common color and its frequency\n",
    "    most_common_color = color_counter.most_common(1)[0]\n",
    "    \n",
    "    return most_common_color[0]\n",
    "\n",
    "def find_closest_color(rgb_value, color_list, threshold=100):\n",
    "    min_distance = math.inf\n",
    "    closest_color = None\n",
    "\n",
    "    for color_name in color_list:\n",
    "        color_rgb = color_list[color_name]\n",
    "        distance = math.sqrt(sum([(c1 - c2) ** 2 for c1, c2 in zip(rgb_value, color_rgb)]))\n",
    "        if distance < min_distance and distance < threshold:\n",
    "            min_distance = distance\n",
    "            closest_color = color_name\n",
    "\n",
    "    return closest_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender_and_brand(file_name):\n",
    "    # ตัดข้อความ 'Crop_' และ '.JPG' จากชื่อไฟล์\n",
    "    name = file_name.replace('Crop_', '').replace('.JPG', '')\n",
    "    \n",
    "    # แยกชื่อเข้าด้วยเครื่องหมาย '-'\n",
    "    parts = name.split('-')\n",
    "    \n",
    "    if len(parts) == 2:\n",
    "        gender, brand = parts\n",
    "        if gender.lower() == 'male' or gender.lower() == 'female':\n",
    "            return gender.capitalize(), brand  # Capitalize the gender\n",
    "    return 'Unknown', brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Colors_List = { # 84 87 58\n",
    "\n",
    "    'Black' : (0,0,0), # 84 87 58\n",
    "    'White' : (255,255,255), # \n",
    "    'Red' : (255,0,0),\n",
    "    'Lime' : (0,255,0),\n",
    "    'Blue' : (0,0,255),\n",
    "    'Yellow' : (255,255,0),\n",
    "    'Aqua' : (0,255,255),\n",
    "    'Magenta' : (255,0,255),\n",
    "    'Silver' : (192,192,192),\n",
    "    'Gray' : (128,128,128)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# อ่านรูปภาพ\n",
    "image_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\dlgb\\1-2_2.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# ตรวจสอบว่าอ่านรูปได้หรือไม่\n",
    "if image is not None:\n",
    "    # แปลงภาพจากรูปภาพ BGR เป็น RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # กำหนด threshold เพื่อตัดสีพื้นหลัง\n",
    "    lower_threshold = np.array([0, 0, 0], dtype=np.uint8)\n",
    "    upper_threshold = np.array([30, 30, 30], dtype=np.uint8)\n",
    "    mask = cv2.inRange(image_rgb, lower_threshold, upper_threshold)\n",
    "\n",
    "    # นำ mask มาใช้กับภาพเพื่อทำให้สีพื้นหลังเป็นสีขาว\n",
    "    image_rgb[mask != 0] = [255, 255, 255]\n",
    "\n",
    "    # หาสีที่พบบ่อยที่สุดในภาพ\n",
    "    flattened_image = image_rgb.reshape((-1, 3))\n",
    "    unique_colors, counts = np.unique(flattened_image, axis=0, return_counts=True)\n",
    "    dominant_color = unique_colors[np.argmax(counts)]\n",
    "\n",
    "    print(\"สีหลักของรองเท้า:\", dominant_color)\n",
    "else:\n",
    "    print(\"ไม่สามารถอ่านรูปได้\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install colorthief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\dlgb'\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('_1.png'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        os.remove(file_path)\n",
    "        print(f'ลบไฟล์: {filename}')\n",
    "\n",
    "print('เสร็จสิ้นการลบไฟล์')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorthief import ColorThief\n",
    "import os\n",
    "\n",
    "directory = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\dlgb'\n",
    "\n",
    "file_list = os.listdir(directory)\n",
    "sorted_file_list = sorted(file_list, key=lambda x: int(x.split('-')[0]))\n",
    "\n",
    "for filename in sorted_file_list:  # ใช้ sorted_file_list ที่เราเรียงลำดับไว้แล้ว\n",
    "    if filename.endswith(\".png\"):\n",
    "        ct = ColorThief(os.path.join(directory, filename))\n",
    "        dominant_color = ct.get_color(quality=1)\n",
    "        \n",
    "        palette = ct.get_palette(color_count=3)\n",
    "        first_color = palette[0]\n",
    "\n",
    "        print(f'ชื่อรูป: {filename}')\n",
    "        print(first_color)\n",
    "        print(f\"#{first_color[0]:02x}{first_color[1]:02x}{first_color[2]:02x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# คิดสี RGB\n",
    "\n",
    "import math\n",
    "\n",
    "def calculate_distance(color1, color2):\n",
    "    r1, g1, b1 = color1\n",
    "    r2, g2, b2 = color2\n",
    "    distance = math.sqrt((r1 - r2) ** 2 + (g1 - g2) ** 2 + (b1 - b2) ** 2)\n",
    "    return distance\n",
    "\n",
    "def find_closest_color(input_color, colors):\n",
    "    tolerance = 150  # กำหนดค่า tolerance เป็น 140\n",
    "    min_distance = tolerance\n",
    "    closest_color = None\n",
    "    for color, rgb in colors.items():\n",
    "        distance = calculate_distance(input_color, rgb)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_color = color\n",
    "    return closest_color\n",
    "\n",
    "# สีที่กำหนด 10 สี\n",
    "colors = {\n",
    "    \"Red\": (255, 0, 0),\n",
    "    \"Orange\": (255, 128, 0),\n",
    "    \"Yellow\": (255, 255, 0),\n",
    "    \"Lime\": (128, 255, 0),\n",
    "    \"Green\": (0, 255, 0),\n",
    "    \"Light Green\": (0, 255, 128),\n",
    "    \"Cyan\": (0, 255, 255),\n",
    "    \"Light Blue\": (0, 128, 255),\n",
    "    \"Blue\": (0, 0, 255),\n",
    "    \"Purple\": (128, 0, 128),\n",
    "    \"Magenta\": (255, 0, 255),\n",
    "    \"Hot Pink\": (255, 0, 127),\n",
    "    \"Pink\": (255, 192, 203),\n",
    "    \"White\": (255, 255, 255),\n",
    "    \"Black\": (0, 0, 0),\n",
    "}\n",
    "\n",
    "# รับค่าสีจากผู้ใช้\n",
    "input_r = int(input(\"ป้อนค่าสีแดง (0-255): \"))\n",
    "input_g = int(input(\"ป้อนค่าสีเขียว (0-255): \"))\n",
    "input_b = int(input(\"ป้อนค่าสีน้ำเงิน (0-255): \")) \n",
    "\n",
    "# สีที่ป้อนเข้ามา\n",
    "input_color = (input_r, input_g, input_b)\n",
    "\n",
    "# หาสีที่ใกล้เคียงที่สุด\n",
    "closest_color = find_closest_color(input_color, colors)\n",
    "\n",
    "print(f\"สีที่ใกล้เคียงที่สุดคือ: {closest_color}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorthief import ColorThief\n",
    "import os\n",
    "\n",
    "directory = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\dlgb'\n",
    "\n",
    "file_list = os.listdir(directory)\n",
    "sorted_file_list = sorted(file_list, key=lambda x: int(x.split('-')[0]))\n",
    "\n",
    "output_file_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\output.txt'\n",
    "\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for filename in sorted_file_list:\n",
    "        if filename.endswith(\".png\"):\n",
    "            ct = ColorThief(os.path.join(directory, filename))\n",
    "            dominant_color = ct.get_color(quality=1)\n",
    "            \n",
    "            palette = ct.get_palette(color_count=3)\n",
    "            first_color = palette[0]\n",
    "            \n",
    "            # output_file.write(f'ชื่อรูป: {filename}\\n')\n",
    "            output_file.write(f'ชื่อรูป: {filename} \\\\ {first_color} \\\\ HEX:#{first_color[0]:02x}{first_color[1]:02x}{first_color[2]:02x}\\n')\n",
    "            # output_file.write(f\"#{first_color[0]:02x}{first_color[1]:02x}{first_color[2]:02x}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from colorthief import ColorThief\n",
    "import os\n",
    "\n",
    "def calculate_distance(color1, color2):\n",
    "    r1, g1, b1 = color1\n",
    "    r2, g2, b2 = color2\n",
    "    distance = math.sqrt((r1 - r2) ** 2 + (g1 - g2) ** 2 + (b1 - b2) ** 2)\n",
    "    return distance\n",
    "\n",
    "def find_closest_color(input_color, colors):\n",
    "    tolerance = 150\n",
    "    min_distance = tolerance\n",
    "    closest_color = None\n",
    "    for color, rgb in colors.items():\n",
    "        distance = calculate_distance(input_color, rgb)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_color = color\n",
    "    return closest_color\n",
    "\n",
    "def convert_rgb_to_hex(rgb):\n",
    "    return '#{0:02x}{1:02x}{2:02x}'.format(rgb[0], rgb[1], rgb[2])\n",
    "\n",
    "# สีที่กำหนด 10 สี\n",
    "colors = {\n",
    "    \"Red\": (255, 0, 0),\n",
    "    \"Orange\": (255, 128, 0),\n",
    "    \"Yellow\": (255, 255, 0),\n",
    "    \"Lime\": (128, 255, 0),\n",
    "    \"Green\": (0, 255, 0),\n",
    "    \"Light Green\": (0, 255, 128),\n",
    "    \"Cyan\": (0, 255, 255),\n",
    "    \"Light Blue\": (0, 128, 255),\n",
    "    \"Blue\": (0, 0, 255),\n",
    "    \"Purple\": (128, 0, 128),\n",
    "    \"Magenta\": (255, 0, 255),\n",
    "    \"Hot Pink\": (255, 0, 127),\n",
    "    \"Pink\": (255, 192, 203),\n",
    "    \"White\": (255, 255, 255),\n",
    "    \"Black\": (0, 0, 0),\n",
    "}\n",
    "\n",
    "# อ่านค่า RGB และแปลงเป็นชื่อสีและ HEX จากไฟล์ .txt\n",
    "directory = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\dlgb'\n",
    "output_file_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\output.txt'\n",
    "\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    file_list = os.listdir(directory)\n",
    "    sorted_file_list = sorted(file_list, key=lambda x: int(x.split('-')[0]))\n",
    "\n",
    "    for filename in sorted_file_list:\n",
    "        if filename.endswith(\".png\"):\n",
    "            ct = ColorThief(os.path.join(directory, filename))\n",
    "            dominant_color = ct.get_color(quality=1)\n",
    "            \n",
    "            palette = ct.get_palette(color_count=3)\n",
    "            first_color = palette[0]\n",
    "\n",
    "            closest_color = find_closest_color(dominant_color, colors)\n",
    "            hex_value = convert_rgb_to_hex(first_color)\n",
    "\n",
    "            output_file.write(f'ชื่อรูป: {filename} \\\\ {first_color} \\\\ HEX:{hex_value} \\\\ {closest_color}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # *****\n",
    "# from colorthief import ColorThief\n",
    "# import matplotlib.pyplot as plt\n",
    "# import colorsys\n",
    "\n",
    "# ct = ColorThief(r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\dlgb\\4-2_2.png')\n",
    "# dominant_color = ct.get_color(quality=1)\n",
    "\n",
    "# plt.imshow([[dominant_color]])\n",
    "# plt.show()\n",
    "\n",
    "# palette = ct.get_palette(color_count=5)\n",
    "# plt.imshow([[palette[i] for i in range(5)]])\n",
    "# plt.show()\n",
    "\n",
    "# for color in palette:\n",
    "#     print(color)\n",
    "#     print(f\"#{color[0]:02x}{color[1]:02x}{color[2]:02x}\")\n",
    "#     print(colorsys.rgb_to_hsv(*color))\n",
    "#     print(colorsys.rgb_to_hls(*color))\n",
    "# # *****\n",
    "\n",
    "\n",
    "import os\n",
    "from colorthief import ColorThief\n",
    "\n",
    "# Path to the directory containing the images\n",
    "directory_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\dlgb'\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.png'):  # Consider only PNG files, adjust extensions if needed\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "        # Print filename\n",
    "        print(f\"Filename: {filename}\")\n",
    "        \n",
    "        # Perform color extraction\n",
    "        ct = ColorThief(file_path)\n",
    "        dominant_color = ct.get_color(quality=1)  # Get the dominant color\n",
    "        \n",
    "        # Print the dominant color only\n",
    "        print(dominant_color)\n",
    "        \n",
    "        print()  # Add an empty line after each image's color information\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to get dominant color from an image using RGB Histogram\n",
    "def get_dominant_color(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    reshaped_img = img.reshape(-1, 3)\n",
    "\n",
    "    hist_r = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
    "    hist_g = cv2.calcHist([img], [1], None, [256], [0, 256])\n",
    "    hist_b = cv2.calcHist([img], [2], None, [256], [0, 256])\n",
    "\n",
    "    hist_r[0] = 0\n",
    "    hist_g[0] = 0\n",
    "    hist_b[0] = 0\n",
    "\n",
    "    max_r = np.argmax(hist_r)\n",
    "    max_g = np.argmax(hist_g)\n",
    "    max_b = np.argmax(hist_b)\n",
    "\n",
    "    dominant_color = (int(max_r), int(max_g), int(max_b))\n",
    "    \n",
    "    return dominant_color\n",
    "\n",
    "# Directory path\n",
    "directory_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\dlgb'\n",
    "\n",
    "# List to store data\n",
    "data = []\n",
    "\n",
    "# Iterate through images in the directory\n",
    "for image_name in sorted(os.listdir(directory_path), key=lambda x: int(x.split(\"_\")[0].split(\"-\")[0])):\n",
    "    image_path = os.path.join(directory_path, image_name)\n",
    "    if os.path.isfile(image_path):  # Check if it's a file\n",
    "        predicted_color = get_dominant_color(image_path)\n",
    "        data.append((image_name, predicted_color))\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Image Name', 'Color RGB'])\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "output_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\shoe_colors.xlsx'\n",
    "df.to_excel(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def calculate_distance(color1, color2):\n",
    "    r1, g1, b1 = color1\n",
    "    r2, g2, b2 = color2\n",
    "    distance = math.sqrt((r1 - r2) ** 2 + (g1 - g2) ** 2 + (b1 - b2) ** 2)\n",
    "    return distance\n",
    "\n",
    "def find_closest_color(input_color, colors):\n",
    "    tolerance = 150  # กำหนดค่า tolerance เป็น 150\n",
    "    min_distance = tolerance\n",
    "    closest_color = None\n",
    "    for color, rgb in colors.items():\n",
    "        distance = calculate_distance(input_color, rgb)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_color = color\n",
    "    return closest_color\n",
    "\n",
    "# อ่านข้อมูลจากไฟล์ Excel\n",
    "file_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\shoe_colors.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# สร้างฟังก์ชันเพื่อคำนวณสีที่ใกล้เคียงที่สุด\n",
    "colors = {\n",
    "    \"Red\": (255, 51, 51),\n",
    "    \"Orange\": (255, 178, 102),\n",
    "    \"Yellow\": (255, 220, 0),\n",
    "    \"Green\": (130, 255, 51),\n",
    "    \"Cyan\": (50, 200, 200),\n",
    "    \"Blue\": (51, 51, 255),\n",
    "    \"Purple\": (153, 51, 255),\n",
    "    \"Magenta\": (255,102,255),\n",
    "    \"Pink\": (230, 70, 150),\n",
    "    \"White\": (250, 250, 250),\n",
    "    \"Gray\": (90, 90, 90),\n",
    "    \"Black\": (0, 0, 0),\n",
    "}\n",
    "\n",
    "# สร้างคอลัมน์ใหม่เพื่อเก็บข้อมูลสีที่ใกล้เคียงที่สุด\n",
    "closest_colors = []\n",
    "for idx, row in data.iterrows():\n",
    "    input_color = eval(row['Color RGB'])  # สีจากไฟล์\n",
    "    closest_color = find_closest_color(input_color, colors)\n",
    "    closest_colors.append(closest_color)\n",
    "\n",
    "data['Closest Color'] = closest_colors\n",
    "\n",
    "# บันทึกเป็นไฟล์ Excel ใหม่\n",
    "output_file_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\shoe_colors_with_closest.xlsx'\n",
    "data.to_excel(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "\n",
    "# def get_dominant_color_for_pair(file_paths, exclude_black=True):\n",
    "#     dominant_colors = [get_dominant_color(file_path, exclude_black) for file_path in file_paths]\n",
    "#     return np.mean(dominant_colors, axis=0, dtype=int)\n",
    "\n",
    "# def find_matching_pairs_with_color(directory):\n",
    "#     files = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "\n",
    "#     # Sort the files based on both numerical and hyphen parts\n",
    "#     files.sort(key=lambda x: [int(part) if part.isdigit() else part for part in x.split('_')[0].split('-')])\n",
    "\n",
    "#     pairs = {}\n",
    "\n",
    "#     for file in files:\n",
    "#         common_part = file.split('_')[0]\n",
    "\n",
    "#         if common_part not in pairs:\n",
    "#             pairs[common_part] = [file]\n",
    "#         else:\n",
    "#             pairs[common_part].append(file)\n",
    "\n",
    "#     pairs = {key: value for key, value in pairs.items() if len(value) > 1}\n",
    "\n",
    "#     for common_part, files in pairs.items():\n",
    "#         dominant_color = get_dominant_color_for_pair([join(directory, file) for file in files])\n",
    "#         print(f\"Matching pair for {common_part}: {files} = {common_part}{dominant_color}\")\n",
    "\n",
    "# # Example usage\n",
    "# directory_path = \"F:/intern/model_shoes_detection/Detect running shoes/shoe detection/Real_1/dlgb/\"\n",
    "# find_matching_pairs_with_color(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "\n",
    "# def get_dominant_color(image_path, exclude_black=True):\n",
    "#     image = Image.open(image_path)\n",
    "#     image_array = np.array(image)\n",
    "#     unique_colors, counts = np.unique(image_array.reshape(-1, image_array.shape[2]), axis=0, return_counts=True)\n",
    "\n",
    "#     if exclude_black:\n",
    "#         non_black_indices = np.where(~np.all(unique_colors == 0, axis=1))\n",
    "#         unique_colors = unique_colors[non_black_indices]\n",
    "#         counts = counts[non_black_indices]\n",
    "\n",
    "#     dominant_color_rgb = unique_colors[np.argmax(counts)]\n",
    "    \n",
    "#     return dominant_color_rgb\n",
    "\n",
    "# def get_average_color(image_paths):\n",
    "#     dominant_colors = [get_dominant_color(image_path) for image_path in image_paths]\n",
    "#     average_color = np.mean(dominant_colors, axis=0, dtype=int)\n",
    "#     return average_color\n",
    "\n",
    "# def find_matching_pairs_with_color(directory):\n",
    "#     files = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "\n",
    "#     # Sort the files based on both numerical and hyphen parts\n",
    "#     files.sort(key=lambda x: [int(part) if part.isdigit() else part for part in x.split('_')[0].split('-')])\n",
    "\n",
    "#     pairs = {}\n",
    "\n",
    "#     for file in files:\n",
    "#         common_part = file.split('_')[0]\n",
    "\n",
    "#         if common_part not in pairs:\n",
    "#             pairs[common_part] = [file]\n",
    "#         else:\n",
    "#             pairs[common_part].append(file)\n",
    "\n",
    "#     pairs = {key: value for key, value in pairs.items() if len(value) > 1}\n",
    "\n",
    "#     for common_part, files in pairs.items():\n",
    "#         average_color = get_average_color([join(directory, file) for file in files])\n",
    "#         print(f\"Matching pair for {common_part}: {files} = {common_part}{average_color}\")\n",
    "\n",
    "# # Example usage\n",
    "# directory_path = \"F:/intern/model_shoes_detection/Detect running shoes/shoe detection/Real_1/dlgb/\"\n",
    "# find_matching_pairs_with_color(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorthief import ColorThief\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import Counter\n",
    "\n",
    "def find_matching_pairs(directory):\n",
    "    files = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "    pairs = {}\n",
    "    \n",
    "    for file in files:\n",
    "        common_part = file.split('_')[0]\n",
    "        if common_part not in pairs:\n",
    "            pairs[common_part] = [file]\n",
    "        else:\n",
    "            pairs[common_part].append(file)\n",
    "    \n",
    "    pairs = {key: value for key, value in pairs.items() if len(value) > 1}\n",
    "    return pairs\n",
    "\n",
    "def get_dominant_color(directory, matching_pairs):\n",
    "    for common_part, files in matching_pairs.items():\n",
    "        img_paths = [join(directory, f) for f in files]\n",
    "        colors = []\n",
    "\n",
    "        for img_path in img_paths:\n",
    "            ct = ColorThief(img_path)\n",
    "            palette = ct.get_palette(color_count=10)  # Get a palette of dominant colors\n",
    "\n",
    "            # Add the colors in the palette to the list\n",
    "            colors.extend(palette)\n",
    "\n",
    "        # Count the occurrences of each color\n",
    "        color_counter = Counter(colors)\n",
    "        most_common_color = color_counter.most_common(1)[0][0]  # Get the most common color\n",
    "        \n",
    "        print(f\"Matching pair for {common_part}: {files} = RGB: {most_common_color}\")\n",
    "\n",
    "# Example usage\n",
    "directory_path = \"D:/SWE62-363 Seminar for software Engineering/Detect running shoes/shoe detection/Real_1/dlgb/\"\n",
    "matching_pairs = find_matching_pairs(directory_path)\n",
    "get_dominant_color(directory_path, matching_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def find_matching_pairs(directory):\n",
    "    # Get a list of all files in the directory\n",
    "    files = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "    \n",
    "    # Create a dictionary to store pairs\n",
    "    pairs = {}\n",
    "\n",
    "    # Iterate through each file in the directory\n",
    "    for file in files:\n",
    "        # Extract the common part of the name (excluding _1, _2, etc.)\n",
    "        common_part = file.split('_')[0]\n",
    "\n",
    "        # If the common part is not already in the dictionary, add it\n",
    "        if common_part not in pairs:\n",
    "            pairs[common_part] = [file]\n",
    "        else:\n",
    "            # If it's already in the dictionary, append the current file to the list\n",
    "            pairs[common_part].append(file)\n",
    "\n",
    "    # Filter out pairs with only one file (no matching pair)\n",
    "    pairs = {key: value for key, value in pairs.items() if len(value) > 1}\n",
    "\n",
    "    return pairs\n",
    "\n",
    "# Example usage\n",
    "directory_path = \"D:/SWE62-363 Seminar for software Engineering/Detect running shoes/shoe detection/Real_1/dlgb/\"\n",
    "matching_pairs = find_matching_pairs(directory_path)\n",
    "\n",
    "# Print matching pairs\n",
    "for common_part, files in matching_pairs.items():\n",
    "    print(f\"Matching pair for {common_part}: {files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "input_folder = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop'\n",
    "output_folder = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\dlgb'\n",
    "\n",
    "api_url = 'https://api.pixian.ai/api/v2/remove-background'\n",
    "headers = {\n",
    "    'Authorization': 'Basic cHg0cjV6aXpwdHJ2cHBtOnZtcTBxcnZkb3Y4cWtsYjJwcWo4anA2ZjZzZThjM3AxMDZlanVnN2g2OHY0azB0azJkaW4='\n",
    "}\n",
    "\n",
    "# หากโฟลเดอร์ปลายทางไม่ได้ถูกสร้างไว้ ให้สร้างโฟลเดอร์นี้\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.jpg'):\n",
    "        input_filepath = os.path.join(input_folder, filename)\n",
    "        output_filepath = os.path.join(output_folder, os.path.splitext(filename)[0] + '.png')  # เปลี่ยนนามสกุลไฟล์เป็น .png\n",
    "\n",
    "        # ทำการลบพื้นหลังของรูป\n",
    "        response = requests.post(\n",
    "            api_url,\n",
    "            files={'image': open(input_filepath, 'rb')},\n",
    "            data={},\n",
    "            headers=headers\n",
    "        )\n",
    "\n",
    "        # บันทึกรูปที่ผ่านการลบพื้นหลัง\n",
    "        if response.status_code == requests.codes.ok:\n",
    "            with open(output_filepath, 'wb') as out:\n",
    "                out.write(response.content)\n",
    "            print(f\"Removed background for {filename} and saved to {output_filepath}\")\n",
    "        else:\n",
    "            print(f\"Error removing background for {filename}: {response.status_code}, {response.text}\")\n",
    "\n",
    "print(\"Processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# # โปรแกรมหาค่าเฉลี่ยของสีในรูปภาพ\n",
    "# def average_color(image):\n",
    "#     # เปิดภาพในโหมด RGB\n",
    "#     img = image.convert(\"RGB\")\n",
    "#     # หาขนาดของรูป\n",
    "#     width, height = img.size\n",
    "#     # ตัวแปรเพื่อเก็บผลลัพธ์\n",
    "#     total_red = 0\n",
    "#     total_green = 0\n",
    "#     total_blue = 0\n",
    "#     total_pixels = 0\n",
    "    \n",
    "#     # วนลูปทุกพิกเซลเพื่อหาค่าเฉลี่ยของสี (ยกเว้นสีดำ)\n",
    "#     for x in range(width):\n",
    "#         for y in range(height):\n",
    "#             r, g, b = img.getpixel((x, y))\n",
    "#             # ตรวจสอบว่าสีไม่ใช่สีดำ (r, g, b ไม่เท่ากับ (0, 0, 0))\n",
    "#             if (r, g, b) != (0, 0, 0):\n",
    "#                 total_red += r\n",
    "#                 total_green += g\n",
    "#                 total_blue += b\n",
    "#                 total_pixels += 1\n",
    "    \n",
    "#     # หาค่าเฉลี่ยของสีแต่ละสี (R, G, B)\n",
    "#     average_red = total_red // total_pixels\n",
    "#     average_green = total_green // total_pixels\n",
    "#     average_blue = total_blue // total_pixels\n",
    "    \n",
    "#     return average_red, average_green, average_blue\n",
    "\n",
    "# # โหลดรูปภาพ\n",
    "# image_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-deletebackground\\36-2_1_de_30.png'  # ระบุ path ของรูปภาพที่ต้องการใช้\n",
    "# image = Image.open(image_path)\n",
    "\n",
    "# # หาค่าเฉลี่ยของสีในรูปภาพ\n",
    "# average_red, average_green, average_blue = average_color(image)\n",
    "\n",
    "# # แสดงผลลัพธ์\n",
    "# print(f\"Average RGB Color: ({average_red}, {average_green}, {average_blue})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# # Open an image file\n",
    "# image_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-deletebackground\\36-2_1_de_30.png'\n",
    "# image = Image.open(image_path)\n",
    "\n",
    "# # Get the width and height of the image\n",
    "# image_width, image_height = image.size\n",
    "\n",
    "# # Specify valid coordinates within the image range\n",
    "# x = 50  # choose a valid x-coordinate within the range (0 to image_width - 1)\n",
    "# y = 100  # choose a valid y-coordinate within the range (0 to image_height - 1)\n",
    "\n",
    "# # Check if the specified coordinates are within the valid range\n",
    "# if 0 <= x < image_width and 0 <= y < image_height:\n",
    "#     # Get the RGB values at the specified pixel\n",
    "#     rgb_values = image.getpixel((x, y))\n",
    "#     # Output the RGB values\n",
    "#     print(\"RGB values at pixel ({}, {}): {}\".format(x, y, rgb_values))\n",
    "# else:\n",
    "#     print(\"Invalid coordinates. The specified pixel is outside the valid range for the image.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark จุดตรงกลางเเละระบุจุดตรงกลางเป็นสี RGB นั้น\n",
    "\n",
    "\n",
    "import os\n",
    "from tkinter import Tk, Canvas, filedialog\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "class ColorPickerApp:\n",
    "    def __init__(self):\n",
    "        self.canvas_width = 450\n",
    "        self.canvas_height = 500\n",
    "        self.process_images_and_pick_colors()\n",
    "\n",
    "    def extract_number_from_filename(self, filename):\n",
    "        # Extract the first number from the filename, ignoring non-digit characters\n",
    "        digits = ''.join(filter(str.isdigit, filename.split('_')[0]))\n",
    "        if digits:\n",
    "            return int(digits)\n",
    "        return -1  # Return a special value for filenames without numbers\n",
    "\n",
    "    def process_images_and_pick_colors(self):\n",
    "        folder_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes-deletebackground'\n",
    "        output_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes-deletebackground\\label_RGB.txt'\n",
    "\n",
    "        # List to store filename and RGB tuples\n",
    "        colors = []\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.jpg') or filename.endswith('.png'):  # Assuming images are jpg or png files\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                image = Image.open(file_path)\n",
    "                image = image.resize((self.canvas_width, self.canvas_height))\n",
    "                # Get color at the center of the image\n",
    "                x, y = self.canvas_width // 2, self.canvas_height // 2\n",
    "                pixel = image.getpixel((x, y))\n",
    "                colors.append((filename, pixel))\n",
    "\n",
    "        # Sort colors based on the first number in the filename\n",
    "        sorted_colors = sorted(colors, key=lambda x: self.extract_number_from_filename(x[0]))\n",
    "\n",
    "        with open(output_path, 'w') as file:\n",
    "            for filename, pixel in sorted_colors:\n",
    "                file.write(f\"{filename}: Selected Color (RGB): {pixel}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = ColorPickerApp()\n",
    "    print(\"Save label_RGB.txt Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# อ่านไฟล์ label_RGB.txt เเล้วบันทึกสีเป็นไฟล์ .xlsx\n",
    "\n",
    "import os\n",
    "import math\n",
    "import openpyxl\n",
    "\n",
    "def calculate_distance(color1, color2):\n",
    "    r1, g1, b1 = color1\n",
    "    r2, g2, b2 = color2\n",
    "    distance = math.sqrt((r1 - r2) ** 2 + (g1 - g2) ** 2 + (b1 - b2) ** 2)\n",
    "    return distance\n",
    "\n",
    "def find_closest_color(input_color, colors):\n",
    "    tolerance = 150  \n",
    "    min_distance = tolerance\n",
    "    closest_color = None\n",
    "    for color, rgb in colors.items():\n",
    "        distance = calculate_distance(input_color, rgb)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_color = color\n",
    "    return closest_color\n",
    "\n",
    "colors = {\n",
    "    \"Red\": (255, 0, 0),\n",
    "    \"Orange\": (255, 128, 0),\n",
    "    \"Yellow\": (255, 255, 0),\n",
    "    \"Green\": (0, 255, 0),\n",
    "    \"Cyan\": (3, 169, 244),\n",
    "    \"Blue\": (0, 0, 255),\n",
    "    \"Purple\": (163, 44, 196),\n",
    "    \"Pink\": (255, 22, 148),\n",
    "    \"White\": (255, 255, 255),\n",
    "    \"Black\": (0, 0, 0),\n",
    "    # \"Gray\": (128, 128, 128)\n",
    "}\n",
    "\n",
    "input_file_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes-deletebackground\\label_RGB.txt'\n",
    "\n",
    "output_file_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes-deletebackground\\after2.xlsx'\n",
    "workbook = openpyxl.Workbook()\n",
    "sheet = workbook.active\n",
    "\n",
    "# กำหนดค่าให้กับ cell A1 และ D1\n",
    "sheet.cell(row=1, column=1, value=\"ชื่อรูป\")\n",
    "sheet.cell(row=1, column=4, value=\"สีของรองเท้า\")\n",
    "\n",
    "# อ่านค่าสี RGB จากไฟล์และบันทึกลง Excel\n",
    "with open(input_file_path, 'r') as file:\n",
    "    row_num = 2  # เริ่มต้นที่ row ที่ 2 เพราะ row แรกใช้เป็นหัวข้อ\n",
    "    for line in file:\n",
    "        filename, rgb_values = line.strip().split(\": Selected Color (RGB): \")\n",
    "        r, g, b, _ = eval(rgb_values)\n",
    "        input_color = (r, g, b)\n",
    "        closest_color = find_closest_color(input_color, colors)\n",
    "        sheet.cell(row=row_num, column=1, value=filename.strip())\n",
    "        sheet.cell(row=row_num, column=4, value=closest_color)\n",
    "        row_num += 1\n",
    "\n",
    "workbook.save(output_file_path)\n",
    "\n",
    "print(\"Save after2.xlsx success!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เพิ่ม Gender - Brand\n",
    "\n",
    "import openpyxl\n",
    "\n",
    "# เปิดไฟล์ existing Excel\n",
    "file_path = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\Real_1\\Shoes-deletebackground\\after2.xlsx'\n",
    "workbook = openpyxl.load_workbook(file_path)\n",
    "sheet = workbook.active\n",
    "\n",
    "# เพิ่มข้อมูลในคอลัมน์ B1 และ C1\n",
    "sheet['B1'] = 'Gender'\n",
    "sheet['C1'] = 'Brand'\n",
    "\n",
    "# บันทึกไฟล์\n",
    "workbook.save(file_path)\n",
    "\n",
    "print(\"Update after2.xlsx sucess!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# คิดสี RGB\n",
    "\n",
    "import math\n",
    "\n",
    "def calculate_distance(color1, color2):\n",
    "    r1, g1, b1 = color1\n",
    "    r2, g2, b2 = color2\n",
    "    distance = math.sqrt((r1 - r2) ** 2 + (g1 - g2) ** 2 + (b1 - b2) ** 2)\n",
    "    return distance\n",
    "\n",
    "def find_closest_color(input_color, colors):\n",
    "    tolerance = 150  # กำหนดค่า tolerance เป็น 140\n",
    "    min_distance = tolerance\n",
    "    closest_color = None\n",
    "    for color, rgb in colors.items():\n",
    "        distance = calculate_distance(input_color, rgb)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_color = color\n",
    "    return closest_color\n",
    "\n",
    "# สีที่กำหนด 10 สี\n",
    "colors = {\n",
    "    \"Red\": (255, 0, 0),\n",
    "    \"Orange\": (255, 128, 0),\n",
    "    \"Yellow\": (255, 255, 0),\n",
    "    \"Green\": (0, 255, 0),\n",
    "    \"Cyan\": (3, 169, 244),\n",
    "    \"Blue\": (0, 0, 255),\n",
    "    \"Purple\": (163,44,196),\n",
    "    \"Pink\": (255, 22, 148),\n",
    "    \"White\": (255, 255, 255),\n",
    "    \"Black\": (0, 0, 0),\n",
    "    # \"Gray\": (128,128,128)\n",
    "}\n",
    "\n",
    "# รับค่าสีจากผู้ใช้\n",
    "input_r = int(input(\"ป้อนค่าสีแดง (0-255): \"))\n",
    "input_g = int(input(\"ป้อนค่าสีเขียว (0-255): \"))\n",
    "input_b = int(input(\"ป้อนค่าสีน้ำเงิน (0-255): \")) \n",
    "\n",
    "# สีที่ป้อนเข้ามา\n",
    "input_color = (input_r, input_g, input_b)\n",
    "\n",
    "# หาสีที่ใกล้เคียงที่สุด\n",
    "closest_color = find_closest_color(input_color, colors)\n",
    "\n",
    "print(f\"สีที่ใกล้เคียงที่สุดคือ: {closest_color}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # โหลดรูปภาพ\n",
    "# image_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-deletebackground\\36-2_1_de_30.png'  # ระบุ path ของรูปภาพที่ต้องการใช้\n",
    "# image = cv2.imread(image_path)\n",
    "\n",
    "# # แปลงภาพเป็นรูปแบบ HSV (Hue, Saturation, Value)\n",
    "# hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# # กำหนดช่วงสีต่าง ๆ ในรูปแบบ HSV\n",
    "# color_ranges = {\n",
    "#     'Red': ([0, 100, 100], [10, 255, 255]),\n",
    "#     'Orange': ([11, 100, 100], [20, 255, 255]),\n",
    "#     'Yellow': ([21, 100, 100], [30, 255, 255]),\n",
    "#     'Green': ([31, 100, 100], [85, 255, 255]),\n",
    "#     'Cyan': ([86, 100, 100], [125, 255, 255]),\n",
    "#     'Blue': ([126, 100, 100], [165, 255, 255]),\n",
    "#     'Purple': ([166, 100, 100], [250, 255, 255]),\n",
    "#     'Pink': ([251, 100, 100], [295, 255, 255]),\n",
    "#     # 'White': ([0, 0, 231], [180, 30, 255]),\n",
    "#     # 'Black': ([0, 0, 0], [180, 255, 30])\n",
    "# }\n",
    "\n",
    "# # นับจำนวนพิกเซลที่ตรงกับแต่ละสี\n",
    "# color_counts = {}\n",
    "# for color, (lower_bound, upper_bound) in color_ranges.items():\n",
    "#     mask = cv2.inRange(hsv_image, np.array(lower_bound), np.array(upper_bound))\n",
    "#     color_counts[color] = cv2.countNonZero(mask)\n",
    "\n",
    "# # หาสีที่มีจำนวนพิกเซลมากที่สุด\n",
    "# dominant_color = max(color_counts, key=color_counts.get)\n",
    "\n",
    "# print(f\"สีที่มีจำนวนพิกเซลมากที่สุดในรูปคือ: {dominant_color}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import colorsys\n",
    "\n",
    "# def get_image_color_codes(image_path):\n",
    "#     # Read the image\n",
    "#     image = cv2.imread(image_path)\n",
    "    \n",
    "#     # Convert BGR to RGB\n",
    "#     image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     # Get average color using numpy\n",
    "#     average_color = np.mean(image_rgb, axis=(0, 1))\n",
    "    \n",
    "#     # Get HEX code\n",
    "#     hex_code = '#{:02x}{:02x}{:02x}'.format(int(average_color[0]), int(average_color[1]), int(average_color[2]))\n",
    "    \n",
    "#     # Get RGB code\n",
    "#     rgb_code = tuple(int(c) for c in average_color)\n",
    "    \n",
    "#     # Convert RGB to HSL\n",
    "#     hsl_code = colorsys.rgb_to_hls(rgb_code[0]/255, rgb_code[1]/255, rgb_code[2]/255)\n",
    "#     hsl_code = tuple(int(round(c * 100)) for c in hsl_code)  # Scaling to 0-100 range\n",
    "    \n",
    "#     return hex_code, rgb_code, hsl_code\n",
    "\n",
    "# # Example usage\n",
    "# image_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-deletebackground\\35-2_1_de_29.png'  # ระบุ path ของรูปภาพที่ต้องการใช้\n",
    "# hex_code, rgb_code, hsl_code = get_image_color_codes(image_path)\n",
    "\n",
    "# print(\"HEX Code:\", hex_code)\n",
    "# print(\"RGB Code:\", rgb_code)\n",
    "# print(\"HSL Code:\", hsl_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "workbook = openpyxl.load_workbook('after2.xlsx')\n",
    "sheet = workbook.active\n",
    "sheet['B1'] = 'Gender'\n",
    "sheet['C1'] = 'Brand'\n",
    "\n",
    "workbook.save('after2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_after = pd.read_excel('after.xlsx')\n",
    "df_after2 = pd.read_excel('after2.xlsx')\n",
    "\n",
    "# สร้าง dictionary จาก df_after โดยให้ Crop_File เป็น key และ Gender, Brand เป็น values\n",
    "crop_file_dict = df_after.set_index('Crop_File')[['Gender', 'Brand']].to_dict(orient='index')\n",
    "\n",
    "# แปลงทุกค่าใน df_after2 เป็น string\n",
    "df_after2 = df_after2.applymap(str)\n",
    "\n",
    "# ตรวจสอบและรับค่า Gender และ Brand จาก df_after แล้วนำมาใส่ใน df_after2\n",
    "for index, row in df_after2.iterrows():\n",
    "    image_name = row['ชื่อรูป'].split('_')[0]  # ดึง Crop_File จากชื่อรูป\n",
    "    if image_name in crop_file_dict:\n",
    "        gender_value = crop_file_dict[image_name]['Gender']\n",
    "        brand_value = crop_file_dict[image_name]['Brand']\n",
    "        if pd.notna(gender_value) and gender_value != '':\n",
    "            df_after2.at[index, 'Gender'] = gender_value\n",
    "        if pd.notna(brand_value):\n",
    "            df_after2.at[index, 'Brand'] = brand_value\n",
    "\n",
    "# เก็บผลลัพธ์ในไฟล์ output.xlsx\n",
    "df_after2.to_excel('after3.xlsx', index=False)\n",
    "print('Save file after3.xlsx success!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# ตั้งค่าพาธไปยังโฟลเดอร์ที่มีไฟล์ label ของ YOLO\n",
    "labels_folder = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\yolov5\\yolov5\\runs\\detect\\exp\\labels'\n",
    "\n",
    "# ตั้งค่าพาธไปยังโฟลเดอร์ที่มีรูปภาพต้นฉบับ\n",
    "original_images_folder = r'D:\\SWE62-363 Seminar for software Engineering\\Detect running shoes\\shoe detection\\my-own\\my_own_test3'\n",
    "\n",
    "def count_shoes_in_image(label_file_path, original_image_path):\n",
    "    # โหลดขนาดของรูปภาพต้นฉบับ\n",
    "    original_image = cv2.imread(original_image_path)\n",
    "    original_height, original_width, _ = original_image.shape\n",
    "\n",
    "    with open(label_file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    num_shoes = 0\n",
    "\n",
    "    # วนลูปผ่านทุกบรรทัดในไฟล์ label\n",
    "    for line in lines:\n",
    "        line_content = line.strip().split()\n",
    "        \n",
    "        # ตรวจสอบว่ามีข้อมูลครบหรือไม่ (ต้องมี 6 ค่า class_id, x_center, y_center, width, height, confidence)\n",
    "        if len(line_content) == 6:\n",
    "            class_id, x_center, y_center, width, height, confidence = map(float, line_content)\n",
    "            \n",
    "            # แปลงรูปแบบ YOLO เป็นพิกัดพิกเซล\n",
    "            x, y, w, h = x_center * original_width, y_center * original_height, width * original_width, height * original_height\n",
    "\n",
    "            # สมมติว่า class_id 0 หมายถึงรองเท้า (แก้ตามคอนฟิกเรื่องคลาสของคุณ)\n",
    "            if class_id == 0:\n",
    "                num_shoes += 1\n",
    "\n",
    "    return num_shoes\n",
    "\n",
    "def count_shoes_in_folder(labels_folder, original_images_folder):\n",
    "    num_total_shoes = 0\n",
    "\n",
    "    # วนลูปผ่านไฟล์ label ในโฟลเดอร์ labels\n",
    "    for label_file_name in os.listdir(labels_folder):\n",
    "        label_file_path = os.path.join(labels_folder, label_file_name)\n",
    "\n",
    "        # รับพาธไปยังไฟล์รูปภาพต้นฉบับที่เกี่ยวข้อง\n",
    "        original_image_name = label_file_name.replace('.txt', '.jpg')\n",
    "        original_image_path = os.path.join(original_images_folder, original_image_name)\n",
    "\n",
    "        # โหลดขนาดของรูปภาพต้นฉบับ\n",
    "        original_image = cv2.imread(original_image_path)\n",
    "        original_height, original_width, _ = original_image.shape\n",
    "\n",
    "        # นับจำนวนรองเท้าในรูปภาพปัจจุบัน\n",
    "        num_shoes_in_image = count_shoes_in_image(label_file_path, original_image_path)\n",
    "        num_total_shoes += num_shoes_in_image\n",
    "\n",
    "        print(f'จำนวนรองเท้าใน {original_image_name}: {num_shoes_in_image}')\n",
    "\n",
    "    print(f'จำนวนรองเท้าทั้งหมดในทุกรูป: {num_total_shoes}')\n",
    "\n",
    "# เรียกใช้ฟังก์ชันเพื่อนับจำนวนรองเท้าในทุกรูปภาพในโฟลเดอร์ที่ระบุ\n",
    "count_shoes_in_folder(labels_folder, original_images_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_list = sorted(os.listdir(folder_path), key=lambda x: (int(re.search(r'de_(\\d+)\\.png', x).group(1))))\n",
    "\n",
    "# for idx, filename in enumerate(file_list):\n",
    "#     if filename.endswith(\".png\"):\n",
    "#         # อ่านรูปภาพ\n",
    "#         img_path = os.path.join(folder_path, filename)\n",
    "#         img = cv2.imread(img_path)\n",
    "#         grid_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         grid_HSV = cv2.cvtColor(grid_RGB, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "#         # ทำการทำนายสี\n",
    "#         mask_1 = cv2.inRange(grid_HSV, lower_red, upper_red)\n",
    "#         mask_2 = cv2.inRange(grid_HSV, lower_yellow, upper_yellow)\n",
    "#         mask_3 = cv2.inRange(grid_HSV, lower_background, upper_background)\n",
    "#         mask_4 = cv2.inRange(grid_HSV, lower_white, upper_white)\n",
    "#         mask_5 = cv2.inRange(grid_HSV, lower_green, upper_green)\n",
    "#         mask_6 = cv2.inRange(grid_HSV, lower_light_blue, upper_light_blue)\n",
    "#         mask_7 = cv2.inRange(grid_HSV, lower_orange, upper_orange)\n",
    "#         mask_8 = cv2.inRange(grid_HSV, lower_pink, upper_pink)\n",
    "#         mask_9 = cv2.inRange(grid_HSV, lower_cyan, upper_cyan)\n",
    "\n",
    "#         object_mask = mask_1 + mask_2 + mask_4 + mask_5 + mask_6 + mask_7 + mask_8 + mask_9\n",
    "#         object_mask = cv2.bitwise_and(object_mask, 255 - mask_3)\n",
    "\n",
    "#         color_areas = {\n",
    "#             \"Red\": np.sum(mask_1),\n",
    "#             \"Yellow\": np.sum(mask_2),\n",
    "#             \"White\": np.sum(mask_4),\n",
    "#             \"Green\": np.sum(mask_5),\n",
    "#             \"Light Blue\": np.sum(mask_6),\n",
    "#             \"Orange\": np.sum(mask_7),\n",
    "#             \"Pink\": np.sum(mask_8),\n",
    "#             \"Cyan\": np.sum(mask_9)\n",
    "#         }\n",
    "\n",
    "#         total_color_value = sum(color_areas.values())\n",
    "\n",
    "#         if all(value == 0 for value in color_areas.values()):\n",
    "#             object_color = \"ไม่สามารถระบุสีได้\"\n",
    "#         elif total_color_value <= 50000:\n",
    "#             object_color = \"Black\"\n",
    "#         else:\n",
    "#             object_color = max(color_areas, key=color_areas.get)\n",
    "\n",
    "#         # ดึงข้อมูลจาก input_sheet\n",
    "#         gender = input_sheet.cell(row=idx + 2, column=2).value\n",
    "#         brand = input_sheet.cell(row=idx + 2, column=3).value\n",
    "\n",
    "#         # เพิ่มข้อมูลลงใน Excel\n",
    "#         sheet.append([filename, gender, brand, object_color])\n",
    "\n",
    "# # บันทึกไฟล์ Excel\n",
    "# workbook.save(r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\after2.xlsx')\n",
    "# print('Save file after2.xlse success!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import openpyxl\n",
    "# import re\n",
    "\n",
    "# # โหลดไฟล์ Excel ที่ต้องการดึงข้อมูล\n",
    "# input_workbook = openpyxl.load_workbook(r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\after.xlsx')\n",
    "# input_sheet = input_workbook.active\n",
    "\n",
    "# # สร้างไฟล์ Excel สำหรับเก็บข้อมูลใหม่\n",
    "# workbook = openpyxl.Workbook()\n",
    "# sheet = workbook.active\n",
    "# sheet['A1'] = 'ชื่อรูป'\n",
    "# sheet['B1'] = 'Gender'\n",
    "# sheet['C1'] = 'Brand'\n",
    "# sheet['D1'] = 'สีของรองเท้า'\n",
    "\n",
    "# # ระบุตำแหน่งของโฟลเดอร์ที่มีรูปภาพ\n",
    "# folder_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-deletebackground'\n",
    "\n",
    "# # กำหนดค่าสีต่างๆ\n",
    "# lower_red = np.array([0, 150, 50])\n",
    "# upper_red = np.array([10, 255, 255])\n",
    "# lower_yellow = np.array([25, 150, 50])\n",
    "# upper_yellow = np.array([35, 255, 255])\n",
    "# lower_background = np.array([0, 0, 0])\n",
    "# upper_background = np.array([250, 255, 30])\n",
    "# lower_white = np.array([0, 0, 255])\n",
    "# upper_white = np.array([0, 0, 255])\n",
    "# lower_green = np.array([45, 150, 50])\n",
    "# upper_green = np.array([65, 255, 255])\n",
    "# lower_light_blue = np.array([95, 150, 0])\n",
    "# upper_light_blue = np.array([110, 255, 255])\n",
    "# lower_orange = np.array([15, 150, 0])\n",
    "# upper_orange = np.array([25, 255, 255])\n",
    "# lower_pink = np.array([145, 150, 0])\n",
    "# upper_pink = np.array([155, 255, 255])\n",
    "# lower_cyan = np.array([85, 150, 0])\n",
    "# upper_cyan = np.array([95, 255, 255])\n",
    "\n",
    "# # วนลูปผ่านทุกรูปภาพในโฟลเดอร์\n",
    "# # เรียงลำดับไฟล์ตามตัวเลขที่อยู่หลัง 'de_' และก่อน '.png'\n",
    "# file_list = sorted(os.listdir(folder_path), key=lambda x: (int(re.search(r'de_(\\d+)\\.png', x).group(1))))\n",
    "\n",
    "# for idx, filename in enumerate(file_list):\n",
    "#     if filename.endswith(\".png\"):\n",
    "#         # อ่านรูปภาพ\n",
    "#         img_path = os.path.join(folder_path, filename)\n",
    "#         img = cv2.imread(img_path)\n",
    "#         grid_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         grid_HSV = cv2.cvtColor(grid_RGB, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "#         # ทำการทำนายสี\n",
    "#         mask_1 = cv2.inRange(grid_HSV, lower_red, upper_red)\n",
    "#         mask_2 = cv2.inRange(grid_HSV, lower_yellow, upper_yellow)\n",
    "#         mask_3 = cv2.inRange(grid_HSV, lower_background, upper_background)\n",
    "#         mask_4 = cv2.inRange(grid_HSV, lower_white, upper_white)\n",
    "#         mask_5 = cv2.inRange(grid_HSV, lower_green, upper_green)\n",
    "#         mask_6 = cv2.inRange(grid_HSV, lower_light_blue, upper_light_blue)\n",
    "#         mask_7 = cv2.inRange(grid_HSV, lower_orange, upper_orange)\n",
    "#         mask_8 = cv2.inRange(grid_HSV, lower_pink, upper_pink)\n",
    "#         mask_9 = cv2.inRange(grid_HSV, lower_cyan, upper_cyan)\n",
    "\n",
    "#         object_mask = mask_1 + mask_2 + mask_4 + mask_5 + mask_6 + mask_7 + mask_8 + mask_9\n",
    "#         object_mask = cv2.bitwise_and(object_mask, 255 - mask_3)\n",
    "\n",
    "#         color_areas = {\n",
    "#             \"Red\": np.sum(mask_1),\n",
    "#             \"Yellow\": np.sum(mask_2),\n",
    "#             \"White\": np.sum(mask_4),\n",
    "#             \"Green\": np.sum(mask_5),\n",
    "#             \"Light Blue\": np.sum(mask_6),\n",
    "#             \"Orange\": np.sum(mask_7),\n",
    "#             \"Pink\": np.sum(mask_8),\n",
    "#             \"Cyan\": np.sum(mask_9)\n",
    "#         }\n",
    "\n",
    "#         total_color_value = sum(color_areas.values())\n",
    "\n",
    "#         if all(value == 0 for value in color_areas.values()):\n",
    "#             object_color = \"ไม่สามารถระบุสีได้\"\n",
    "#         elif total_color_value <= 50000:\n",
    "#             object_color = \"Black\"\n",
    "#         else:\n",
    "#             object_color = max(color_areas, key=color_areas.get)\n",
    "\n",
    "#         # ดึงข้อมูลจาก input_sheet\n",
    "#         gender = input_sheet.cell(row=idx + 2, column=2).value\n",
    "#         brand = input_sheet.cell(row=idx + 2, column=3).value\n",
    "\n",
    "#         # เพิ่มข้อมูลลงใน Excel\n",
    "#         sheet.append([filename, gender, brand, object_color])\n",
    "\n",
    "# # บันทึกไฟล์ Excel\n",
    "# workbook.save(r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\after2.xlsx')\n",
    "# print('Save file after2.xlse success!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # กำหนดที่อยู่ของรูปภาพ\n",
    "# image_path = 'F:\\\\intern\\\\model_shoes_detection\\\\Detect running shoes\\\\shoe detection\\\\Real_1\\\\Shoes-crop\\\\3-2_1.jpg'\n",
    "\n",
    "# # อ่านรูปภาพ\n",
    "# image = cv2.imread(image_path)\n",
    "\n",
    "# # ตรวจสอบว่าสามารถอ่านรูปภาพได้\n",
    "# if image is not None:\n",
    "#     # สร้างลิสต์เพื่อเก็บค่าสี RGB\n",
    "#     rgb_colors = []\n",
    "\n",
    "#     # วนลูปผ่านทุกพิกเซลในรูปภาพ\n",
    "#     height, width, _ = image.shape\n",
    "#     for y in range(height):\n",
    "#         for x in range(width):\n",
    "#             # ดึงค่าสีของแต่ละพิกเซล (BGR)\n",
    "#             b, g, r = image[y, x]\n",
    "\n",
    "#             # เพิ่มค่าสี RGB ลงในลิสต์\n",
    "#             rgb_colors.append((r, g, b))\n",
    "\n",
    "#     # บันทึกข้อมูลสีลงในไฟล์ .txt\n",
    "#     output_file = 'colors.txt'\n",
    "#     with open(output_file, 'w') as file:\n",
    "#         for color in rgb_colors:\n",
    "#             file.write(f\"{color[0]}, {color[1]}, {color[2]}\\n\")\n",
    "\n",
    "#     print(f\"บันทึกสีลงในไฟล์ {output_file} เรียบร้อยแล้ว\")\n",
    "# else:\n",
    "#     print(\"ไม่สามารถอ่านรูปภาพได้\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# # กำหนดโฟลเดอร์ที่มีรูปภาพ\n",
    "# folder_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-crop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # รายการเก็บค่า mean color ของแต่ละรูป\n",
    "# mean_colors = []\n",
    "\n",
    "# # วนลูปผ่านไฟล์รูปทั้งหมดในโฟลเดอร์\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "#         # อ่านภาพ\n",
    "#         image_path = os.path.join(folder_path, filename)\n",
    "#         image = cv2.imread(image_path)\n",
    "        \n",
    "#         # ตรวจสอบว่าสามารถอ่านรูปภาพได้\n",
    "#         if image is not None:\n",
    "#             # คำนวณค่าสีเฉลี่ย\n",
    "#             mean_color = np.mean(image, axis=(0, 1))\n",
    "#             mean_colors.append(mean_color)\n",
    "#         else:\n",
    "#             print(f\"ไม่สามารถอ่านรูปภาพ {filename} ได้\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # บันทึกผลลัพธ์เป็นไฟล์ .txt\n",
    "# output_file = 'mean_colors.txt'\n",
    "# with open(output_file, 'w') as file:\n",
    "#     for mean_color in mean_colors:\n",
    "#         # แปลงสีจาก BGR เป็น RGB และเขียนลงในไฟล์ในรูปแบบของข้อความ\n",
    "#         mean_color_rgb = mean_color[::-1]\n",
    "#         file.write(f\"Mean Color (RGB): {mean_color_rgb[0]:.2f}, {mean_color_rgb[1]:.2f}, {mean_color_rgb[2]:.2f}\\n\")\n",
    "\n",
    "# print(f\"บันทึกค่า mean color ลงในไฟล์ {output_file} เรียบร้อยแล้ว\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import requests\n",
    "\n",
    "# api_key = '52DC8T7NrkYcjE9Hmfk5CVJq'  # ใส่ API Key ที่คุณได้รับจาก Remove.bg\n",
    "# input_image_folder = 'F:\\\\intern\\\\model_shoes_detection\\\\Detect running shoes\\\\shoe detection\\\\Real_1\\\\Shoes-crop'\n",
    "# output_image_folder = 'F:\\\\intern\\\\model_shoes_detection\\\\Detect running shoes\\\\shoe detection\\\\Real_1\\\\Shoes-removebg'\n",
    "\n",
    "# # Create the output folder if it doesn't exist\n",
    "# os.makedirs(output_image_folder, exist_ok=True)\n",
    "\n",
    "# # Iterate through the input images\n",
    "# for image_filename in os.listdir(input_image_folder):\n",
    "#     if image_filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "#         image_path = os.path.join(input_image_folder, image_filename)\n",
    "\n",
    "#         # Create the API request\n",
    "#         response = requests.post(\n",
    "#             'https://api.remove.bg/v1.0/removebg',\n",
    "#             headers={'X-Api-Key': api_key},\n",
    "#             files={'image_url': (None, 'file:///' + os.path.abspath(image_path))}\n",
    "#         )\n",
    "\n",
    "#         # Check the status of the request\n",
    "#         if response.status_code == requests.codes.ok:\n",
    "#             # Save the resulting image with the background removed\n",
    "#             output_path = os.path.join(output_image_folder, image_filename)\n",
    "#             with open(output_path, 'wb') as out:\n",
    "#                 out.write(response.content)\n",
    "#             print(f'Background removed successfully for {image_filename}')\n",
    "#         else:\n",
    "#             print(f'Error removing background for {image_filename}: {response.status_code}')\n",
    "\n",
    "# print(\"Background removal completed. Resulting images saved to:\", output_image_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision.models as models\n",
    "\n",
    "# model_save_path = 'F:/intern/model_shoes_detection/Detect running shoes/shoe detection/resnet50.pth'\n",
    "\n",
    "# # ดาวน์โหลดโมเดล ResNet-50\n",
    "# resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "# torch.save(resnet50.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "# import torch\n",
    "# import torchvision.models.detection as detection_models\n",
    "# import torchvision.transforms as transforms\n",
    "# import numpy as np\n",
    "\n",
    "# # Define the path to the directory containing the models\n",
    "# model_dir = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection'\n",
    "\n",
    "# # Load the pre-trained Faster R-CNN model\n",
    "# faster_rcnn_model_path = os.path.join(model_dir, 'faster_rcnn_model.pth')\n",
    "# faster_rcnn_model = detection_models.fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "# faster_rcnn_model.load_state_dict(torch.load(faster_rcnn_model_path))\n",
    "# faster_rcnn_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# # Load the pre-trained ResNet-50 model for color classification\n",
    "# resnet50_model_path = os.path.join(model_dir, 'resnet50.pth')\n",
    "# resnet50 = torch.hub.load('pytorch/vision', 'resnet50', pretrained=False)\n",
    "# resnet50.load_state_dict(torch.load(resnet50_model_path))\n",
    "# resnet50.eval()  # Set the ResNet-50 model to evaluation mode\n",
    "\n",
    "# # Define a transformation to preprocess images for ResNet-50\n",
    "# preprocess_resnet = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors_List = { # 84 87 58\n",
    "\n",
    "#     'Black' : (0,0,0), # 84 87 58\n",
    "#     'White' : (255,255,255), # \n",
    "#     'Red' : (255,0,0),\n",
    "#     'Lime' : (0,255,0),\n",
    "#     'Blue' : (0,0,255),\n",
    "#     'Yellow' : (255,255,0),\n",
    "#     'Aqua' : (0,255,255),\n",
    "#     'Magenta' : (255,0,255),\n",
    "#     'Silver' : (192,192,192),\n",
    "#     'Gray' : (128,128,128),\n",
    "#     'Maroon' : (128,0,0),\n",
    "#     'Dark red' : (139,0,0),\n",
    "#     'Brown' : (165,42,42),\n",
    "#     'Firebrick' : (178,34,34),\n",
    "#     'crimson' : (220,20,60),\n",
    "#     'tomato' : (255,99,71),\n",
    "#     'coral' : (255,127,80),\n",
    "#     'indian red' : (205,92,92),\n",
    "#     'light coral' : (240,128,128),\n",
    "#     'dark salmon' : (233,150,122),\n",
    "#     'salmon' : (250,128,114),\n",
    "#     'light salmon' : (255,160,122),\n",
    "#     'orange red' : (255,69,0),\n",
    "#     'dark orange' : (255,140,0),\n",
    "#     'orange' : \t(255,165,0),\n",
    "#     'gold' : \t(255,215,0),\n",
    "#     'dark golden rod' : \t(184,134,11),\n",
    "#     'golden rod' : (218,165,32),\n",
    "#     'pale golden rod' : (238,232,170),\n",
    "#     'dark khaki' : (189,183,107),\n",
    "#     'khaki' : (240,230,140),\n",
    "#     'olive' : (128,128,0),\n",
    "#     'yellow green' : (154,205,50),\n",
    "#     'dark olive green' : (85,107,47),\n",
    "#     'olive drab' : (107,142,35),\n",
    "#     'lawn green' : (124,252,0),\n",
    "#     'chartreuse' : (127,255,0),\n",
    "#     'green yellow' : (173,255,47),\n",
    "#     'dark green' : (0,100,0),\n",
    "#     'green' : (0,128,0),\n",
    "#     'forest green' : (34,139,34),\n",
    "#     'lime' : (0,255,0),\n",
    "#     'lime green' : (50,205,50),\n",
    "#     'light green' : (144,238,144),\n",
    "#     'pale green' : (152,251,152),\n",
    "#     'dark sea green' : (143,188,143),\n",
    "#     'medium spring green' : (0,250,154),\n",
    "#     'spring green' : (0,255,127),\n",
    "#     'sea green' : (46,139,87),\n",
    "#     'medium aqua marine' : (102,205,170),\n",
    "#     'medium sea green' : (60,179,113),\n",
    "#     'light sea green' : (32,178,170),\n",
    "#     'dark slate gray' : (47,79,79),\n",
    "#     'teal' : (0,128,128),\n",
    "#     'dark cyan' : (0,139,139),\n",
    "#     'aqua' : (0,255,255),\n",
    "#     'cyan' : (0,255,255),\n",
    "#     'light cyan' : (224,255,255),\n",
    "#     'dark turquoise' : (0,206,209),\n",
    "#     'turquoise' : (64,224,208),\n",
    "#     'pale turquoise' : (175,238,238),\n",
    "#     'aqua marine' : (127,255,212),\n",
    "#     'powder blue' : (176,224,230),\n",
    "#     'cadet blue' : (95,158,160),\n",
    "#     'steel blue' : (70,130,180),\n",
    "#     'corn flower blue' : (100,149,237),\n",
    "#     'deep sky blue' : (0,191,255),\n",
    "#     'dodger blue' : (30,144,255),\n",
    "#     'light blue' : (173,216,230),\n",
    "#     'sky blue' : (135,206,235),\n",
    "#     'light sky blue' : (135,206,250),\n",
    "#     'midnight blue' : (25,25,112),\n",
    "#     'navy' : (0,0,128),\n",
    "#     'dark blue' : (0,0,139),\n",
    "#     'medium blue' : (0,0,205),\n",
    "#     'blue' : (0,0,255),\n",
    "#     'royal blue' : (65,105,225),\n",
    "#     'blue violet' : (138,43,226),\n",
    "#     'indigo' : (75,0,130),\n",
    "#     'dark slate blue' : (72,61,139),\n",
    "#     'slate blue' : (106,90,205),\n",
    "#     'medium slate blue' : (123,104,238),\n",
    "#     'medium purple' : (147,112,219),\n",
    "#     'dark magenta' : (139,0,139),\n",
    "#     'dark violet' : (148,0,211),\n",
    "#     'dark orchid' : (153,50,204),\n",
    "#     'medium orchid' : (186,85,211),\n",
    "#     'purple' : (128,0,128),\n",
    "#     'thistle' : (216,191,216),\n",
    "#     'plum' : (221,160,221),\n",
    "#     'violet' : (238,130,238),\n",
    "#     'magenta / fuchsia' : (255,0,255),\n",
    "#     'orchid' : (218,112,214),\n",
    "#     'medium violet red' : (199,21,133),\n",
    "#     'pale violet red' : (219,112,147),\n",
    "#     'deep pink' : (255,20,147),\n",
    "#     'hot pink' : (255,105,180),\n",
    "#     'light pink' : (255,182,193),\n",
    "#     'pink' : (255,192,203),\n",
    "#     'antique white' : (250,235,215),\n",
    "#     'beige' : (245,245,220),\n",
    "#     'bisque' : (255,228,196),\n",
    "#     'blanched almond' : (255,235,205),\n",
    "#     'wheat' : (245,222,179),\n",
    "#     'corn silk' : (255,248,220),\n",
    "#     'lemon chiffon' : (255,250,205),\n",
    "#     'light golden rod yellow' : (250,250,210),\n",
    "#     'light yellow' : (255,255,224),\n",
    "#     'saddle brown' : (139,69,19),\n",
    "#     'sienna' : (160,82,45),\n",
    "#     'chocolate' : (210,105,30),\n",
    "#     'peru' : (205,133,63),\n",
    "#     'sandy brown' : (244,164,96),\n",
    "#     'burly wood' : (222,184,135),\n",
    "#     'tan' : (210,180,140),\n",
    "#     'rosy brown' : (188,143,143),\n",
    "#     'moccasin' : (255,228,181),\n",
    "#     'navajo white' : (255,222,173),\n",
    "#     'peach puff' : (255,218,185),\n",
    "#     'misty rose' : (255,228,225),\n",
    "#     'lavender blush' : (255,240,245),\n",
    "#     'linen' : (250,240,230),\n",
    "#     'old lace' : (253,245,230),\n",
    "#     'papaya whip' : (255,239,213),\n",
    "#     'sea shell' : (255,245,238),\n",
    "#     'mint cream' : (245,255,250),\n",
    "#     'slate gray' : (112,128,144),\n",
    "#     'light slate gray' : (119,136,153),\n",
    "#     'light steel blue' : (176,196,222),\n",
    "#     'lavender' : (230,230,250),\n",
    "#     'floral white' : (255,250,240),\n",
    "#     'alice blue' : (240,248,255),\n",
    "#     'ghost white' : (248,248,255),\n",
    "#     'honeydew' : (240,255,240),\n",
    "#     'ivory' : (255,255,240),\n",
    "#     'azure' : (240,255,255),\n",
    "#     'snow' : (255,250,250),\n",
    "#     'dim gray / dim grey' : (105,105,105),\n",
    "#     'gray / grey' : (128,128,128),\n",
    "#     'dark gray / dark grey' : (169,169,169),\n",
    "#     'silver' : (192,192,192),\n",
    "#     'light gray / light grey' : (211,211,211),\n",
    "#     'gainsboro' : (220,220,220),\n",
    "#     'white smoke' : (245,245,245),\n",
    "  \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Create a list to store the detected and classified shoes\n",
    "# detected_and_classified_shoes = []\n",
    "\n",
    "# # Specify the directory containing shoe images\n",
    "# image_dir = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\Shoes-removebg'\n",
    "\n",
    "# for file_name in os.listdir(image_dir):\n",
    "#     if file_name.lower().endswith('.jpg'):\n",
    "#         image_path = os.path.join(image_dir, file_name)\n",
    "\n",
    "#         # Detect objects in the image using Faster R-CNN\n",
    "#         image = Image.open(image_path).convert('RGB')\n",
    "#         image_tensor = transforms.ToTensor()(image).unsqueeze(0)\n",
    "#         with torch.no_grad():\n",
    "#             detections = faster_rcnn_model(image_tensor)\n",
    "\n",
    "#         # Assuming that detections is a dictionary with 'boxes' and 'labels' keys\n",
    "#         # For simplicity, let's assume we are interested in the first detected object\n",
    "#         if len(detections[0]['labels']) > 0:\n",
    "#             box = detections[0]['boxes'][0]\n",
    "#             label = detections[0]['labels'][0].item()\n",
    "\n",
    "#             # Crop the detected object\n",
    "#             box = box.cpu().numpy()  # Convert box coordinates to a NumPy array\n",
    "#             cropped_image = image.crop((box[0], box[1], box[2], box[3]))\n",
    "\n",
    "#             # Preprocess the cropped image for ResNet-50\n",
    "#             cropped_image_tensor = preprocess_resnet(cropped_image)\n",
    "#             cropped_image_tensor = cropped_image_tensor.unsqueeze(0)\n",
    "\n",
    "#             # Perform color classification using ResNet-50\n",
    "#             with torch.no_grad():\n",
    "#                 output = resnet50(cropped_image_tensor)\n",
    "\n",
    "#             _, predicted_class = output.max(1)\n",
    "#             color_index = predicted_class.item()\n",
    "\n",
    "#             color_list = list(Colors_List.keys())\n",
    "\n",
    "#             if color_index < len(color_list):\n",
    "#                 predicted_color = color_list[color_index]\n",
    "#             else:\n",
    "#                 predicted_color = \"Unknown Color\"\n",
    "\n",
    "#             # Append the detected and classified shoe information\n",
    "#             detected_and_classified_shoes.append({\n",
    "#                 'Image_File': file_name,\n",
    "#                 'Label': label,\n",
    "#                 'Box': box.tolist(),\n",
    "#                 'Predicted_Color': predicted_color\n",
    "#             })\n",
    "\n",
    "#             # Print the message for object detection and color classification\n",
    "#             print(f'Object detected in {file_name}: {label}')\n",
    "#             print(f'Color classified for {file_name}: {predicted_color}')\n",
    "\n",
    "# # Print or process the detected and classified shoes as needed\n",
    "# for shoe in detected_and_classified_shoes:\n",
    "#     print(f'Image File: {shoe[\"Image_File\"]}, Label: {shoe[\"Label\"]}, Box: {shoe[\"Box\"]}, Predicted Color: {shoe[\"Predicted_Color\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read data from 'after.xlsx'\n",
    "# excel_data = pd.read_excel('after.xlsx')\n",
    "\n",
    "# # Create a DataFrame for shoe detection results\n",
    "# df_detection = pd.DataFrame(detected_and_classified_shoes)\n",
    "# df_detection = df_detection.rename(columns={'Image_File': 'Crop_File', 'Predicted_Color': 'Color'})\n",
    "\n",
    "# # Extract 'Gender' and 'Brand' data from 'after.xlsx'\n",
    "# excel_data = excel_data[['Gender', 'Brand']]\n",
    "\n",
    "# # Merge data from shoe detection and 'after.xlsx'\n",
    "# result_df = pd.concat([df_detection, excel_data], axis=1)\n",
    "\n",
    "# output_path = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\shoe detection\\Real_1\\after2.xlsx'\n",
    "# result_df.to_excel(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shoes_color_data = {'Crop_File': [], 'Color': []}\n",
    "\n",
    "# # Specify the directory containing shoe images\n",
    "# image_dir = 'F:/intern/model_shoes_detection/Detect running shoes/shoe detection/Real_1/Shoes-crop/'\n",
    "\n",
    "# # Iterate through the image files in the directory\n",
    "# for file_name in os.listdir(image_dir):\n",
    "#     if file_name.lower().endswith('.jpg'):\n",
    "#         image_path = os.path.join(image_dir, file_name)\n",
    "#         predicted_color = predict_color(image_path)\n",
    "#         shoes_color_data['Crop_File'].append(file_name)\n",
    "#         shoes_color_data['Color'].append(predicted_color)\n",
    "\n",
    "# # Read the original DataFrame from 'after.xlsx'\n",
    "# original_df = pd.read_excel('after.xlsx')\n",
    "\n",
    "# # Merge the color predictions DataFrame with the original DataFrame based on 'Crop_File'\n",
    "# merged_df = original_df.merge(pd.DataFrame(shoes_color_data), on='Crop_File', how='left')\n",
    "\n",
    "# # Save the updated DataFrame to 'after2.xlsx'\n",
    "# merged_df.to_excel('after2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from torchvision import transforms\n",
    "# import numpy as np\n",
    "# import math\n",
    "# import torch\n",
    "\n",
    "# def find_most_frequent_color(image_path):\n",
    "#     # Load the image\n",
    "#     image = Image.open(image_path)\n",
    "    \n",
    "#     # Convert the image to RGB color space\n",
    "#     image = image.convert('RGB')\n",
    "    \n",
    "#     # Get the pixel data\n",
    "#     pixels = image.getdata()\n",
    "    \n",
    "#     # Count the frequency of each color\n",
    "#     color_counter = Counter(pixels)\n",
    "    \n",
    "#     # Find the most common color and its frequency\n",
    "#     most_common_color = color_counter.most_common(1)[0]\n",
    "    \n",
    "#     return most_common_color[0]\n",
    "\n",
    "# def find_closest_color(rgb_value, color_list):\n",
    "#     min_distance = math.inf\n",
    "#     closest_color = None\n",
    "\n",
    "#     for color_name in color_list:\n",
    "#         color_rgb = color_list[color_name]\n",
    "#         # Calculate the Euclidean distance between the RGB values\n",
    "#         distance = math.sqrt(sum((c1 - c2) ** 2 for c1, c2 in zip(rgb_value, color_rgb)))\n",
    "#         if distance < min_distance:\n",
    "#             min_distance = distance\n",
    "#             closest_color = color_name\n",
    "\n",
    "#     return closest_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors_List = { # 84 87 58\n",
    "\n",
    "#     'Black' : (0,0,0), # 84 87 58\n",
    "#     'White' : (255,255,255), # \n",
    "#     'Red' : (255,0,0),\n",
    "#     'Lime' : (0,255,0),\n",
    "#     'Blue' : (0,0,255),\n",
    "#     'Yellow' : (255,255,0),\n",
    "#     'Aqua' : (0,255,255),\n",
    "#     'Magenta' : (255,0,255),\n",
    "#     'Silver' : (192,192,192),\n",
    "#     'Gray' : (128,128,128),\n",
    "#     'Maroon' : (128,0,0),\n",
    "#     'Dark red' : (139,0,0),\n",
    "#     'Brown' : (165,42,42),\n",
    "#     'Firebrick' : (178,34,34),\n",
    "#     'crimson' : (220,20,60),\n",
    "#     'tomato' : (255,99,71),\n",
    "#     'coral' : (255,127,80),\n",
    "#     'indian red' : (205,92,92),\n",
    "#     'light coral' : (240,128,128),\n",
    "#     'dark salmon' : (233,150,122),\n",
    "#     'salmon' : (250,128,114),\n",
    "#     'light salmon' : (255,160,122),\n",
    "#     'orange red' : (255,69,0),\n",
    "#     'dark orange' : (255,140,0),\n",
    "#     'orange' : \t(255,165,0),\n",
    "#     'gold' : \t(255,215,0),\n",
    "#     'dark golden rod' : \t(184,134,11),\n",
    "#     'golden rod' : (218,165,32),\n",
    "#     'pale golden rod' : (238,232,170),\n",
    "#     'dark khaki' : (189,183,107),\n",
    "#     'khaki' : (240,230,140),\n",
    "#     'olive' : (128,128,0),\n",
    "#     'yellow green' : (154,205,50),\n",
    "#     'dark olive green' : (85,107,47),\n",
    "#     'olive drab' : (107,142,35),\n",
    "#     'lawn green' : (124,252,0),\n",
    "#     'chartreuse' : (127,255,0),\n",
    "#     'green yellow' : \t(173,255,47),\n",
    "#     'dark green' : (0,100,0),\n",
    "#     'green' : (0,128,0),\n",
    "#     'forest green' : (34,139,34),\n",
    "#     'lime' : (0,255,0),\n",
    "#     'lime green' : (50,205,50),\n",
    "#     'light green' : (144,238,144),\n",
    "#     'pale green' : (152,251,152),\n",
    "#     'dark sea green' : (143,188,143),\n",
    "#     'medium spring green' : (0,250,154),\n",
    "#     'spring green' : (0,255,127),\n",
    "#     'sea green' : (46,139,87),\n",
    "#     'medium aqua marine' : (102,205,170),\n",
    "#     'medium sea green' : (60,179,113),\n",
    "#     'light sea green' : (32,178,170),\n",
    "#     'dark slate gray' : (47,79,79),\n",
    "#     'teal' : (0,128,128),\n",
    "#     'dark cyan' : (0,139,139),\n",
    "#     'aqua' : (0,255,255),\n",
    "#     'cyan' : (0,255,255),\n",
    "#     'light cyan' : (224,255,255),\n",
    "#     'dark turquoise' : (0,206,209),\n",
    "#     'turquoise' : (64,224,208),\n",
    "#     'pale turquoise' : (175,238,238),\n",
    "#     'aqua marine' : (127,255,212),\n",
    "#     'powder blue' : (176,224,230),\n",
    "#     'cadet blue' : (95,158,160),\n",
    "#     'steel blue' : (70,130,180),\n",
    "#     'corn flower blue' : (100,149,237),\n",
    "#     'deep sky blue' : (0,191,255),\n",
    "#     'dodger blue' : (30,144,255),\n",
    "#     'light blue' : (173,216,230),\n",
    "#     'sky blue' : (135,206,235),\n",
    "#     'light sky blue' : (135,206,250),\n",
    "#     'midnight blue' : (25,25,112),\n",
    "#     'navy' : (0,0,128),\n",
    "#     'dark blue' : (0,0,139),\n",
    "#     'medium blue' : (0,0,205),\n",
    "#     'blue' : (0,0,255),\n",
    "#     'royal blue' : (65,105,225),\n",
    "#     'blue violet' : (138,43,226),\n",
    "#     'indigo' : (75,0,130),\n",
    "#     'dark slate blue' : (72,61,139),\n",
    "#     'slate blue' : (106,90,205),\n",
    "#     'medium slate blue' : (123,104,238),\n",
    "#     'medium purple' : (147,112,219),\n",
    "#     'dark magenta' : (139,0,139),\n",
    "#     'dark violet' : (148,0,211),\n",
    "#     'dark orchid' : (153,50,204),\n",
    "#     'medium orchid' : (186,85,211),\n",
    "#     'purple' : (128,0,128),\n",
    "#     'thistle' : (216,191,216),\n",
    "#     'plum' : (221,160,221),\n",
    "#     'violet' : (238,130,238),\n",
    "#     'magenta / fuchsia' : (255,0,255),\n",
    "#     'orchid' : (218,112,214),\n",
    "#     'medium violet red' : (199,21,133),\n",
    "#     'pale violet red' : (219,112,147),\n",
    "#     'deep pink' : (255,20,147),\n",
    "#     'hot pink' : (255,105,180),\n",
    "#     'light pink' : (255,182,193),\n",
    "#     'pink' : (255,192,203),\n",
    "#     'antique white' : (250,235,215),\n",
    "#     'beige' : (245,245,220),\n",
    "#     'bisque' : (255,228,196),\n",
    "#     'blanched almond' : (255,235,205),\n",
    "#     'wheat' : (245,222,179),\n",
    "#     'corn silk' : (255,248,220),\n",
    "#     'lemon chiffon' : (255,250,205),\n",
    "#     'light golden rod yellow' : (250,250,210),\n",
    "#     'light yellow' : (255,255,224),\n",
    "#     'saddle brown' : (139,69,19),\n",
    "#     'sienna' : (160,82,45),\n",
    "#     'chocolate' : (210,105,30),\n",
    "#     'peru' : (205,133,63),\n",
    "#     'sandy brown' : (244,164,96),\n",
    "#     'burly wood' : (222,184,135),\n",
    "#     'tan' : (210,180,140),\n",
    "#     'rosy brown' : (188,143,143),\n",
    "#     'moccasin' : (255,228,181),\n",
    "#     'navajo white' : (255,222,173),\n",
    "#     'peach puff' : (255,218,185),\n",
    "#     'misty rose' : (255,228,225),\n",
    "#     'lavender blush' : (255,240,245),\n",
    "#     'linen' : (250,240,230),\n",
    "#     'old lace' : (253,245,230),\n",
    "#     'papaya whip' : (255,239,213),\n",
    "#     'sea shell' : (255,245,238),\n",
    "#     'mint cream' : (245,255,250),\n",
    "#     'slate gray' : (112,128,144),\n",
    "#     'light slate gray' : (119,136,153),\n",
    "#     'light steel blue' : (176,196,222),\n",
    "#     'lavender' : (230,230,250),\n",
    "#     'floral white' : (255,250,240),\n",
    "#     'alice blue' : (240,248,255),\n",
    "#     'ghost white' : (248,248,255),\n",
    "#     'honeydew' : (240,255,240),\n",
    "#     'ivory' : (255,255,240),\n",
    "#     'azure' : (240,255,255),\n",
    "#     'snow' : (255,250,250),\n",
    "#     'dim gray / dim grey' : (105,105,105),\n",
    "#     'gray / grey' : (128,128,128),\n",
    "#     'dark gray / dark grey' : (169,169,169),\n",
    "#     'silver' : (192,192,192),\n",
    "#     'light gray / light grey' : (211,211,211),\n",
    "#     'gainsboro' : (220,220,220),\n",
    "#     'white smoke' : (245,245,245),\n",
    "  \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_gender_and_brand(file_name):\n",
    "#     # ตัดข้อความ 'Crop_' และ '.JPG' จากชื่อไฟล์\n",
    "#     name = file_name.replace('Crop_', '').replace('.JPG', '')\n",
    "    \n",
    "#     # แยกชื่อเข้าด้วยเครื่องหมาย '-'\n",
    "#     parts = name.split('-')\n",
    "    \n",
    "#     if len(parts) == 2:\n",
    "#         gender, brand = parts\n",
    "#         if gender.lower() == 'male' or gender.lower() == 'female':\n",
    "#             return gender.capitalize(), brand  # Capitalize the gender\n",
    "#     return 'Unknown', brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from collections import Counter\n",
    "# import pandas as pd\n",
    "\n",
    "# def count_shoe_colors(image_path, threshold=100):\n",
    "#     rgb = find_most_frequent_color(image_path)\n",
    "#     closest_clr = find_closest_color(rgb, Colors_List)\n",
    "#     print(f\"Image: {image_path}, RGB: {rgb}, Closest Color: {closest_clr}\")\n",
    "#     return f\"{closest_clr} {rgb}\", closest_clr\n",
    "\n",
    "# shoes_color_data = {}\n",
    "\n",
    "# for file_name in os.listdir('F:\\\\intern\\\\model_shoes_detection\\\\Detect running shoes\\\\shoe detection\\\\Real_1\\\\Shoes-crop\\\\'):\n",
    "#     if file_name.lower().endswith('jpg'):\n",
    "#         image_path = os.path.join('F:\\\\intern\\\\model_shoes_detection\\\\Detect running shoes\\\\shoe detection\\\\Real_1\\\\Shoes-crop\\\\', file_name)\n",
    "#         color = count_shoe_colors(image_path)\n",
    "#         shoes_color_data[file_name] = color\n",
    "\n",
    "# color_counts = Counter(shoes_color_data.values())\n",
    "\n",
    "# new_data = {'Crop_File': [], 'Gender': [], 'Brand': [], 'Color': [], 'Counts': []}\n",
    "\n",
    "# for file_name, color in shoes_color_data.items():\n",
    "#     if color is not None:\n",
    "#         gender, brand = get_gender_and_brand(file_name)\n",
    "#         color_info, color_name = count_shoe_colors(image_path)  # Get color name and RGB value\n",
    "#         count = color_counts[color_name]\n",
    "#         new_data['Crop_File'].append(file_name)\n",
    "#         new_data['Gender'].append(gender)\n",
    "#         new_data['Brand'].append(brand)\n",
    "#         new_data['Color'].append(color_info)  # Store color name and RGB value\n",
    "#         new_data['Counts'].append(f'{count} คู่')\n",
    "        \n",
    "# original_df = pd.read_excel('after.xlsx')\n",
    "\n",
    "# new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# new_df['Gender'] = original_df['Gender']\n",
    "# new_df['Brand'] = original_df['Brand']\n",
    "\n",
    "# new_df.to_excel('after2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolov5 = r'F:\\intern\\model_shoes_detection\\Detect running shoes\\yolov5\\yolov5'\n",
    "# os.chdir(yolov5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python detect.py --weights \"F:\\\\intern\\\\model_shoes_detection\\\\Detect running shoes\\\\yolov5m_Objects365.pt\" --source \"F:\\\\intern\\\\model_shoes_detection\\\\Detect running shoes\\\\shoe detection\\\\my-own\\\\my_own_test3\" --imgsz 416 --conf 0.7 --save-txt --save-conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# # กำหนดตำแหน่งของไฟล์ labels\n",
    "# labels_folder = \"F:\\\\intern\\\\model_shoes_detection\\\\Detect running shoes\\\\yolov5\\\\yolov5\\\\runs\\\\detect\\\\exp3\\\\\"\n",
    "\n",
    "# # สร้างโครงข้อมูลสำหรับบันทึกข้อมูล\n",
    "# data = {'Image': [], 'Color': [], 'Gender': [], 'Num_People': []}\n",
    "\n",
    "# for filename in os.listdir(labels_folder):\n",
    "#     if filename.endswith(\".txt\"):\n",
    "#         with open(os.path.join(labels_folder, filename), 'r') as file:\n",
    "#             lines = file.readlines()\n",
    "#             if lines:\n",
    "#                 image_name = os.path.splitext(filename)[0] + \".jpg\"\n",
    "#                 color = lines[0].strip()  # สีอยู่บรรทัดแรกของไฟล์ labels\n",
    "\n",
    "#                 # ให้เพิ่มโค้ดนี้เพื่อนับจำนวนคนในภาพ\n",
    "#                 img_path = os.path.join(source_folder, image_name)\n",
    "#                 img = cv2.imread(img_path)\n",
    "#                 gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#                 face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "#                 faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4)\n",
    "#                 num_people = len(faces)\n",
    "\n",
    "#                 # เพิ่มข้อมูลลงใน DataFrame\n",
    "#                 data['Image'].append(image_name)\n",
    "#                 data['Color'].append(color)\n",
    "#                 data['Gender'].append(gender)  # ผลการทำนายเพศ\n",
    "#                 data['Num_People'].append(num_people)  # จำนวนคน\n",
    "\n",
    "# # สร้าง DataFrame จากข้อมูล\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # บันทึกลงในไฟล์ Excel\n",
    "# output_file = \"shoe_colors.xlsx\"\n",
    "# df.to_excel(output_file, index=False)\n",
    "\n",
    "# # ยืนยันที่ไฟล์ถูกบันทึก\n",
    "# print(f\"บันทึกข้อมูลลงในไฟล์ {output_file} เรียบร้อยแล้ว\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work on in later ^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = bio_dict\n",
    "# df = pd.DataFrame.from_dict(data, orient='index', columns=['Gender','Brand'])\n",
    "# df.to_excel('after2.xlsx', index_label='Crop_File')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# img = Image.open(\"D:\\\\Ai\\Detect running shoes\\\\shoe detection\\\\Real_1\\\\Shoes-crop\\\\2-2_1.JPG\")\n",
    "\n",
    "# max_colors = 256\n",
    "\n",
    "# print(img.getcolors(max_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
